Namespace(alpha=0.6, batch_size=32, beta_init=0.4, buffer_capacity=50000, clip_grad=True, device='cuda', envname='LunarLander-v2', epsilon_decay=0.925, epsilon_init=1, epsilon_min=0.01, epsilon_range=None, eval_episode=3, eval_period=1000, gamma=0.99, lr=0.001, max_episode_len=1000, model_dir='models/', n_iterations=150000, n_steps=1, natoms=51, no_dist=True, no_double=True, no_dueling=True, no_noisy=True, no_prioritized=False, noisy_std=0.5, save_model=False, start_update=100, target_update_period=500, vmax=200, vmin=-200, write_period=100)
Iteration:       0, Train reward:     nan, Eval reward: -232.151, TD loss:     nan, Episode:    0, Epsilon:    1
Iteration:     100, Train reward: -370.385, Eval reward: -232.151, TD loss:     nan, Episode:    1, Epsilon: 0.925
Iteration:     200, Train reward: -370.385, Eval reward: -232.151, TD loss:   1.162, Episode:    1, Epsilon: 0.925
Iteration:     300, Train reward: -233.558, Eval reward: -232.151, TD loss:   1.111, Episode:    2, Epsilon: 0.8556250000000001
Iteration:     400, Train reward: -237.792, Eval reward: -232.151, TD loss:   1.249, Episode:    3, Epsilon: 0.7914531250000001
Iteration:     500, Train reward: -192.902, Eval reward: -232.151, TD loss:   1.432, Episode:    4, Epsilon: 0.7320941406250001
Iteration:     600, Train reward: -212.346, Eval reward: -232.151, TD loss:   1.521, Episode:    5, Epsilon: 0.6771870800781251
Iteration:     700, Train reward: -204.304, Eval reward: -232.151, TD loss:   1.524, Episode:    6, Epsilon: 0.6263980490722657
Iteration:     800, Train reward: -188.344, Eval reward: -232.151, TD loss:   1.756, Episode:    7, Epsilon: 0.5794181953918458
Iteration:     900, Train reward: -164.005, Eval reward: -232.151, TD loss:   1.919, Episode:    8, Epsilon: 0.5359618307374574
Iteration:    1000, Train reward: -164.005, Eval reward: -179.813, TD loss:   1.984, Episode:    8, Epsilon: 0.5359618307374574
Iteration:    1100, Train reward: -156.496, Eval reward: -179.813, TD loss:   1.805, Episode:    9, Epsilon: 0.49576469343214813
Iteration:    1200, Train reward: -156.496, Eval reward: -179.813, TD loss:   1.832, Episode:    9, Epsilon: 0.49576469343214813
Iteration:    1300, Train reward: -156.496, Eval reward: -179.813, TD loss:   1.758, Episode:    9, Epsilon: 0.49576469343214813
Iteration:    1400, Train reward: -151.321, Eval reward: -179.813, TD loss:   1.586, Episode:   10, Epsilon: 0.45858234142473703
Iteration:    1500, Train reward: -151.321, Eval reward: -179.813, TD loss:   1.540, Episode:   10, Epsilon: 0.45858234142473703
Iteration:    1600, Train reward: -149.380, Eval reward: -179.813, TD loss:   2.045, Episode:   11, Epsilon: 0.4241886658178818
Iteration:    1700, Train reward: -147.300, Eval reward: -179.813, TD loss:   1.687, Episode:   12, Epsilon: 0.39237451588154065
Iteration:    1800, Train reward: -147.300, Eval reward: -179.813, TD loss:   1.669, Episode:   12, Epsilon: 0.39237451588154065
Iteration:    1900, Train reward: -142.868, Eval reward: -179.813, TD loss:   1.484, Episode:   13, Epsilon: 0.36294642719042514
Iteration:    2000, Train reward: -142.868, Eval reward: -205.422, TD loss:   1.502, Episode:   13, Epsilon: 0.36294642719042514
Iteration:    2100, Train reward: -142.868, Eval reward: -205.422, TD loss:   1.832, Episode:   13, Epsilon: 0.36294642719042514
Iteration:    2200, Train reward: -138.901, Eval reward: -205.422, TD loss:   1.660, Episode:   14, Epsilon: 0.3357254451511433
Iteration:    2300, Train reward: -138.901, Eval reward: -205.422, TD loss:   1.634, Episode:   14, Epsilon: 0.3357254451511433
Iteration:    2400, Train reward: -136.439, Eval reward: -205.422, TD loss:   1.589, Episode:   15, Epsilon: 0.3105460367648075
Iteration:    2500, Train reward: -136.439, Eval reward: -205.422, TD loss:   1.327, Episode:   15, Epsilon: 0.3105460367648075
Iteration:    2600, Train reward: -136.439, Eval reward: -205.422, TD loss:   1.540, Episode:   15, Epsilon: 0.3105460367648075
Iteration:    2700, Train reward: -129.954, Eval reward: -205.422, TD loss:   1.352, Episode:   16, Epsilon: 0.287255084007447
Iteration:    2800, Train reward: -129.954, Eval reward: -205.422, TD loss:   1.357, Episode:   16, Epsilon: 0.287255084007447
Iteration:    2900, Train reward: -125.869, Eval reward: -205.422, TD loss:   1.484, Episode:   17, Epsilon: 0.2657109527068885
Iteration:    3000, Train reward: -125.869, Eval reward: -180.696, TD loss:   1.301, Episode:   17, Epsilon: 0.2657109527068885
Iteration:    3100, Train reward: -126.352, Eval reward: -180.696, TD loss:   1.535, Episode:   18, Epsilon: 0.24578263125387187
Iteration:    3200, Train reward: -126.352, Eval reward: -180.696, TD loss:   1.481, Episode:   18, Epsilon: 0.24578263125387187
Iteration:    3300, Train reward: -123.195, Eval reward: -180.696, TD loss:   1.400, Episode:   19, Epsilon: 0.2273489339098315
Iteration:    3400, Train reward: -123.195, Eval reward: -180.696, TD loss:   1.470, Episode:   19, Epsilon: 0.2273489339098315
Iteration:    3500, Train reward: -119.949, Eval reward: -180.696, TD loss:   1.602, Episode:   20, Epsilon: 0.21029776386659413
Iteration:    3600, Train reward: -119.949, Eval reward: -180.696, TD loss:   1.643, Episode:   20, Epsilon: 0.21029776386659413
Iteration:    3700, Train reward: -119.949, Eval reward: -180.696, TD loss:   1.743, Episode:   20, Epsilon: 0.21029776386659413
Iteration:    3800, Train reward: -101.519, Eval reward: -180.696, TD loss:   1.711, Episode:   21, Epsilon: 0.19452543157659957
Iteration:    3900, Train reward: -98.299, Eval reward: -180.696, TD loss:   1.639, Episode:   22, Epsilon: 0.1799360242083546
Iteration:    4000, Train reward: -98.299, Eval reward: -314.970, TD loss:   1.707, Episode:   22, Epsilon: 0.1799360242083546
Iteration:    4100, Train reward: -98.299, Eval reward: -314.970, TD loss:   1.847, Episode:   22, Epsilon: 0.1799360242083546
Iteration:    4200, Train reward: -98.299, Eval reward: -314.970, TD loss:   1.575, Episode:   22, Epsilon: 0.1799360242083546
Iteration:    4300, Train reward: -98.299, Eval reward: -314.970, TD loss:   1.620, Episode:   22, Epsilon: 0.1799360242083546
Iteration:    4400, Train reward: -98.299, Eval reward: -314.970, TD loss:   1.553, Episode:   22, Epsilon: 0.1799360242083546
Iteration:    4500, Train reward: -89.748, Eval reward: -314.970, TD loss:   1.578, Episode:   23, Epsilon: 0.16644082239272803
Iteration:    4600, Train reward: -89.748, Eval reward: -314.970, TD loss:   1.769, Episode:   23, Epsilon: 0.16644082239272803
Iteration:    4700, Train reward: -89.748, Eval reward: -314.970, TD loss:   1.597, Episode:   23, Epsilon: 0.16644082239272803
Iteration:    4800, Train reward: -97.991, Eval reward: -314.970, TD loss:   1.639, Episode:   24, Epsilon: 0.15395776071327344
Iteration:    4900, Train reward: -97.991, Eval reward: -314.970, TD loss:   1.889, Episode:   24, Epsilon: 0.15395776071327344
Iteration:    5000, Train reward: -97.991, Eval reward: -93.157, TD loss:   2.046, Episode:   24, Epsilon: 0.15395776071327344
Iteration:    5100, Train reward: -82.681, Eval reward: -93.157, TD loss:   1.973, Episode:   25, Epsilon: 0.14241092865977795
Iteration:    5200, Train reward: -82.681, Eval reward: -93.157, TD loss:   1.775, Episode:   25, Epsilon: 0.14241092865977795
Iteration:    5300, Train reward: -81.184, Eval reward: -93.157, TD loss:   1.701, Episode:   26, Epsilon: 0.1317301090102946
Iteration:    5400, Train reward: -77.990, Eval reward: -93.157, TD loss:   1.751, Episode:   27, Epsilon: 0.12185035083452252
Iteration:    5500, Train reward: -77.990, Eval reward: -93.157, TD loss:   1.824, Episode:   27, Epsilon: 0.12185035083452252
Iteration:    5600, Train reward: -77.990, Eval reward: -93.157, TD loss:   1.757, Episode:   27, Epsilon: 0.12185035083452252
Iteration:    5700, Train reward: -77.990, Eval reward: -93.157, TD loss:   1.492, Episode:   27, Epsilon: 0.12185035083452252
Iteration:    5800, Train reward: -77.990, Eval reward: -93.157, TD loss:   1.550, Episode:   27, Epsilon: 0.12185035083452252
Iteration:    5900, Train reward: -77.990, Eval reward: -93.157, TD loss:   1.685, Episode:   27, Epsilon: 0.12185035083452252
Iteration:    6000, Train reward: -77.990, Eval reward: -79.461, TD loss:   1.406, Episode:   27, Epsilon: 0.12185035083452252
Iteration:    6100, Train reward: -77.990, Eval reward: -79.461, TD loss:   1.527, Episode:   27, Epsilon: 0.12185035083452252
Iteration:    6200, Train reward: -77.990, Eval reward: -79.461, TD loss:   1.381, Episode:   27, Epsilon: 0.12185035083452252
Iteration:    6300, Train reward: -77.990, Eval reward: -79.461, TD loss:   1.444, Episode:   27, Epsilon: 0.12185035083452252
Iteration:    6400, Train reward: -80.231, Eval reward: -79.461, TD loss:   1.256, Episode:   28, Epsilon: 0.11271157452193334
Iteration:    6500, Train reward: -80.231, Eval reward: -79.461, TD loss:   1.297, Episode:   28, Epsilon: 0.11271157452193334
Iteration:    6600, Train reward: -74.873, Eval reward: -79.461, TD loss:   1.280, Episode:   29, Epsilon: 0.10425820643278834
Iteration:    6700, Train reward: -74.873, Eval reward: -79.461, TD loss:   1.461, Episode:   29, Epsilon: 0.10425820643278834
Iteration:    6800, Train reward: -74.873, Eval reward: -79.461, TD loss:   1.347, Episode:   29, Epsilon: 0.10425820643278834
Iteration:    6900, Train reward: -74.873, Eval reward: -79.461, TD loss:   1.329, Episode:   29, Epsilon: 0.10425820643278834
Iteration:    7000, Train reward: -74.873, Eval reward: -158.217, TD loss:   1.197, Episode:   29, Epsilon: 0.10425820643278834
Iteration:    7100, Train reward: -74.873, Eval reward: -158.217, TD loss:   1.184, Episode:   29, Epsilon: 0.10425820643278834
Iteration:    7200, Train reward: -74.873, Eval reward: -158.217, TD loss:   1.318, Episode:   29, Epsilon: 0.10425820643278834
Iteration:    7300, Train reward: -74.873, Eval reward: -158.217, TD loss:   1.126, Episode:   29, Epsilon: 0.10425820643278834
Iteration:    7400, Train reward: -74.873, Eval reward: -158.217, TD loss:   1.245, Episode:   29, Epsilon: 0.10425820643278834
Iteration:    7500, Train reward: -74.873, Eval reward: -158.217, TD loss:   1.136, Episode:   29, Epsilon: 0.10425820643278834
Iteration:    7600, Train reward: -71.215, Eval reward: -158.217, TD loss:   1.149, Episode:   30, Epsilon: 0.09643884095032922
Iteration:    7700, Train reward: -68.210, Eval reward: -158.217, TD loss:   1.213, Episode:   31, Epsilon: 0.08920592787905453
Iteration:    7800, Train reward: -68.210, Eval reward: -158.217, TD loss:   1.216, Episode:   31, Epsilon: 0.08920592787905453
Iteration:    7900, Train reward: -68.210, Eval reward: -158.217, TD loss:   1.230, Episode:   31, Epsilon: 0.08920592787905453
Iteration:    8000, Train reward: -68.210, Eval reward: -64.709, TD loss:   1.088, Episode:   31, Epsilon: 0.08920592787905453
Iteration:    8100, Train reward: -68.210, Eval reward: -64.709, TD loss:   1.189, Episode:   31, Epsilon: 0.08920592787905453
Iteration:    8200, Train reward: -68.210, Eval reward: -64.709, TD loss:   1.164, Episode:   31, Epsilon: 0.08920592787905453
Iteration:    8300, Train reward: -68.210, Eval reward: -64.709, TD loss:   1.038, Episode:   31, Epsilon: 0.08920592787905453
Iteration:    8400, Train reward: -68.210, Eval reward: -64.709, TD loss:   1.151, Episode:   31, Epsilon: 0.08920592787905453
Iteration:    8500, Train reward: -68.210, Eval reward: -64.709, TD loss:   1.099, Episode:   31, Epsilon: 0.08920592787905453
Iteration:    8600, Train reward: -68.210, Eval reward: -64.709, TD loss:   1.130, Episode:   31, Epsilon: 0.08920592787905453
Iteration:    8700, Train reward: -61.438, Eval reward: -64.709, TD loss:   0.917, Episode:   32, Epsilon: 0.08251548328812544
Iteration:    8800, Train reward: -61.438, Eval reward: -64.709, TD loss:   1.052, Episode:   32, Epsilon: 0.08251548328812544
Iteration:    8900, Train reward: -61.438, Eval reward: -64.709, TD loss:   1.119, Episode:   32, Epsilon: 0.08251548328812544
Iteration:    9000, Train reward: -61.438, Eval reward: -59.177, TD loss:   1.080, Episode:   32, Epsilon: 0.08251548328812544
Iteration:    9100, Train reward: -61.438, Eval reward: -59.177, TD loss:   1.092, Episode:   32, Epsilon: 0.08251548328812544
Iteration:    9200, Train reward: -61.438, Eval reward: -59.177, TD loss:   1.139, Episode:   32, Epsilon: 0.08251548328812544
Iteration:    9300, Train reward: -61.438, Eval reward: -59.177, TD loss:   1.036, Episode:   32, Epsilon: 0.08251548328812544
Iteration:    9400, Train reward: -61.350, Eval reward: -59.177, TD loss:   1.078, Episode:   33, Epsilon: 0.07632682204151604
Iteration:    9500, Train reward: -61.350, Eval reward: -59.177, TD loss:   1.045, Episode:   33, Epsilon: 0.07632682204151604
Iteration:    9600, Train reward: -61.350, Eval reward: -59.177, TD loss:   1.102, Episode:   33, Epsilon: 0.07632682204151604
Iteration:    9700, Train reward: -61.350, Eval reward: -59.177, TD loss:   1.005, Episode:   33, Epsilon: 0.07632682204151604
Iteration:    9800, Train reward: -61.350, Eval reward: -59.177, TD loss:   0.951, Episode:   33, Epsilon: 0.07632682204151604
Iteration:    9900, Train reward: -61.350, Eval reward: -59.177, TD loss:   0.971, Episode:   33, Epsilon: 0.07632682204151604
Iteration:   10000, Train reward: -61.350, Eval reward: -25.485, TD loss:   0.924, Episode:   33, Epsilon: 0.07632682204151604
Iteration:   10100, Train reward: -61.350, Eval reward: -25.485, TD loss:   0.986, Episode:   33, Epsilon: 0.07632682204151604
Iteration:   10200, Train reward: -61.350, Eval reward: -25.485, TD loss:   1.005, Episode:   33, Epsilon: 0.07632682204151604
Iteration:   10300, Train reward: -61.350, Eval reward: -25.485, TD loss:   0.950, Episode:   33, Epsilon: 0.07632682204151604
Iteration:   10400, Train reward: -59.192, Eval reward: -25.485, TD loss:   0.860, Episode:   34, Epsilon: 0.07060231038840234
Iteration:   10500, Train reward: -59.192, Eval reward: -25.485, TD loss:   0.893, Episode:   34, Epsilon: 0.07060231038840234
Iteration:   10600, Train reward: -59.192, Eval reward: -25.485, TD loss:   1.090, Episode:   34, Epsilon: 0.07060231038840234
Iteration:   10700, Train reward: -59.192, Eval reward: -25.485, TD loss:   1.040, Episode:   34, Epsilon: 0.07060231038840234
Iteration:   10800, Train reward: -59.192, Eval reward: -25.485, TD loss:   1.023, Episode:   34, Epsilon: 0.07060231038840234
Iteration:   10900, Train reward: -59.192, Eval reward: -25.485, TD loss:   1.097, Episode:   34, Epsilon: 0.07060231038840234
Iteration:   11000, Train reward: -59.192, Eval reward: -43.594, TD loss:   0.970, Episode:   34, Epsilon: 0.07060231038840234
Iteration:   11100, Train reward: -59.192, Eval reward: -43.594, TD loss:   0.992, Episode:   34, Epsilon: 0.07060231038840234
Iteration:   11200, Train reward: -59.192, Eval reward: -43.594, TD loss:   0.914, Episode:   34, Epsilon: 0.07060231038840234
Iteration:   11300, Train reward: -59.192, Eval reward: -43.594, TD loss:   0.928, Episode:   34, Epsilon: 0.07060231038840234
Iteration:   11400, Train reward: -56.262, Eval reward: -43.594, TD loss:   0.962, Episode:   35, Epsilon: 0.06530713710927216
Iteration:   11500, Train reward: -56.262, Eval reward: -43.594, TD loss:   0.917, Episode:   35, Epsilon: 0.06530713710927216
Iteration:   11600, Train reward: -56.262, Eval reward: -43.594, TD loss:   0.953, Episode:   35, Epsilon: 0.06530713710927216
Iteration:   11700, Train reward: -56.262, Eval reward: -43.594, TD loss:   0.932, Episode:   35, Epsilon: 0.06530713710927216
Iteration:   11800, Train reward: -56.262, Eval reward: -43.594, TD loss:   0.868, Episode:   35, Epsilon: 0.06530713710927216
Iteration:   11900, Train reward: -56.262, Eval reward: -43.594, TD loss:   0.989, Episode:   35, Epsilon: 0.06530713710927216
Iteration:   12000, Train reward: -56.262, Eval reward: -81.213, TD loss:   0.833, Episode:   35, Epsilon: 0.06530713710927216
Iteration:   12100, Train reward: -56.262, Eval reward: -81.213, TD loss:   1.025, Episode:   35, Epsilon: 0.06530713710927216
Iteration:   12200, Train reward: -56.262, Eval reward: -81.213, TD loss:   0.943, Episode:   35, Epsilon: 0.06530713710927216
Iteration:   12300, Train reward: -56.262, Eval reward: -81.213, TD loss:   0.833, Episode:   35, Epsilon: 0.06530713710927216
Iteration:   12400, Train reward: -56.377, Eval reward: -81.213, TD loss:   0.876, Episode:   36, Epsilon: 0.060409101826076755
Iteration:   12500, Train reward: -56.377, Eval reward: -81.213, TD loss:   0.874, Episode:   36, Epsilon: 0.060409101826076755
Iteration:   12600, Train reward: -56.377, Eval reward: -81.213, TD loss:   0.928, Episode:   36, Epsilon: 0.060409101826076755
Iteration:   12700, Train reward: -56.377, Eval reward: -81.213, TD loss:   0.958, Episode:   36, Epsilon: 0.060409101826076755
Iteration:   12800, Train reward: -56.377, Eval reward: -81.213, TD loss:   0.874, Episode:   36, Epsilon: 0.060409101826076755
Iteration:   12900, Train reward: -56.377, Eval reward: -81.213, TD loss:   0.795, Episode:   36, Epsilon: 0.060409101826076755
Iteration:   13000, Train reward: -56.377, Eval reward: -35.334, TD loss:   0.790, Episode:   36, Epsilon: 0.060409101826076755
Iteration:   13100, Train reward: -56.377, Eval reward: -35.334, TD loss:   0.845, Episode:   36, Epsilon: 0.060409101826076755
Iteration:   13200, Train reward: -56.377, Eval reward: -35.334, TD loss:   0.819, Episode:   36, Epsilon: 0.060409101826076755
Iteration:   13300, Train reward: -56.377, Eval reward: -35.334, TD loss:   0.826, Episode:   36, Epsilon: 0.060409101826076755
Iteration:   13400, Train reward: -57.430, Eval reward: -35.334, TD loss:   0.837, Episode:   37, Epsilon: 0.055878419189121
Iteration:   13500, Train reward: -57.430, Eval reward: -35.334, TD loss:   0.761, Episode:   37, Epsilon: 0.055878419189121
Iteration:   13600, Train reward: -57.430, Eval reward: -35.334, TD loss:   0.912, Episode:   37, Epsilon: 0.055878419189121
Iteration:   13700, Train reward: -57.430, Eval reward: -35.334, TD loss:   0.963, Episode:   37, Epsilon: 0.055878419189121
Iteration:   13800, Train reward: -57.430, Eval reward: -35.334, TD loss:   0.824, Episode:   37, Epsilon: 0.055878419189121
Iteration:   13900, Train reward: -57.430, Eval reward: -35.334, TD loss:   0.866, Episode:   37, Epsilon: 0.055878419189121
Iteration:   14000, Train reward: -57.430, Eval reward: -78.830, TD loss:   0.810, Episode:   37, Epsilon: 0.055878419189121
Iteration:   14100, Train reward: -57.430, Eval reward: -78.830, TD loss:   0.845, Episode:   37, Epsilon: 0.055878419189121
Iteration:   14200, Train reward: -57.430, Eval reward: -78.830, TD loss:   0.899, Episode:   37, Epsilon: 0.055878419189121
Iteration:   14300, Train reward: -57.430, Eval reward: -78.830, TD loss:   0.872, Episode:   37, Epsilon: 0.055878419189121
Iteration:   14400, Train reward: -52.368, Eval reward: -78.830, TD loss:   0.889, Episode:   38, Epsilon: 0.05168753774993693
Iteration:   14500, Train reward: -52.368, Eval reward: -78.830, TD loss:   0.832, Episode:   38, Epsilon: 0.05168753774993693
Iteration:   14600, Train reward: -52.368, Eval reward: -78.830, TD loss:   0.882, Episode:   38, Epsilon: 0.05168753774993693
Iteration:   14700, Train reward: -52.368, Eval reward: -78.830, TD loss:   0.893, Episode:   38, Epsilon: 0.05168753774993693
Iteration:   14800, Train reward: -52.368, Eval reward: -78.830, TD loss:   0.811, Episode:   38, Epsilon: 0.05168753774993693
Iteration:   14900, Train reward: -52.368, Eval reward: -78.830, TD loss:   0.780, Episode:   38, Epsilon: 0.05168753774993693
Iteration:   15000, Train reward: -52.368, Eval reward: -185.721, TD loss:   0.783, Episode:   38, Epsilon: 0.05168753774993693
Iteration:   15100, Train reward: -52.368, Eval reward: -185.721, TD loss:   0.881, Episode:   38, Epsilon: 0.05168753774993693
Iteration:   15200, Train reward: -52.368, Eval reward: -185.721, TD loss:   0.761, Episode:   38, Epsilon: 0.05168753774993693
Iteration:   15300, Train reward: -52.368, Eval reward: -185.721, TD loss:   0.749, Episode:   38, Epsilon: 0.05168753774993693
Iteration:   15400, Train reward: -51.620, Eval reward: -185.721, TD loss:   0.757, Episode:   39, Epsilon: 0.047810972418691665
Iteration:   15500, Train reward: -51.620, Eval reward: -185.721, TD loss:   0.676, Episode:   39, Epsilon: 0.047810972418691665
Iteration:   15600, Train reward: -51.620, Eval reward: -185.721, TD loss:   0.823, Episode:   39, Epsilon: 0.047810972418691665
Iteration:   15700, Train reward: -51.620, Eval reward: -185.721, TD loss:   0.807, Episode:   39, Epsilon: 0.047810972418691665
Iteration:   15800, Train reward: -51.620, Eval reward: -185.721, TD loss:   0.731, Episode:   39, Epsilon: 0.047810972418691665
Iteration:   15900, Train reward: -51.620, Eval reward: -185.721, TD loss:   0.673, Episode:   39, Epsilon: 0.047810972418691665
Iteration:   16000, Train reward: -51.620, Eval reward: -108.664, TD loss:   0.988, Episode:   39, Epsilon: 0.047810972418691665
Iteration:   16100, Train reward: -51.620, Eval reward: -108.664, TD loss:   0.860, Episode:   39, Epsilon: 0.047810972418691665
Iteration:   16200, Train reward: -51.620, Eval reward: -108.664, TD loss:   0.928, Episode:   39, Epsilon: 0.047810972418691665
Iteration:   16300, Train reward: -51.620, Eval reward: -108.664, TD loss:   0.952, Episode:   39, Epsilon: 0.047810972418691665
Iteration:   16400, Train reward: -55.634, Eval reward: -108.664, TD loss:   0.834, Episode:   41, Epsilon: 0.04090826327574306
Iteration:   16500, Train reward: -55.634, Eval reward: -108.664, TD loss:   0.861, Episode:   41, Epsilon: 0.04090826327574306
Iteration:   16600, Train reward: -55.634, Eval reward: -108.664, TD loss:   0.833, Episode:   41, Epsilon: 0.04090826327574306
Iteration:   16700, Train reward: -55.634, Eval reward: -108.664, TD loss:   0.829, Episode:   41, Epsilon: 0.04090826327574306
Iteration:   16800, Train reward: -55.634, Eval reward: -108.664, TD loss:   0.908, Episode:   41, Epsilon: 0.04090826327574306
Iteration:   16900, Train reward: -55.634, Eval reward: -108.664, TD loss:   0.833, Episode:   41, Epsilon: 0.04090826327574306
Iteration:   17000, Train reward: -55.634, Eval reward: -161.807, TD loss:   0.824, Episode:   41, Epsilon: 0.04090826327574306
Iteration:   17100, Train reward: -55.634, Eval reward: -161.807, TD loss:   0.807, Episode:   41, Epsilon: 0.04090826327574306
Iteration:   17200, Train reward: -55.634, Eval reward: -161.807, TD loss:   0.795, Episode:   41, Epsilon: 0.04090826327574306
Iteration:   17300, Train reward: -55.634, Eval reward: -161.807, TD loss:   0.814, Episode:   41, Epsilon: 0.04090826327574306
Iteration:   17400, Train reward: -62.621, Eval reward: -161.807, TD loss:   0.891, Episode:   42, Epsilon: 0.037840143530062334
Iteration:   17500, Train reward: -75.894, Eval reward: -161.807, TD loss:   0.936, Episode:   43, Epsilon: 0.03500213276530766
Iteration:   17600, Train reward: -70.586, Eval reward: -161.807, TD loss:   1.516, Episode:   44, Epsilon: 0.03237697280790959
Iteration:   17700, Train reward: -79.652, Eval reward: -161.807, TD loss:   1.684, Episode:   45, Epsilon: 0.029948699847316372
Iteration:   17800, Train reward: -92.669, Eval reward: -161.807, TD loss:   2.080, Episode:   46, Epsilon: 0.027702547358767645
Iteration:   17900, Train reward: -92.669, Eval reward: -161.807, TD loss:   2.082, Episode:   46, Epsilon: 0.027702547358767645
Iteration:   18000, Train reward: -92.669, Eval reward: -107.953, TD loss:   2.118, Episode:   46, Epsilon: 0.027702547358767645
Iteration:   18100, Train reward: -92.669, Eval reward: -107.953, TD loss:   1.839, Episode:   46, Epsilon: 0.027702547358767645
Iteration:   18200, Train reward: -92.669, Eval reward: -107.953, TD loss:   2.222, Episode:   46, Epsilon: 0.027702547358767645
Iteration:   18300, Train reward: -92.669, Eval reward: -107.953, TD loss:   2.174, Episode:   46, Epsilon: 0.027702547358767645
Iteration:   18400, Train reward: -92.669, Eval reward: -107.953, TD loss:   1.904, Episode:   46, Epsilon: 0.027702547358767645
Iteration:   18500, Train reward: -92.669, Eval reward: -107.953, TD loss:   1.872, Episode:   46, Epsilon: 0.027702547358767645
Iteration:   18600, Train reward: -92.669, Eval reward: -107.953, TD loss:   2.214, Episode:   46, Epsilon: 0.027702547358767645
Iteration:   18700, Train reward: -92.669, Eval reward: -107.953, TD loss:   1.787, Episode:   46, Epsilon: 0.027702547358767645
Iteration:   18800, Train reward: -97.192, Eval reward: -107.953, TD loss:   2.033, Episode:   47, Epsilon: 0.025624856306860073
Iteration:   18900, Train reward: -105.859, Eval reward: -107.953, TD loss:   1.955, Episode:   48, Epsilon: 0.02370299208384557
Iteration:   19000, Train reward: -105.859, Eval reward: -80.036, TD loss:   2.112, Episode:   48, Epsilon: 0.02370299208384557
Iteration:   19100, Train reward: -105.859, Eval reward: -80.036, TD loss:   2.033, Episode:   48, Epsilon: 0.02370299208384557
Iteration:   19200, Train reward: -105.859, Eval reward: -80.036, TD loss:   2.037, Episode:   48, Epsilon: 0.02370299208384557
Iteration:   19300, Train reward: -105.859, Eval reward: -80.036, TD loss:   1.935, Episode:   48, Epsilon: 0.02370299208384557
Iteration:   19400, Train reward: -105.859, Eval reward: -80.036, TD loss:   1.969, Episode:   48, Epsilon: 0.02370299208384557
Iteration:   19500, Train reward: -105.859, Eval reward: -80.036, TD loss:   1.815, Episode:   48, Epsilon: 0.02370299208384557
Iteration:   19600, Train reward: -105.859, Eval reward: -80.036, TD loss:   2.082, Episode:   48, Epsilon: 0.02370299208384557
Iteration:   19700, Train reward: -105.859, Eval reward: -80.036, TD loss:   1.826, Episode:   48, Epsilon: 0.02370299208384557
Iteration:   19800, Train reward: -105.859, Eval reward: -80.036, TD loss:   2.069, Episode:   48, Epsilon: 0.02370299208384557
Iteration:   19900, Train reward: -109.646, Eval reward: -80.036, TD loss:   1.707, Episode:   49, Epsilon: 0.02192526767755715
Iteration:   20000, Train reward: -109.646, Eval reward: -79.486, TD loss:   1.841, Episode:   49, Epsilon: 0.02192526767755715
Iteration:   20100, Train reward: -109.646, Eval reward: -79.486, TD loss:   1.923, Episode:   49, Epsilon: 0.02192526767755715
Iteration:   20200, Train reward: -112.313, Eval reward: -79.486, TD loss:   2.108, Episode:   50, Epsilon: 0.020280872601740364
Iteration:   20300, Train reward: -116.765, Eval reward: -79.486, TD loss:   2.066, Episode:   51, Epsilon: 0.01875980715660984
Iteration:   20400, Train reward: -116.765, Eval reward: -79.486, TD loss:   1.933, Episode:   51, Epsilon: 0.01875980715660984
Iteration:   20500, Train reward: -116.765, Eval reward: -79.486, TD loss:   2.158, Episode:   51, Epsilon: 0.01875980715660984
Iteration:   20600, Train reward: -116.765, Eval reward: -79.486, TD loss:   2.179, Episode:   51, Epsilon: 0.01875980715660984
Iteration:   20700, Train reward: -116.765, Eval reward: -79.486, TD loss:   2.072, Episode:   51, Epsilon: 0.01875980715660984
Iteration:   20800, Train reward: -116.765, Eval reward: -79.486, TD loss:   2.158, Episode:   51, Epsilon: 0.01875980715660984
Iteration:   20900, Train reward: -116.765, Eval reward: -79.486, TD loss:   2.181, Episode:   51, Epsilon: 0.01875980715660984
Iteration:   21000, Train reward: -126.361, Eval reward: -136.807, TD loss:   2.062, Episode:   52, Epsilon: 0.017352821619864102
Iteration:   21100, Train reward: -132.851, Eval reward: -136.807, TD loss:   2.237, Episode:   53, Epsilon: 0.016051359998374294
Iteration:   21200, Train reward: -140.410, Eval reward: -136.807, TD loss:   2.248, Episode:   54, Epsilon: 0.014847507998496223
Iteration:   21300, Train reward: -151.880, Eval reward: -136.807, TD loss:   2.850, Episode:   55, Epsilon: 0.013733944898609006
Iteration:   21400, Train reward: -151.880, Eval reward: -136.807, TD loss:   3.062, Episode:   55, Epsilon: 0.013733944898609006
Iteration:   21500, Train reward: -160.607, Eval reward: -136.807, TD loss:   3.199, Episode:   56, Epsilon: 0.012703899031213332
Iteration:   21600, Train reward: -162.924, Eval reward: -136.807, TD loss:   3.156, Episode:   57, Epsilon: 0.011751106603872333
Iteration:   21700, Train reward: -162.924, Eval reward: -136.807, TD loss:   3.649, Episode:   57, Epsilon: 0.011751106603872333
Iteration:   21800, Train reward: -162.636, Eval reward: -136.807, TD loss:   3.411, Episode:   58, Epsilon: 0.010869773608581908
Iteration:   21900, Train reward: -162.040, Eval reward: -136.807, TD loss:   3.639, Episode:   59, Epsilon: 0.010054540587938265
Iteration:   22000, Train reward: -167.832, Eval reward: -170.813, TD loss:   3.312, Episode:   60, Epsilon: 0.01
Iteration:   22100, Train reward: -171.288, Eval reward: -170.813, TD loss:   3.291, Episode:   61, Epsilon: 0.01
Iteration:   22200, Train reward: -171.288, Eval reward: -170.813, TD loss:   3.490, Episode:   61, Epsilon: 0.01
Iteration:   22300, Train reward: -160.253, Eval reward: -170.813, TD loss:   3.766, Episode:   63, Epsilon: 0.01
Iteration:   22400, Train reward: -160.253, Eval reward: -170.813, TD loss:   3.581, Episode:   63, Epsilon: 0.01
Iteration:   22500, Train reward: -157.803, Eval reward: -170.813, TD loss:   3.485, Episode:   64, Epsilon: 0.01
Iteration:   22600, Train reward: -157.803, Eval reward: -170.813, TD loss:   3.704, Episode:   64, Epsilon: 0.01
Iteration:   22700, Train reward: -149.842, Eval reward: -170.813, TD loss:   4.017, Episode:   65, Epsilon: 0.01
Iteration:   22800, Train reward: -132.282, Eval reward: -170.813, TD loss:   3.873, Episode:   66, Epsilon: 0.01
Iteration:   22900, Train reward: -134.205, Eval reward: -170.813, TD loss:   3.583, Episode:   67, Epsilon: 0.01
Iteration:   23000, Train reward: -128.224, Eval reward: -163.850, TD loss:   3.782, Episode:   68, Epsilon: 0.01
Iteration:   23100, Train reward: -123.795, Eval reward: -163.850, TD loss:   4.178, Episode:   69, Epsilon: 0.01
Iteration:   23200, Train reward: -123.795, Eval reward: -163.850, TD loss:   3.525, Episode:   69, Epsilon: 0.01
Iteration:   23300, Train reward: -133.814, Eval reward: -163.850, TD loss:   4.115, Episode:   70, Epsilon: 0.01
Iteration:   23400, Train reward: -133.814, Eval reward: -163.850, TD loss:   4.196, Episode:   70, Epsilon: 0.01
Iteration:   23500, Train reward: -133.814, Eval reward: -163.850, TD loss:   4.040, Episode:   70, Epsilon: 0.01
Iteration:   23600, Train reward: -133.814, Eval reward: -163.850, TD loss:   4.149, Episode:   70, Epsilon: 0.01
Iteration:   23700, Train reward: -133.814, Eval reward: -163.850, TD loss:   3.982, Episode:   70, Epsilon: 0.01
Iteration:   23800, Train reward: -133.814, Eval reward: -163.850, TD loss:   3.852, Episode:   70, Epsilon: 0.01
Iteration:   23900, Train reward: -138.886, Eval reward: -163.850, TD loss:   3.820, Episode:   71, Epsilon: 0.01
Iteration:   24000, Train reward: -144.947, Eval reward: -73.823, TD loss:   4.214, Episode:   72, Epsilon: 0.01
Iteration:   24100, Train reward: -143.084, Eval reward: -73.823, TD loss:   4.368, Episode:   73, Epsilon: 0.01
Iteration:   24200, Train reward: -135.947, Eval reward: -73.823, TD loss:   4.141, Episode:   74, Epsilon: 0.01
Iteration:   24300, Train reward: -135.947, Eval reward: -73.823, TD loss:   4.266, Episode:   74, Epsilon: 0.01
Iteration:   24400, Train reward: -125.865, Eval reward: -73.823, TD loss:   4.197, Episode:   76, Epsilon: 0.01
Iteration:   24500, Train reward: -128.524, Eval reward: -73.823, TD loss:   4.529, Episode:   77, Epsilon: 0.01
Iteration:   24600, Train reward: -128.524, Eval reward: -73.823, TD loss:   4.331, Episode:   77, Epsilon: 0.01
Iteration:   24700, Train reward: -135.155, Eval reward: -73.823, TD loss:   4.421, Episode:   79, Epsilon: 0.01
Iteration:   24800, Train reward: -135.155, Eval reward: -73.823, TD loss:   4.405, Episode:   79, Epsilon: 0.01
Iteration:   24900, Train reward: -128.679, Eval reward: -73.823, TD loss:   4.624, Episode:   80, Epsilon: 0.01
Iteration:   25000, Train reward: -128.802, Eval reward: -177.796, TD loss:   4.772, Episode:   81, Epsilon: 0.01
Iteration:   25100, Train reward: -128.802, Eval reward: -177.796, TD loss:   4.897, Episode:   81, Epsilon: 0.01
Iteration:   25200, Train reward: -127.479, Eval reward: -177.796, TD loss:   4.483, Episode:   83, Epsilon: 0.01
Iteration:   25300, Train reward: -133.354, Eval reward: -177.796, TD loss:   4.487, Episode:   84, Epsilon: 0.01
Iteration:   25400, Train reward: -133.354, Eval reward: -177.796, TD loss:   5.190, Episode:   84, Epsilon: 0.01
Iteration:   25500, Train reward: -133.354, Eval reward: -177.796, TD loss:   4.600, Episode:   84, Epsilon: 0.01
Iteration:   25600, Train reward: -133.354, Eval reward: -177.796, TD loss:   4.546, Episode:   84, Epsilon: 0.01
Iteration:   25700, Train reward: -146.759, Eval reward: -177.796, TD loss:   4.501, Episode:   85, Epsilon: 0.01
Iteration:   25800, Train reward: -146.759, Eval reward: -177.796, TD loss:   4.526, Episode:   85, Epsilon: 0.01
Iteration:   25900, Train reward: -148.236, Eval reward: -177.796, TD loss:   4.816, Episode:   86, Epsilon: 0.01
Iteration:   26000, Train reward: -149.852, Eval reward: -99.577, TD loss:   4.905, Episode:   87, Epsilon: 0.01
Iteration:   26100, Train reward: -189.217, Eval reward: -99.577, TD loss:   5.314, Episode:   89, Epsilon: 0.01
Iteration:   26200, Train reward: -189.217, Eval reward: -99.577, TD loss:   5.327, Episode:   89, Epsilon: 0.01
Iteration:   26300, Train reward: -173.653, Eval reward: -99.577, TD loss:   5.199, Episode:   90, Epsilon: 0.01
Iteration:   26400, Train reward: -172.373, Eval reward: -99.577, TD loss:   5.116, Episode:   91, Epsilon: 0.01
Iteration:   26500, Train reward: -173.992, Eval reward: -99.577, TD loss:   5.469, Episode:   93, Epsilon: 0.01
Iteration:   26600, Train reward: -178.206, Eval reward: -99.577, TD loss:   5.665, Episode:   94, Epsilon: 0.01
Iteration:   26700, Train reward: -187.378, Eval reward: -99.577, TD loss:   5.387, Episode:   95, Epsilon: 0.01
Iteration:   26800, Train reward: -182.669, Eval reward: -99.577, TD loss:   5.496, Episode:   97, Epsilon: 0.01
Iteration:   26900, Train reward: -190.464, Eval reward: -99.577, TD loss:   5.205, Episode:   98, Epsilon: 0.01
Iteration:   27000, Train reward: -193.629, Eval reward: -197.762, TD loss:   5.015, Episode:   99, Epsilon: 0.01
Iteration:   27100, Train reward: -193.629, Eval reward: -197.762, TD loss:   5.136, Episode:   99, Epsilon: 0.01
Iteration:   27200, Train reward: -204.550, Eval reward: -197.762, TD loss:   5.191, Episode:  101, Epsilon: 0.01
Iteration:   27300, Train reward: -204.550, Eval reward: -197.762, TD loss:   5.466, Episode:  101, Epsilon: 0.01
Iteration:   27400, Train reward: -202.820, Eval reward: -197.762, TD loss:   4.790, Episode:  102, Epsilon: 0.01
Iteration:   27500, Train reward: -202.820, Eval reward: -197.762, TD loss:   4.978, Episode:  102, Epsilon: 0.01
Iteration:   27600, Train reward: -198.422, Eval reward: -197.762, TD loss:   4.730, Episode:  103, Epsilon: 0.01
Iteration:   27700, Train reward: -197.551, Eval reward: -197.762, TD loss:   4.477, Episode:  104, Epsilon: 0.01
Iteration:   27800, Train reward: -197.551, Eval reward: -197.762, TD loss:   4.909, Episode:  104, Epsilon: 0.01
Iteration:   27900, Train reward: -197.551, Eval reward: -197.762, TD loss:   4.500, Episode:  104, Epsilon: 0.01
Iteration:   28000, Train reward: -197.551, Eval reward: -225.528, TD loss:   4.911, Episode:  104, Epsilon: 0.01
Iteration:   28100, Train reward: -197.551, Eval reward: -225.528, TD loss:   4.213, Episode:  104, Epsilon: 0.01
Iteration:   28200, Train reward: -197.551, Eval reward: -225.528, TD loss:   4.194, Episode:  104, Epsilon: 0.01
Iteration:   28300, Train reward: -198.486, Eval reward: -225.528, TD loss:   4.202, Episode:  105, Epsilon: 0.01
Iteration:   28400, Train reward: -198.486, Eval reward: -225.528, TD loss:   4.363, Episode:  105, Epsilon: 0.01
Iteration:   28500, Train reward: -209.131, Eval reward: -225.528, TD loss:   4.413, Episode:  106, Epsilon: 0.01
Iteration:   28600, Train reward: -187.275, Eval reward: -225.528, TD loss:   3.993, Episode:  108, Epsilon: 0.01
Iteration:   28700, Train reward: -189.831, Eval reward: -225.528, TD loss:   3.169, Episode:  109, Epsilon: 0.01
Iteration:   28800, Train reward: -196.513, Eval reward: -225.528, TD loss:   3.852, Episode:  111, Epsilon: 0.01
Iteration:   28900, Train reward: -196.513, Eval reward: -225.528, TD loss:   3.971, Episode:  111, Epsilon: 0.01
Iteration:   29000, Train reward: -196.513, Eval reward: -100.092, TD loss:   3.974, Episode:  111, Epsilon: 0.01
Iteration:   29100, Train reward: -196.513, Eval reward: -100.092, TD loss:   3.780, Episode:  111, Epsilon: 0.01
Iteration:   29200, Train reward: -186.406, Eval reward: -100.092, TD loss:   3.210, Episode:  112, Epsilon: 0.01
Iteration:   29300, Train reward: -178.930, Eval reward: -100.092, TD loss:   3.215, Episode:  113, Epsilon: 0.01
Iteration:   29400, Train reward: -182.973, Eval reward: -100.092, TD loss:   3.413, Episode:  114, Epsilon: 0.01
Iteration:   29500, Train reward: -178.532, Eval reward: -100.092, TD loss:   3.635, Episode:  115, Epsilon: 0.01
Iteration:   29600, Train reward: -178.532, Eval reward: -100.092, TD loss:   3.216, Episode:  115, Epsilon: 0.01
Iteration:   29700, Train reward: -174.697, Eval reward: -100.092, TD loss:   3.536, Episode:  117, Epsilon: 0.01
Iteration:   29800, Train reward: -174.401, Eval reward: -100.092, TD loss:   3.129, Episode:  118, Epsilon: 0.01
Iteration:   29900, Train reward: -177.984, Eval reward: -100.092, TD loss:   3.441, Episode:  119, Epsilon: 0.01
Iteration:   30000, Train reward: -172.765, Eval reward: -312.718, TD loss:   3.282, Episode:  120, Epsilon: 0.01
Iteration:   30100, Train reward: -172.765, Eval reward: -312.718, TD loss:   3.108, Episode:  120, Epsilon: 0.01
Iteration:   30200, Train reward: -172.765, Eval reward: -312.718, TD loss:   2.853, Episode:  120, Epsilon: 0.01
Iteration:   30300, Train reward: -182.806, Eval reward: -312.718, TD loss:   2.841, Episode:  121, Epsilon: 0.01
Iteration:   30400, Train reward: -200.706, Eval reward: -312.718, TD loss:   2.736, Episode:  122, Epsilon: 0.01
Iteration:   30500, Train reward: -205.465, Eval reward: -312.718, TD loss:   3.301, Episode:  123, Epsilon: 0.01
Iteration:   30600, Train reward: -210.112, Eval reward: -312.718, TD loss:   2.865, Episode:  124, Epsilon: 0.01
Iteration:   30700, Train reward: -195.807, Eval reward: -312.718, TD loss:   2.747, Episode:  125, Epsilon: 0.01
Iteration:   30800, Train reward: -195.807, Eval reward: -312.718, TD loss:   2.711, Episode:  125, Epsilon: 0.01
Iteration:   30900, Train reward: -194.671, Eval reward: -312.718, TD loss:   2.482, Episode:  126, Epsilon: 0.01
Iteration:   31000, Train reward: -201.174, Eval reward: -221.640, TD loss:   2.556, Episode:  127, Epsilon: 0.01
Iteration:   31100, Train reward: -206.357, Eval reward: -221.640, TD loss:   2.796, Episode:  128, Epsilon: 0.01
Iteration:   31200, Train reward: -206.357, Eval reward: -221.640, TD loss:   2.586, Episode:  128, Epsilon: 0.01
Iteration:   31300, Train reward: -202.406, Eval reward: -221.640, TD loss:   2.789, Episode:  129, Epsilon: 0.01
Iteration:   31400, Train reward: -194.934, Eval reward: -221.640, TD loss:   2.589, Episode:  130, Epsilon: 0.01
Iteration:   31500, Train reward: -197.037, Eval reward: -221.640, TD loss:   2.379, Episode:  131, Epsilon: 0.01
Iteration:   31600, Train reward: -197.037, Eval reward: -221.640, TD loss:   2.770, Episode:  131, Epsilon: 0.01
Iteration:   31700, Train reward: -213.950, Eval reward: -221.640, TD loss:   2.791, Episode:  133, Epsilon: 0.01
Iteration:   31800, Train reward: -213.950, Eval reward: -221.640, TD loss:   2.764, Episode:  133, Epsilon: 0.01
Iteration:   31900, Train reward: -213.950, Eval reward: -221.640, TD loss:   2.503, Episode:  133, Epsilon: 0.01
Iteration:   32000, Train reward: -213.950, Eval reward: -135.180, TD loss:   2.678, Episode:  133, Epsilon: 0.01
Iteration:   32100, Train reward: -218.119, Eval reward: -135.180, TD loss:   2.912, Episode:  134, Epsilon: 0.01
Iteration:   32200, Train reward: -218.119, Eval reward: -135.180, TD loss:   2.517, Episode:  134, Epsilon: 0.01
Iteration:   32300, Train reward: -212.412, Eval reward: -135.180, TD loss:   2.545, Episode:  135, Epsilon: 0.01
Iteration:   32400, Train reward: -222.900, Eval reward: -135.180, TD loss:   2.746, Episode:  137, Epsilon: 0.01
Iteration:   32500, Train reward: -225.310, Eval reward: -135.180, TD loss:   2.449, Episode:  138, Epsilon: 0.01
Iteration:   32600, Train reward: -230.323, Eval reward: -135.180, TD loss:   2.739, Episode:  139, Epsilon: 0.01
Iteration:   32700, Train reward: -235.023, Eval reward: -135.180, TD loss:   2.871, Episode:  140, Epsilon: 0.01
Iteration:   32800, Train reward: -222.843, Eval reward: -135.180, TD loss:   2.662, Episode:  141, Epsilon: 0.01
Iteration:   32900, Train reward: -225.496, Eval reward: -135.180, TD loss:   2.652, Episode:  142, Epsilon: 0.01
Iteration:   33000, Train reward: -224.102, Eval reward: -187.161, TD loss:   3.062, Episode:  143, Epsilon: 0.01
Iteration:   33100, Train reward: -224.102, Eval reward: -187.161, TD loss:   3.347, Episode:  143, Epsilon: 0.01
Iteration:   33200, Train reward: -219.300, Eval reward: -187.161, TD loss:   2.797, Episode:  144, Epsilon: 0.01
Iteration:   33300, Train reward: -214.040, Eval reward: -187.161, TD loss:   2.800, Episode:  146, Epsilon: 0.01
Iteration:   33400, Train reward: -214.685, Eval reward: -187.161, TD loss:   2.727, Episode:  147, Epsilon: 0.01
Iteration:   33500, Train reward: -209.388, Eval reward: -187.161, TD loss:   2.781, Episode:  148, Epsilon: 0.01
Iteration:   33600, Train reward: -214.853, Eval reward: -187.161, TD loss:   3.065, Episode:  149, Epsilon: 0.01
Iteration:   33700, Train reward: -214.853, Eval reward: -187.161, TD loss:   2.973, Episode:  149, Epsilon: 0.01
Iteration:   33800, Train reward: -212.188, Eval reward: -187.161, TD loss:   2.641, Episode:  150, Epsilon: 0.01
Iteration:   33900, Train reward: -222.093, Eval reward: -187.161, TD loss:   3.021, Episode:  152, Epsilon: 0.01
Iteration:   34000, Train reward: -229.760, Eval reward: -191.738, TD loss:   3.058, Episode:  153, Epsilon: 0.01
Iteration:   34100, Train reward: -225.105, Eval reward: -191.738, TD loss:   3.074, Episode:  154, Epsilon: 0.01
Iteration:   34200, Train reward: -256.907, Eval reward: -191.738, TD loss:   2.913, Episode:  155, Epsilon: 0.01
Iteration:   34300, Train reward: -268.196, Eval reward: -191.738, TD loss:   3.026, Episode:  156, Epsilon: 0.01
Iteration:   34400, Train reward: -257.302, Eval reward: -191.738, TD loss:   2.749, Episode:  157, Epsilon: 0.01
Iteration:   34500, Train reward: -239.290, Eval reward: -191.738, TD loss:   2.789, Episode:  159, Epsilon: 0.01
Iteration:   34600, Train reward: -239.521, Eval reward: -191.738, TD loss:   3.061, Episode:  160, Epsilon: 0.01
Iteration:   34700, Train reward: -239.521, Eval reward: -191.738, TD loss:   2.959, Episode:  160, Epsilon: 0.01
Iteration:   34800, Train reward: -228.545, Eval reward: -191.738, TD loss:   3.077, Episode:  161, Epsilon: 0.01
Iteration:   34900, Train reward: -218.215, Eval reward: -191.738, TD loss:   2.803, Episode:  162, Epsilon: 0.01
Iteration:   35000, Train reward: -225.273, Eval reward: -168.393, TD loss:   2.773, Episode:  163, Epsilon: 0.01
Iteration:   35100, Train reward: -222.396, Eval reward: -168.393, TD loss:   3.264, Episode:  164, Epsilon: 0.01
Iteration:   35200, Train reward: -245.743, Eval reward: -168.393, TD loss:   3.031, Episode:  166, Epsilon: 0.01
Iteration:   35300, Train reward: -245.743, Eval reward: -168.393, TD loss:   3.318, Episode:  166, Epsilon: 0.01
Iteration:   35400, Train reward: -229.877, Eval reward: -168.393, TD loss:   2.810, Episode:  167, Epsilon: 0.01
Iteration:   35500, Train reward: -227.609, Eval reward: -168.393, TD loss:   3.374, Episode:  168, Epsilon: 0.01
Iteration:   35600, Train reward: -237.018, Eval reward: -168.393, TD loss:   3.380, Episode:  170, Epsilon: 0.01
Iteration:   35700, Train reward: -230.483, Eval reward: -168.393, TD loss:   2.940, Episode:  171, Epsilon: 0.01
Iteration:   35800, Train reward: -233.788, Eval reward: -168.393, TD loss:   2.976, Episode:  172, Epsilon: 0.01
Iteration:   35900, Train reward: -236.937, Eval reward: -168.393, TD loss:   3.294, Episode:  173, Epsilon: 0.01
Iteration:   36000, Train reward: -237.047, Eval reward: -116.231, TD loss:   3.153, Episode:  174, Epsilon: 0.01
Iteration:   36100, Train reward: -211.821, Eval reward: -116.231, TD loss:   3.461, Episode:  175, Epsilon: 0.01
Iteration:   36200, Train reward: -214.198, Eval reward: -116.231, TD loss:   3.042, Episode:  176, Epsilon: 0.01
Iteration:   36300, Train reward: -222.444, Eval reward: -116.231, TD loss:   3.310, Episode:  177, Epsilon: 0.01
Iteration:   36400, Train reward: -233.123, Eval reward: -116.231, TD loss:   3.168, Episode:  178, Epsilon: 0.01
Iteration:   36500, Train reward: -239.294, Eval reward: -116.231, TD loss:   3.269, Episode:  179, Epsilon: 0.01
Iteration:   36600, Train reward: -244.414, Eval reward: -116.231, TD loss:   3.204, Episode:  180, Epsilon: 0.01
Iteration:   36700, Train reward: -257.349, Eval reward: -116.231, TD loss:   3.162, Episode:  181, Epsilon: 0.01
Iteration:   36800, Train reward: -266.564, Eval reward: -116.231, TD loss:   3.199, Episode:  182, Epsilon: 0.01
Iteration:   36900, Train reward: -276.417, Eval reward: -116.231, TD loss:   3.413, Episode:  184, Epsilon: 0.01
Iteration:   37000, Train reward: -276.417, Eval reward: -165.991, TD loss:   3.292, Episode:  184, Epsilon: 0.01
Iteration:   37100, Train reward: -254.917, Eval reward: -165.991, TD loss:   4.347, Episode:  185, Epsilon: 0.01
Iteration:   37200, Train reward: -258.294, Eval reward: -165.991, TD loss:   3.472, Episode:  186, Epsilon: 0.01
Iteration:   37300, Train reward: -277.939, Eval reward: -165.991, TD loss:   3.471, Episode:  187, Epsilon: 0.01
Iteration:   37400, Train reward: -288.428, Eval reward: -165.991, TD loss:   3.845, Episode:  188, Epsilon: 0.01
Iteration:   37500, Train reward: -288.428, Eval reward: -165.991, TD loss:   3.630, Episode:  188, Epsilon: 0.01
Iteration:   37600, Train reward: -272.697, Eval reward: -165.991, TD loss:   3.900, Episode:  190, Epsilon: 0.01
Iteration:   37700, Train reward: -272.697, Eval reward: -165.991, TD loss:   3.716, Episode:  190, Epsilon: 0.01
Iteration:   37800, Train reward: -296.559, Eval reward: -165.991, TD loss:   3.446, Episode:  191, Epsilon: 0.01
Iteration:   37900, Train reward: -299.552, Eval reward: -165.991, TD loss:   3.804, Episode:  192, Epsilon: 0.01
Iteration:   38000, Train reward: -280.929, Eval reward: -453.939, TD loss:   3.713, Episode:  193, Epsilon: 0.01
Iteration:   38100, Train reward: -289.174, Eval reward: -453.939, TD loss:   3.672, Episode:  194, Epsilon: 0.01
Iteration:   38200, Train reward: -285.768, Eval reward: -453.939, TD loss:   3.962, Episode:  195, Epsilon: 0.01
Iteration:   38300, Train reward: -266.561, Eval reward: -453.939, TD loss:   3.954, Episode:  197, Epsilon: 0.01
Iteration:   38400, Train reward: -266.561, Eval reward: -453.939, TD loss:   4.134, Episode:  197, Epsilon: 0.01
Iteration:   38500, Train reward: -278.717, Eval reward: -453.939, TD loss:   3.719, Episode:  198, Epsilon: 0.01
Iteration:   38600, Train reward: -284.263, Eval reward: -453.939, TD loss:   4.128, Episode:  199, Epsilon: 0.01
Iteration:   38700, Train reward: -281.413, Eval reward: -453.939, TD loss:   3.734, Episode:  200, Epsilon: 0.01
Iteration:   38800, Train reward: -275.427, Eval reward: -453.939, TD loss:   3.540, Episode:  201, Epsilon: 0.01
Iteration:   38900, Train reward: -275.427, Eval reward: -453.939, TD loss:   3.735, Episode:  201, Epsilon: 0.01
Iteration:   39000, Train reward: -263.960, Eval reward: -357.871, TD loss:   4.025, Episode:  202, Epsilon: 0.01
Iteration:   39100, Train reward: -255.290, Eval reward: -357.871, TD loss:   3.830, Episode:  203, Epsilon: 0.01
Iteration:   39200, Train reward: -246.114, Eval reward: -357.871, TD loss:   3.811, Episode:  204, Epsilon: 0.01
Iteration:   39300, Train reward: -253.381, Eval reward: -357.871, TD loss:   3.625, Episode:  205, Epsilon: 0.01
Iteration:   39400, Train reward: -261.323, Eval reward: -357.871, TD loss:   4.011, Episode:  206, Epsilon: 0.01
Iteration:   39500, Train reward: -236.914, Eval reward: -357.871, TD loss:   3.899, Episode:  207, Epsilon: 0.01
Iteration:   39600, Train reward: -224.929, Eval reward: -357.871, TD loss:   3.864, Episode:  208, Epsilon: 0.01
Iteration:   39700, Train reward: -227.089, Eval reward: -357.871, TD loss:   3.945, Episode:  209, Epsilon: 0.01
Iteration:   39800, Train reward: -240.685, Eval reward: -357.871, TD loss:   4.019, Episode:  210, Epsilon: 0.01
Iteration:   39900, Train reward: -222.761, Eval reward: -357.871, TD loss:   3.666, Episode:  212, Epsilon: 0.01
Iteration:   40000, Train reward: -242.485, Eval reward: -401.274, TD loss:   3.911, Episode:  213, Epsilon: 0.01
Iteration:   40100, Train reward: -232.862, Eval reward: -401.274, TD loss:   4.114, Episode:  214, Epsilon: 0.01
Iteration:   40200, Train reward: -248.015, Eval reward: -401.274, TD loss:   4.502, Episode:  215, Epsilon: 0.01
Iteration:   40300, Train reward: -270.020, Eval reward: -401.274, TD loss:   4.200, Episode:  216, Epsilon: 0.01
Iteration:   40400, Train reward: -284.057, Eval reward: -401.274, TD loss:   4.686, Episode:  217, Epsilon: 0.01
Iteration:   40500, Train reward: -276.966, Eval reward: -401.274, TD loss:   4.114, Episode:  219, Epsilon: 0.01
Iteration:   40600, Train reward: -277.436, Eval reward: -401.274, TD loss:   4.674, Episode:  220, Epsilon: 0.01
Iteration:   40700, Train reward: -279.885, Eval reward: -401.274, TD loss:   4.159, Episode:  221, Epsilon: 0.01
Iteration:   40800, Train reward: -293.503, Eval reward: -401.274, TD loss:   4.064, Episode:  223, Epsilon: 0.01
Iteration:   40900, Train reward: -299.782, Eval reward: -401.274, TD loss:   4.655, Episode:  224, Epsilon: 0.01
Iteration:   41000, Train reward: -312.569, Eval reward: -306.268, TD loss:   4.474, Episode:  225, Epsilon: 0.01
Iteration:   41100, Train reward: -315.062, Eval reward: -306.268, TD loss:   5.319, Episode:  226, Epsilon: 0.01
Iteration:   41200, Train reward: -342.576, Eval reward: -306.268, TD loss:   4.680, Episode:  227, Epsilon: 0.01
Iteration:   41300, Train reward: -357.241, Eval reward: -306.268, TD loss:   4.961, Episode:  228, Epsilon: 0.01
Iteration:   41400, Train reward: -358.563, Eval reward: -306.268, TD loss:   4.748, Episode:  230, Epsilon: 0.01
Iteration:   41500, Train reward: -364.703, Eval reward: -306.268, TD loss:   5.068, Episode:  231, Epsilon: 0.01
Iteration:   41600, Train reward: -368.478, Eval reward: -306.268, TD loss:   5.203, Episode:  232, Epsilon: 0.01
Iteration:   41700, Train reward: -383.294, Eval reward: -306.268, TD loss:   5.050, Episode:  234, Epsilon: 0.01
Iteration:   41800, Train reward: -389.431, Eval reward: -306.268, TD loss:   4.878, Episode:  235, Epsilon: 0.01
Iteration:   41900, Train reward: -368.799, Eval reward: -306.268, TD loss:   5.257, Episode:  236, Epsilon: 0.01
Iteration:   42000, Train reward: -344.639, Eval reward: -427.361, TD loss:   4.394, Episode:  238, Epsilon: 0.01
Iteration:   42100, Train reward: -351.107, Eval reward: -427.361, TD loss:   5.335, Episode:  239, Epsilon: 0.01
Iteration:   42200, Train reward: -364.048, Eval reward: -427.361, TD loss:   5.699, Episode:  240, Epsilon: 0.01
Iteration:   42300, Train reward: -366.451, Eval reward: -427.361, TD loss:   5.156, Episode:  241, Epsilon: 0.01
Iteration:   42400, Train reward: -369.502, Eval reward: -427.361, TD loss:   5.660, Episode:  242, Epsilon: 0.01
Iteration:   42500, Train reward: -366.314, Eval reward: -427.361, TD loss:   5.303, Episode:  243, Epsilon: 0.01
Iteration:   42600, Train reward: -357.010, Eval reward: -427.361, TD loss:   5.285, Episode:  244, Epsilon: 0.01
Iteration:   42700, Train reward: -357.010, Eval reward: -427.361, TD loss:   5.170, Episode:  244, Epsilon: 0.01
Iteration:   42800, Train reward: -349.386, Eval reward: -427.361, TD loss:   5.652, Episode:  245, Epsilon: 0.01
Iteration:   42900, Train reward: -308.457, Eval reward: -427.361, TD loss:   5.535, Episode:  247, Epsilon: 0.01
Iteration:   43000, Train reward: -313.045, Eval reward: -359.087, TD loss:   5.359, Episode:  248, Epsilon: 0.01
Iteration:   43100, Train reward: -334.788, Eval reward: -359.087, TD loss:   5.455, Episode:  249, Epsilon: 0.01
Iteration:   43200, Train reward: -330.933, Eval reward: -359.087, TD loss:   5.525, Episode:  250, Epsilon: 0.01
Iteration:   43300, Train reward: -328.438, Eval reward: -359.087, TD loss:   5.307, Episode:  251, Epsilon: 0.01
Iteration:   43400, Train reward: -281.638, Eval reward: -359.087, TD loss:   5.463, Episode:  253, Epsilon: 0.01
Iteration:   43500, Train reward: -277.086, Eval reward: -359.087, TD loss:   5.306, Episode:  254, Epsilon: 0.01
Iteration:   43600, Train reward: -275.628, Eval reward: -359.087, TD loss:   5.557, Episode:  255, Epsilon: 0.01
Iteration:   43700, Train reward: -284.545, Eval reward: -359.087, TD loss:   5.606, Episode:  256, Epsilon: 0.01
Iteration:   43800, Train reward: -299.581, Eval reward: -359.087, TD loss:   5.047, Episode:  257, Epsilon: 0.01
Iteration:   43900, Train reward: -293.850, Eval reward: -359.087, TD loss:   5.076, Episode:  258, Epsilon: 0.01
Iteration:   44000, Train reward: -287.471, Eval reward: -216.795, TD loss:   4.734, Episode:  259, Epsilon: 0.01
Iteration:   44100, Train reward: -282.661, Eval reward: -216.795, TD loss:   5.448, Episode:  260, Epsilon: 0.01
Iteration:   44200, Train reward: -292.084, Eval reward: -216.795, TD loss:   5.526, Episode:  261, Epsilon: 0.01
Iteration:   44300, Train reward: -296.450, Eval reward: -216.795, TD loss:   6.185, Episode:  262, Epsilon: 0.01
Iteration:   44400, Train reward: -299.257, Eval reward: -216.795, TD loss:   5.487, Episode:  263, Epsilon: 0.01
Iteration:   44500, Train reward: -322.603, Eval reward: -216.795, TD loss:   5.945, Episode:  265, Epsilon: 0.01
Iteration:   44600, Train reward: -335.835, Eval reward: -216.795, TD loss:   5.459, Episode:  266, Epsilon: 0.01
Iteration:   44700, Train reward: -357.987, Eval reward: -216.795, TD loss:   5.767, Episode:  267, Epsilon: 0.01
Iteration:   44800, Train reward: -346.959, Eval reward: -216.795, TD loss:   5.374, Episode:  268, Epsilon: 0.01
Iteration:   44900, Train reward: -329.073, Eval reward: -216.795, TD loss:   4.864, Episode:  269, Epsilon: 0.01
Iteration:   45000, Train reward: -314.847, Eval reward: -329.898, TD loss:   5.666, Episode:  270, Epsilon: 0.01
Iteration:   45100, Train reward: -305.755, Eval reward: -329.898, TD loss:   5.053, Episode:  271, Epsilon: 0.01
Iteration:   45200, Train reward: -317.921, Eval reward: -329.898, TD loss:   5.163, Episode:  272, Epsilon: 0.01
Iteration:   45300, Train reward: -339.024, Eval reward: -329.898, TD loss:   5.943, Episode:  273, Epsilon: 0.01
Iteration:   45400, Train reward: -340.499, Eval reward: -329.898, TD loss:   5.564, Episode:  274, Epsilon: 0.01
Iteration:   45500, Train reward: -325.185, Eval reward: -329.898, TD loss:   5.822, Episode:  275, Epsilon: 0.01
Iteration:   45600, Train reward: -336.437, Eval reward: -329.898, TD loss:   5.126, Episode:  277, Epsilon: 0.01
Iteration:   45700, Train reward: -342.938, Eval reward: -329.898, TD loss:   5.421, Episode:  278, Epsilon: 0.01
Iteration:   45800, Train reward: -348.247, Eval reward: -329.898, TD loss:   5.861, Episode:  279, Epsilon: 0.01
Iteration:   45900, Train reward: -333.466, Eval reward: -329.898, TD loss:   6.052, Episode:  280, Epsilon: 0.01
Iteration:   46000, Train reward: -329.665, Eval reward: -376.814, TD loss:   5.462, Episode:  281, Epsilon: 0.01
Iteration:   46100, Train reward: -335.210, Eval reward: -376.814, TD loss:   6.645, Episode:  282, Epsilon: 0.01
Iteration:   46200, Train reward: -329.619, Eval reward: -376.814, TD loss:   6.944, Episode:  284, Epsilon: 0.01
Iteration:   46300, Train reward: -326.912, Eval reward: -376.814, TD loss:   5.924, Episode:  285, Epsilon: 0.01
Iteration:   46400, Train reward: -327.307, Eval reward: -376.814, TD loss:   5.286, Episode:  286, Epsilon: 0.01
Iteration:   46500, Train reward: -327.307, Eval reward: -376.814, TD loss:   7.587, Episode:  286, Epsilon: 0.01
Iteration:   46600, Train reward: -326.010, Eval reward: -376.814, TD loss:   6.531, Episode:  288, Epsilon: 0.01
Iteration:   46700, Train reward: -326.010, Eval reward: -376.814, TD loss:   6.105, Episode:  288, Epsilon: 0.01
Iteration:   46800, Train reward: -336.525, Eval reward: -376.814, TD loss:   5.606, Episode:  289, Epsilon: 0.01
Iteration:   46900, Train reward: -346.239, Eval reward: -376.814, TD loss:   6.465, Episode:  290, Epsilon: 0.01
Iteration:   47000, Train reward: -350.199, Eval reward: -355.828, TD loss:   5.838, Episode:  291, Epsilon: 0.01
Iteration:   47100, Train reward: -357.219, Eval reward: -355.828, TD loss:   6.328, Episode:  292, Epsilon: 0.01
Iteration:   47200, Train reward: -350.639, Eval reward: -355.828, TD loss:   5.687, Episode:  293, Epsilon: 0.01
Iteration:   47300, Train reward: -351.841, Eval reward: -355.828, TD loss:   6.261, Episode:  294, Epsilon: 0.01
Iteration:   47400, Train reward: -360.720, Eval reward: -355.828, TD loss:   6.225, Episode:  295, Epsilon: 0.01
Iteration:   47500, Train reward: -347.100, Eval reward: -355.828, TD loss:   6.577, Episode:  297, Epsilon: 0.01
Iteration:   47600, Train reward: -347.100, Eval reward: -355.828, TD loss:   6.730, Episode:  297, Epsilon: 0.01
Iteration:   47700, Train reward: -336.407, Eval reward: -355.828, TD loss:   7.402, Episode:  298, Epsilon: 0.01
Iteration:   47800, Train reward: -350.052, Eval reward: -355.828, TD loss:   6.768, Episode:  300, Epsilon: 0.01
Iteration:   47900, Train reward: -350.052, Eval reward: -355.828, TD loss:   6.663, Episode:  300, Epsilon: 0.01
Iteration:   48000, Train reward: -347.475, Eval reward: -328.940, TD loss:   7.247, Episode:  301, Epsilon: 0.01
Iteration:   48100, Train reward: -346.088, Eval reward: -328.940, TD loss:   6.775, Episode:  302, Epsilon: 0.01
Iteration:   48200, Train reward: -338.707, Eval reward: -328.940, TD loss:   6.802, Episode:  303, Epsilon: 0.01
Iteration:   48300, Train reward: -347.956, Eval reward: -328.940, TD loss:   6.608, Episode:  304, Epsilon: 0.01
Iteration:   48400, Train reward: -347.956, Eval reward: -328.940, TD loss:   7.128, Episode:  304, Epsilon: 0.01
Iteration:   48500, Train reward: -347.004, Eval reward: -328.940, TD loss:   7.353, Episode:  306, Epsilon: 0.01
Iteration:   48600, Train reward: -347.004, Eval reward: -328.940, TD loss:   6.550, Episode:  306, Epsilon: 0.01
Iteration:   48700, Train reward: -347.125, Eval reward: -328.940, TD loss:   6.803, Episode:  307, Epsilon: 0.01
Iteration:   48800, Train reward: -356.377, Eval reward: -328.940, TD loss:   7.240, Episode:  309, Epsilon: 0.01
Iteration:   48900, Train reward: -364.383, Eval reward: -328.940, TD loss:   6.887, Episode:  310, Epsilon: 0.01
Iteration:   49000, Train reward: -368.762, Eval reward: -380.309, TD loss:   7.491, Episode:  311, Epsilon: 0.01
Iteration:   49100, Train reward: -363.451, Eval reward: -380.309, TD loss:   7.348, Episode:  312, Epsilon: 0.01
Iteration:   49200, Train reward: -372.393, Eval reward: -380.309, TD loss:   7.539, Episode:  313, Epsilon: 0.01
Iteration:   49300, Train reward: -376.183, Eval reward: -380.309, TD loss:   7.373, Episode:  314, Epsilon: 0.01
Iteration:   49400, Train reward: -381.659, Eval reward: -380.309, TD loss:   7.777, Episode:  315, Epsilon: 0.01
Iteration:   49500, Train reward: -373.284, Eval reward: -380.309, TD loss:   7.719, Episode:  316, Epsilon: 0.01
Iteration:   49600, Train reward: -373.284, Eval reward: -380.309, TD loss:   7.461, Episode:  316, Epsilon: 0.01
Iteration:   49700, Train reward: -376.927, Eval reward: -380.309, TD loss:   6.569, Episode:  317, Epsilon: 0.01
Iteration:   49800, Train reward: -394.153, Eval reward: -380.309, TD loss:   7.185, Episode:  319, Epsilon: 0.01
Iteration:   49900, Train reward: -402.514, Eval reward: -380.309, TD loss:   7.807, Episode:  320, Epsilon: 0.01
Iteration:   50000, Train reward: -414.596, Eval reward: -350.467, TD loss:   7.532, Episode:  321, Epsilon: 0.01
Iteration:   50100, Train reward: -412.360, Eval reward: -350.467, TD loss:   8.060, Episode:  322, Epsilon: 0.01
Iteration:   50200, Train reward: -424.141, Eval reward: -350.467, TD loss:   7.484, Episode:  323, Epsilon: 0.01
Iteration:   50300, Train reward: -420.004, Eval reward: -350.467, TD loss:   6.626, Episode:  324, Epsilon: 0.01
Iteration:   50400, Train reward: -421.130, Eval reward: -350.467, TD loss:   7.972, Episode:  325, Epsilon: 0.01
Iteration:   50500, Train reward: -414.103, Eval reward: -350.467, TD loss:   7.442, Episode:  326, Epsilon: 0.01
Iteration:   50600, Train reward: -414.103, Eval reward: -350.467, TD loss:   7.012, Episode:  326, Epsilon: 0.01
Iteration:   50700, Train reward: -412.233, Eval reward: -350.467, TD loss:   6.917, Episode:  327, Epsilon: 0.01
Iteration:   50800, Train reward: -400.885, Eval reward: -350.467, TD loss:   7.094, Episode:  328, Epsilon: 0.01
Iteration:   50900, Train reward: -391.874, Eval reward: -350.467, TD loss:   7.342, Episode:  329, Epsilon: 0.01
Iteration:   51000, Train reward: -382.898, Eval reward: -368.746, TD loss:   7.181, Episode:  330, Epsilon: 0.01
Iteration:   51100, Train reward: -380.665, Eval reward: -368.746, TD loss:   6.903, Episode:  331, Epsilon: 0.01
Iteration:   51200, Train reward: -388.292, Eval reward: -368.746, TD loss:   7.625, Episode:  332, Epsilon: 0.01
Iteration:   51300, Train reward: -390.830, Eval reward: -368.746, TD loss:   7.401, Episode:  333, Epsilon: 0.01
Iteration:   51400, Train reward: -385.849, Eval reward: -368.746, TD loss:   7.022, Episode:  334, Epsilon: 0.01
Iteration:   51500, Train reward: -385.849, Eval reward: -368.746, TD loss:   7.495, Episode:  334, Epsilon: 0.01
Iteration:   51600, Train reward: -375.347, Eval reward: -368.746, TD loss:   7.431, Episode:  335, Epsilon: 0.01
Iteration:   51700, Train reward: -386.677, Eval reward: -368.746, TD loss:   7.298, Episode:  336, Epsilon: 0.01
Iteration:   51800, Train reward: -379.777, Eval reward: -368.746, TD loss:   7.813, Episode:  337, Epsilon: 0.01
Iteration:   51900, Train reward: -370.072, Eval reward: -368.746, TD loss:   7.285, Episode:  338, Epsilon: 0.01
Iteration:   52000, Train reward: -371.927, Eval reward: -367.235, TD loss:   7.788, Episode:  339, Epsilon: 0.01
Iteration:   52100, Train reward: -357.910, Eval reward: -367.235, TD loss:   7.150, Episode:  340, Epsilon: 0.01
Iteration:   52200, Train reward: -347.287, Eval reward: -367.235, TD loss:   7.712, Episode:  341, Epsilon: 0.01
Iteration:   52300, Train reward: -346.998, Eval reward: -367.235, TD loss:   7.762, Episode:  342, Epsilon: 0.01
Iteration:   52400, Train reward: -341.025, Eval reward: -367.235, TD loss:   7.216, Episode:  343, Epsilon: 0.01
Iteration:   52500, Train reward: -343.299, Eval reward: -367.235, TD loss:   8.373, Episode:  344, Epsilon: 0.01
Iteration:   52600, Train reward: -345.867, Eval reward: -367.235, TD loss:   7.619, Episode:  345, Epsilon: 0.01
Iteration:   52700, Train reward: -352.601, Eval reward: -367.235, TD loss:   7.366, Episode:  346, Epsilon: 0.01
Iteration:   52800, Train reward: -352.601, Eval reward: -367.235, TD loss:   7.945, Episode:  346, Epsilon: 0.01
Iteration:   52900, Train reward: -355.471, Eval reward: -367.235, TD loss:   7.667, Episode:  348, Epsilon: 0.01
Iteration:   53000, Train reward: -365.190, Eval reward: -411.904, TD loss:   7.627, Episode:  349, Epsilon: 0.01
Iteration:   53100, Train reward: -375.540, Eval reward: -411.904, TD loss:   7.922, Episode:  350, Epsilon: 0.01
Iteration:   53200, Train reward: -380.672, Eval reward: -411.904, TD loss:   8.106, Episode:  351, Epsilon: 0.01
Iteration:   53300, Train reward: -380.529, Eval reward: -411.904, TD loss:   8.063, Episode:  352, Epsilon: 0.01
Iteration:   53400, Train reward: -373.794, Eval reward: -411.904, TD loss:   8.059, Episode:  353, Epsilon: 0.01
Iteration:   53500, Train reward: -367.517, Eval reward: -411.904, TD loss:   7.950, Episode:  354, Epsilon: 0.01
Iteration:   53600, Train reward: -379.534, Eval reward: -411.904, TD loss:   8.305, Episode:  355, Epsilon: 0.01
Iteration:   53700, Train reward: -379.875, Eval reward: -411.904, TD loss:   7.500, Episode:  356, Epsilon: 0.01
Iteration:   53800, Train reward: -394.222, Eval reward: -411.904, TD loss:   7.880, Episode:  357, Epsilon: 0.01
Iteration:   53900, Train reward: -402.436, Eval reward: -411.904, TD loss:   7.482, Episode:  358, Epsilon: 0.01
Iteration:   54000, Train reward: -395.060, Eval reward: -435.769, TD loss:   8.235, Episode:  359, Epsilon: 0.01
Iteration:   54100, Train reward: -406.737, Eval reward: -435.769, TD loss:   8.616, Episode:  360, Epsilon: 0.01
Iteration:   54200, Train reward: -406.737, Eval reward: -435.769, TD loss:   8.154, Episode:  360, Epsilon: 0.01
Iteration:   54300, Train reward: -404.186, Eval reward: -435.769, TD loss:   7.287, Episode:  362, Epsilon: 0.01
Iteration:   54400, Train reward: -404.186, Eval reward: -435.769, TD loss:   7.793, Episode:  362, Epsilon: 0.01
Iteration:   54500, Train reward: -407.099, Eval reward: -435.769, TD loss:   8.072, Episode:  363, Epsilon: 0.01
Iteration:   54600, Train reward: -407.518, Eval reward: -435.769, TD loss:   7.672, Episode:  364, Epsilon: 0.01
Iteration:   54700, Train reward: -413.086, Eval reward: -435.769, TD loss:   7.829, Episode:  365, Epsilon: 0.01
Iteration:   54800, Train reward: -403.122, Eval reward: -435.769, TD loss:   8.087, Episode:  366, Epsilon: 0.01
Iteration:   54900, Train reward: -419.237, Eval reward: -435.769, TD loss:   8.272, Episode:  367, Epsilon: 0.01
Iteration:   55000, Train reward: -431.345, Eval reward: -350.248, TD loss:   7.507, Episode:  368, Epsilon: 0.01
Iteration:   55100, Train reward: -424.800, Eval reward: -350.248, TD loss:   7.561, Episode:  369, Epsilon: 0.01
Iteration:   55200, Train reward: -426.699, Eval reward: -350.248, TD loss:   7.819, Episode:  370, Epsilon: 0.01
Iteration:   55300, Train reward: -433.173, Eval reward: -350.248, TD loss:   7.219, Episode:  371, Epsilon: 0.01
Iteration:   55400, Train reward: -432.729, Eval reward: -350.248, TD loss:   8.593, Episode:  372, Epsilon: 0.01
Iteration:   55500, Train reward: -438.754, Eval reward: -350.248, TD loss:   8.093, Episode:  373, Epsilon: 0.01
Iteration:   55600, Train reward: -445.185, Eval reward: -350.248, TD loss:   8.793, Episode:  374, Epsilon: 0.01
Iteration:   55700, Train reward: -443.940, Eval reward: -350.248, TD loss:   7.480, Episode:  375, Epsilon: 0.01
Iteration:   55800, Train reward: -449.234, Eval reward: -350.248, TD loss:   7.319, Episode:  376, Epsilon: 0.01
Iteration:   55900, Train reward: -445.583, Eval reward: -350.248, TD loss:   8.596, Episode:  377, Epsilon: 0.01
Iteration:   56000, Train reward: -448.614, Eval reward: -416.994, TD loss:   8.038, Episode:  378, Epsilon: 0.01
Iteration:   56100, Train reward: -456.626, Eval reward: -416.994, TD loss:   8.174, Episode:  379, Epsilon: 0.01
Iteration:   56200, Train reward: -456.626, Eval reward: -416.994, TD loss:   7.812, Episode:  379, Epsilon: 0.01
Iteration:   56300, Train reward: -448.323, Eval reward: -416.994, TD loss:   7.481, Episode:  380, Epsilon: 0.01
Iteration:   56400, Train reward: -460.212, Eval reward: -416.994, TD loss:   6.999, Episode:  381, Epsilon: 0.01
Iteration:   56500, Train reward: -470.845, Eval reward: -416.994, TD loss:   7.752, Episode:  382, Epsilon: 0.01
Iteration:   56600, Train reward: -473.225, Eval reward: -416.994, TD loss:   8.122, Episode:  383, Epsilon: 0.01
Iteration:   56700, Train reward: -477.273, Eval reward: -416.994, TD loss:   7.510, Episode:  384, Epsilon: 0.01
Iteration:   56800, Train reward: -466.480, Eval reward: -416.994, TD loss:   7.389, Episode:  385, Epsilon: 0.01
Iteration:   56900, Train reward: -469.056, Eval reward: -416.994, TD loss:   8.064, Episode:  386, Epsilon: 0.01
Iteration:   57000, Train reward: -467.466, Eval reward: -444.021, TD loss:   8.187, Episode:  387, Epsilon: 0.01
Iteration:   57100, Train reward: -465.177, Eval reward: -444.021, TD loss:   7.092, Episode:  388, Epsilon: 0.01
Iteration:   57200, Train reward: -469.010, Eval reward: -444.021, TD loss:   7.621, Episode:  389, Epsilon: 0.01
Iteration:   57300, Train reward: -469.010, Eval reward: -444.021, TD loss:   7.476, Episode:  389, Epsilon: 0.01
Iteration:   57400, Train reward: -466.928, Eval reward: -444.021, TD loss:   8.131, Episode:  390, Epsilon: 0.01
Iteration:   57500, Train reward: -448.123, Eval reward: -444.021, TD loss:   8.145, Episode:  391, Epsilon: 0.01
Iteration:   57600, Train reward: -449.827, Eval reward: -444.021, TD loss:   7.514, Episode:  392, Epsilon: 0.01
Iteration:   57700, Train reward: -449.929, Eval reward: -444.021, TD loss:   7.335, Episode:  393, Epsilon: 0.01
Iteration:   57800, Train reward: -455.010, Eval reward: -444.021, TD loss:   8.502, Episode:  394, Epsilon: 0.01
Iteration:   57900, Train reward: -455.010, Eval reward: -444.021, TD loss:   6.991, Episode:  394, Epsilon: 0.01
Iteration:   58000, Train reward: -451.782, Eval reward: -359.288, TD loss:   7.746, Episode:  395, Epsilon: 0.01
Iteration:   58100, Train reward: -446.909, Eval reward: -359.288, TD loss:   7.713, Episode:  396, Epsilon: 0.01
Iteration:   58200, Train reward: -449.335, Eval reward: -359.288, TD loss:   7.352, Episode:  397, Epsilon: 0.01
Iteration:   58300, Train reward: -432.952, Eval reward: -359.288, TD loss:   7.239, Episode:  398, Epsilon: 0.01
Iteration:   58400, Train reward: -432.952, Eval reward: -359.288, TD loss:   7.468, Episode:  398, Epsilon: 0.01
Iteration:   58500, Train reward: -427.194, Eval reward: -359.288, TD loss:   7.637, Episode:  399, Epsilon: 0.01
Iteration:   58600, Train reward: -418.480, Eval reward: -359.288, TD loss:   7.176, Episode:  400, Epsilon: 0.01
Iteration:   58700, Train reward: -415.043, Eval reward: -359.288, TD loss:   7.166, Episode:  401, Epsilon: 0.01
Iteration:   58800, Train reward: -398.902, Eval reward: -359.288, TD loss:   6.372, Episode:  402, Epsilon: 0.01
Iteration:   58900, Train reward: -399.145, Eval reward: -359.288, TD loss:   7.303, Episode:  403, Epsilon: 0.01
Iteration:   59000, Train reward: -391.502, Eval reward: -500.231, TD loss:   7.916, Episode:  404, Epsilon: 0.01
Iteration:   59100, Train reward: -402.500, Eval reward: -500.231, TD loss:   7.595, Episode:  405, Epsilon: 0.01
Iteration:   59200, Train reward: -402.500, Eval reward: -500.231, TD loss:   7.299, Episode:  405, Epsilon: 0.01
Iteration:   59300, Train reward: -389.084, Eval reward: -500.231, TD loss:   6.908, Episode:  406, Epsilon: 0.01
Iteration:   59400, Train reward: -387.136, Eval reward: -500.231, TD loss:   7.785, Episode:  407, Epsilon: 0.01
Iteration:   59500, Train reward: -387.136, Eval reward: -500.231, TD loss:   7.350, Episode:  407, Epsilon: 0.01
Iteration:   59600, Train reward: -368.824, Eval reward: -500.231, TD loss:   7.788, Episode:  408, Epsilon: 0.01
Iteration:   59700, Train reward: -370.217, Eval reward: -500.231, TD loss:   6.871, Episode:  409, Epsilon: 0.01
Iteration:   59800, Train reward: -352.002, Eval reward: -500.231, TD loss:   7.684, Episode:  410, Epsilon: 0.01
Iteration:   59900, Train reward: -367.264, Eval reward: -500.231, TD loss:   7.700, Episode:  411, Epsilon: 0.01
Iteration:   60000, Train reward: -367.264, Eval reward: -372.538, TD loss:   7.372, Episode:  411, Epsilon: 0.01
Iteration:   60100, Train reward: -351.087, Eval reward: -372.538, TD loss:   7.200, Episode:  412, Epsilon: 0.01
Iteration:   60200, Train reward: -340.319, Eval reward: -372.538, TD loss:   7.027, Episode:  413, Epsilon: 0.01
Iteration:   60300, Train reward: -340.319, Eval reward: -372.538, TD loss:   6.860, Episode:  413, Epsilon: 0.01
Iteration:   60400, Train reward: -320.390, Eval reward: -372.538, TD loss:   6.808, Episode:  414, Epsilon: 0.01
Iteration:   60500, Train reward: -326.032, Eval reward: -372.538, TD loss:   7.665, Episode:  415, Epsilon: 0.01
Iteration:   60600, Train reward: -326.103, Eval reward: -372.538, TD loss:   7.201, Episode:  416, Epsilon: 0.01
Iteration:   60700, Train reward: -326.103, Eval reward: -372.538, TD loss:   7.115, Episode:  416, Epsilon: 0.01
Iteration:   60800, Train reward: -305.783, Eval reward: -372.538, TD loss:   7.214, Episode:  417, Epsilon: 0.01
Iteration:   60900, Train reward: -305.783, Eval reward: -372.538, TD loss:   7.378, Episode:  417, Epsilon: 0.01
Iteration:   61000, Train reward: -305.783, Eval reward: -192.802, TD loss:   6.917, Episode:  417, Epsilon: 0.01
Iteration:   61100, Train reward: -305.194, Eval reward: -192.802, TD loss:   6.653, Episode:  418, Epsilon: 0.01
Iteration:   61200, Train reward: -307.286, Eval reward: -192.802, TD loss:   6.882, Episode:  419, Epsilon: 0.01
Iteration:   61300, Train reward: -321.435, Eval reward: -192.802, TD loss:   7.264, Episode:  420, Epsilon: 0.01
Iteration:   61400, Train reward: -314.311, Eval reward: -192.802, TD loss:   6.830, Episode:  421, Epsilon: 0.01
Iteration:   61500, Train reward: -314.311, Eval reward: -192.802, TD loss:   6.865, Episode:  421, Epsilon: 0.01
Iteration:   61600, Train reward: -323.502, Eval reward: -192.802, TD loss:   6.764, Episode:  422, Epsilon: 0.01
Iteration:   61700, Train reward: -307.466, Eval reward: -192.802, TD loss:   6.917, Episode:  423, Epsilon: 0.01
Iteration:   61800, Train reward: -307.466, Eval reward: -192.802, TD loss:   6.587, Episode:  423, Epsilon: 0.01
Iteration:   61900, Train reward: -304.597, Eval reward: -192.802, TD loss:   6.491, Episode:  424, Epsilon: 0.01
Iteration:   62000, Train reward: -295.333, Eval reward: -399.882, TD loss:   6.924, Episode:  425, Epsilon: 0.01
Iteration:   62100, Train reward: -310.421, Eval reward: -399.882, TD loss:   5.879, Episode:  426, Epsilon: 0.01
Iteration:   62200, Train reward: -310.421, Eval reward: -399.882, TD loss:   6.522, Episode:  426, Epsilon: 0.01
Iteration:   62300, Train reward: -306.679, Eval reward: -399.882, TD loss:   5.959, Episode:  427, Epsilon: 0.01
Iteration:   62400, Train reward: -311.404, Eval reward: -399.882, TD loss:   6.585, Episode:  428, Epsilon: 0.01
Iteration:   62500, Train reward: -310.601, Eval reward: -399.882, TD loss:   6.382, Episode:  429, Epsilon: 0.01
Iteration:   62600, Train reward: -323.264, Eval reward: -399.882, TD loss:   6.640, Episode:  430, Epsilon: 0.01
Iteration:   62700, Train reward: -303.364, Eval reward: -399.882, TD loss:   7.472, Episode:  431, Epsilon: 0.01
Iteration:   62800, Train reward: -303.364, Eval reward: -399.882, TD loss:   5.945, Episode:  431, Epsilon: 0.01
Iteration:   62900, Train reward: -303.364, Eval reward: -399.882, TD loss:   6.101, Episode:  431, Epsilon: 0.01
Iteration:   63000, Train reward: -302.494, Eval reward: -336.348, TD loss:   7.026, Episode:  432, Epsilon: 0.01
Iteration:   63100, Train reward: -310.896, Eval reward: -336.348, TD loss:   6.000, Episode:  433, Epsilon: 0.01
Iteration:   63200, Train reward: -326.867, Eval reward: -336.348, TD loss:   6.576, Episode:  434, Epsilon: 0.01
Iteration:   63300, Train reward: -318.617, Eval reward: -336.348, TD loss:   6.383, Episode:  435, Epsilon: 0.01
Iteration:   63400, Train reward: -318.617, Eval reward: -336.348, TD loss:   6.171, Episode:  435, Epsilon: 0.01
Iteration:   63500, Train reward: -312.405, Eval reward: -336.348, TD loss:   5.997, Episode:  436, Epsilon: 0.01
Iteration:   63600, Train reward: -327.133, Eval reward: -336.348, TD loss:   6.581, Episode:  437, Epsilon: 0.01
Iteration:   63700, Train reward: -327.133, Eval reward: -336.348, TD loss:   6.246, Episode:  437, Epsilon: 0.01
Iteration:   63800, Train reward: -323.749, Eval reward: -336.348, TD loss:   5.790, Episode:  438, Epsilon: 0.01
Iteration:   63900, Train reward: -308.195, Eval reward: -336.348, TD loss:   6.409, Episode:  439, Epsilon: 0.01
Iteration:   64000, Train reward: -304.487, Eval reward: -327.544, TD loss:   6.151, Episode:  440, Epsilon: 0.01
Iteration:   64100, Train reward: -304.487, Eval reward: -327.544, TD loss:   6.811, Episode:  440, Epsilon: 0.01
Iteration:   64200, Train reward: -302.991, Eval reward: -327.544, TD loss:   6.507, Episode:  441, Epsilon: 0.01
Iteration:   64300, Train reward: -302.991, Eval reward: -327.544, TD loss:   6.531, Episode:  441, Epsilon: 0.01
Iteration:   64400, Train reward: -302.991, Eval reward: -327.544, TD loss:   6.027, Episode:  441, Epsilon: 0.01
Iteration:   64500, Train reward: -286.398, Eval reward: -327.544, TD loss:   7.247, Episode:  442, Epsilon: 0.01
Iteration:   64600, Train reward: -301.507, Eval reward: -327.544, TD loss:   6.178, Episode:  443, Epsilon: 0.01
Iteration:   64700, Train reward: -301.507, Eval reward: -327.544, TD loss:   6.001, Episode:  443, Epsilon: 0.01
Iteration:   64800, Train reward: -301.507, Eval reward: -327.544, TD loss:   6.609, Episode:  443, Epsilon: 0.01
Iteration:   64900, Train reward: -296.626, Eval reward: -327.544, TD loss:   5.969, Episode:  444, Epsilon: 0.01
Iteration:   65000, Train reward: -296.626, Eval reward: -285.110, TD loss:   6.349, Episode:  444, Epsilon: 0.01
Iteration:   65100, Train reward: -296.626, Eval reward: -285.110, TD loss:   6.336, Episode:  444, Epsilon: 0.01
Iteration:   65200, Train reward: -297.010, Eval reward: -285.110, TD loss:   6.122, Episode:  445, Epsilon: 0.01
Iteration:   65300, Train reward: -297.010, Eval reward: -285.110, TD loss:   6.105, Episode:  445, Epsilon: 0.01
Iteration:   65400, Train reward: -292.794, Eval reward: -285.110, TD loss:   5.358, Episode:  446, Epsilon: 0.01
Iteration:   65500, Train reward: -291.142, Eval reward: -285.110, TD loss:   5.897, Episode:  447, Epsilon: 0.01
Iteration:   65600, Train reward: -298.586, Eval reward: -285.110, TD loss:   5.542, Episode:  448, Epsilon: 0.01
Iteration:   65700, Train reward: -295.703, Eval reward: -285.110, TD loss:   6.478, Episode:  449, Epsilon: 0.01
Iteration:   65800, Train reward: -295.703, Eval reward: -285.110, TD loss:   6.245, Episode:  449, Epsilon: 0.01
Iteration:   65900, Train reward: -292.753, Eval reward: -285.110, TD loss:   5.114, Episode:  450, Epsilon: 0.01
Iteration:   66000, Train reward: -304.490, Eval reward: -247.727, TD loss:   5.718, Episode:  451, Epsilon: 0.01
Iteration:   66100, Train reward: -312.105, Eval reward: -247.727, TD loss:   6.198, Episode:  452, Epsilon: 0.01
Iteration:   66200, Train reward: -309.449, Eval reward: -247.727, TD loss:   5.925, Episode:  453, Epsilon: 0.01
Iteration:   66300, Train reward: -309.449, Eval reward: -247.727, TD loss:   6.421, Episode:  453, Epsilon: 0.01
Iteration:   66400, Train reward: -295.907, Eval reward: -247.727, TD loss:   5.951, Episode:  454, Epsilon: 0.01
Iteration:   66500, Train reward: -293.607, Eval reward: -247.727, TD loss:   5.609, Episode:  455, Epsilon: 0.01
Iteration:   66600, Train reward: -293.607, Eval reward: -247.727, TD loss:   5.566, Episode:  455, Epsilon: 0.01
Iteration:   66700, Train reward: -295.320, Eval reward: -247.727, TD loss:   5.644, Episode:  456, Epsilon: 0.01
Iteration:   66800, Train reward: -295.320, Eval reward: -247.727, TD loss:   6.229, Episode:  456, Epsilon: 0.01
Iteration:   66900, Train reward: -280.774, Eval reward: -247.727, TD loss:   5.445, Episode:  457, Epsilon: 0.01
Iteration:   67000, Train reward: -280.774, Eval reward: -295.893, TD loss:   5.606, Episode:  457, Epsilon: 0.01
Iteration:   67100, Train reward: -290.693, Eval reward: -295.893, TD loss:   6.075, Episode:  458, Epsilon: 0.01
Iteration:   67200, Train reward: -297.913, Eval reward: -295.893, TD loss:   5.322, Episode:  459, Epsilon: 0.01
Iteration:   67300, Train reward: -296.699, Eval reward: -295.893, TD loss:   5.719, Episode:  460, Epsilon: 0.01
Iteration:   67400, Train reward: -301.356, Eval reward: -295.893, TD loss:   5.663, Episode:  461, Epsilon: 0.01
Iteration:   67500, Train reward: -301.356, Eval reward: -295.893, TD loss:   6.621, Episode:  461, Epsilon: 0.01
Iteration:   67600, Train reward: -303.491, Eval reward: -295.893, TD loss:   5.683, Episode:  462, Epsilon: 0.01
Iteration:   67700, Train reward: -292.891, Eval reward: -295.893, TD loss:   5.441, Episode:  463, Epsilon: 0.01
Iteration:   67800, Train reward: -300.723, Eval reward: -295.893, TD loss:   5.453, Episode:  464, Epsilon: 0.01
Iteration:   67900, Train reward: -304.109, Eval reward: -295.893, TD loss:   5.449, Episode:  465, Epsilon: 0.01
Iteration:   68000, Train reward: -305.751, Eval reward: -288.104, TD loss:   5.236, Episode:  466, Epsilon: 0.01
Iteration:   68100, Train reward: -305.751, Eval reward: -288.104, TD loss:   5.481, Episode:  466, Epsilon: 0.01
Iteration:   68200, Train reward: -301.520, Eval reward: -288.104, TD loss:   5.554, Episode:  467, Epsilon: 0.01
Iteration:   68300, Train reward: -301.520, Eval reward: -288.104, TD loss:   5.247, Episode:  467, Epsilon: 0.01
Iteration:   68400, Train reward: -301.520, Eval reward: -288.104, TD loss:   5.163, Episode:  467, Epsilon: 0.01
Iteration:   68500, Train reward: -301.520, Eval reward: -288.104, TD loss:   5.679, Episode:  467, Epsilon: 0.01
Iteration:   68600, Train reward: -301.520, Eval reward: -288.104, TD loss:   5.449, Episode:  467, Epsilon: 0.01
Iteration:   68700, Train reward: -301.520, Eval reward: -288.104, TD loss:   5.411, Episode:  467, Epsilon: 0.01
Iteration:   68800, Train reward: -301.520, Eval reward: -288.104, TD loss:   5.895, Episode:  467, Epsilon: 0.01
Iteration:   68900, Train reward: -301.520, Eval reward: -288.104, TD loss:   5.120, Episode:  467, Epsilon: 0.01
Iteration:   69000, Train reward: -301.520, Eval reward: -324.997, TD loss:   5.602, Episode:  467, Epsilon: 0.01
Iteration:   69100, Train reward: -301.520, Eval reward: -324.997, TD loss:   5.189, Episode:  467, Epsilon: 0.01
Iteration:   69200, Train reward: -290.874, Eval reward: -324.997, TD loss:   5.523, Episode:  468, Epsilon: 0.01
Iteration:   69300, Train reward: -290.874, Eval reward: -324.997, TD loss:   5.559, Episode:  468, Epsilon: 0.01
Iteration:   69400, Train reward: -290.232, Eval reward: -324.997, TD loss:   5.139, Episode:  469, Epsilon: 0.01
Iteration:   69500, Train reward: -291.733, Eval reward: -324.997, TD loss:   5.232, Episode:  470, Epsilon: 0.01
Iteration:   69600, Train reward: -291.733, Eval reward: -324.997, TD loss:   5.597, Episode:  470, Epsilon: 0.01
Iteration:   69700, Train reward: -291.733, Eval reward: -324.997, TD loss:   4.801, Episode:  470, Epsilon: 0.01
Iteration:   69800, Train reward: -291.733, Eval reward: -324.997, TD loss:   5.591, Episode:  470, Epsilon: 0.01
Iteration:   69900, Train reward: -301.640, Eval reward: -324.997, TD loss:   5.288, Episode:  471, Epsilon: 0.01
Iteration:   70000, Train reward: -301.640, Eval reward: -188.447, TD loss:   4.943, Episode:  471, Epsilon: 0.01
Iteration:   70100, Train reward: -301.023, Eval reward: -188.447, TD loss:   5.310, Episode:  472, Epsilon: 0.01
Iteration:   70200, Train reward: -298.097, Eval reward: -188.447, TD loss:   4.737, Episode:  473, Epsilon: 0.01
Iteration:   70300, Train reward: -298.097, Eval reward: -188.447, TD loss:   5.570, Episode:  473, Epsilon: 0.01
Iteration:   70400, Train reward: -316.549, Eval reward: -188.447, TD loss:   4.935, Episode:  474, Epsilon: 0.01
Iteration:   70500, Train reward: -316.843, Eval reward: -188.447, TD loss:   5.111, Episode:  475, Epsilon: 0.01
Iteration:   70600, Train reward: -316.843, Eval reward: -188.447, TD loss:   4.672, Episode:  475, Epsilon: 0.01
Iteration:   70700, Train reward: -316.843, Eval reward: -188.447, TD loss:   5.006, Episode:  475, Epsilon: 0.01
Iteration:   70800, Train reward: -316.843, Eval reward: -188.447, TD loss:   4.853, Episode:  475, Epsilon: 0.01
Iteration:   70900, Train reward: -316.843, Eval reward: -188.447, TD loss:   5.067, Episode:  475, Epsilon: 0.01
Iteration:   71000, Train reward: -316.843, Eval reward: -119.629, TD loss:   4.827, Episode:  475, Epsilon: 0.01
Iteration:   71100, Train reward: -316.843, Eval reward: -119.629, TD loss:   5.168, Episode:  475, Epsilon: 0.01
Iteration:   71200, Train reward: -316.843, Eval reward: -119.629, TD loss:   5.268, Episode:  475, Epsilon: 0.01
Iteration:   71300, Train reward: -316.843, Eval reward: -119.629, TD loss:   5.022, Episode:  475, Epsilon: 0.01
Iteration:   71400, Train reward: -316.843, Eval reward: -119.629, TD loss:   4.875, Episode:  475, Epsilon: 0.01
Iteration:   71500, Train reward: -310.519, Eval reward: -119.629, TD loss:   4.644, Episode:  476, Epsilon: 0.01
Iteration:   71600, Train reward: -310.519, Eval reward: -119.629, TD loss:   5.663, Episode:  476, Epsilon: 0.01
Iteration:   71700, Train reward: -315.065, Eval reward: -119.629, TD loss:   5.490, Episode:  477, Epsilon: 0.01
Iteration:   71800, Train reward: -315.065, Eval reward: -119.629, TD loss:   5.176, Episode:  477, Epsilon: 0.01
Iteration:   71900, Train reward: -315.065, Eval reward: -119.629, TD loss:   5.202, Episode:  477, Epsilon: 0.01
Iteration:   72000, Train reward: -315.065, Eval reward: -209.597, TD loss:   5.342, Episode:  477, Epsilon: 0.01
Iteration:   72100, Train reward: -315.065, Eval reward: -209.597, TD loss:   4.890, Episode:  477, Epsilon: 0.01
Iteration:   72200, Train reward: -315.065, Eval reward: -209.597, TD loss:   5.101, Episode:  477, Epsilon: 0.01
Iteration:   72300, Train reward: -315.065, Eval reward: -209.597, TD loss:   5.204, Episode:  477, Epsilon: 0.01
Iteration:   72400, Train reward: -315.065, Eval reward: -209.597, TD loss:   4.620, Episode:  477, Epsilon: 0.01
Iteration:   72500, Train reward: -315.065, Eval reward: -209.597, TD loss:   5.165, Episode:  477, Epsilon: 0.01
Iteration:   72600, Train reward: -315.065, Eval reward: -209.597, TD loss:   4.945, Episode:  477, Epsilon: 0.01
Iteration:   72700, Train reward: -309.861, Eval reward: -209.597, TD loss:   4.997, Episode:  478, Epsilon: 0.01
Iteration:   72800, Train reward: -309.861, Eval reward: -209.597, TD loss:   5.402, Episode:  478, Epsilon: 0.01
Iteration:   72900, Train reward: -309.861, Eval reward: -209.597, TD loss:   4.991, Episode:  478, Epsilon: 0.01
Iteration:   73000, Train reward: -309.861, Eval reward: -173.997, TD loss:   4.725, Episode:  478, Epsilon: 0.01
Iteration:   73100, Train reward: -309.861, Eval reward: -173.997, TD loss:   5.107, Episode:  478, Epsilon: 0.01
Iteration:   73200, Train reward: -309.861, Eval reward: -173.997, TD loss:   5.089, Episode:  478, Epsilon: 0.01
Iteration:   73300, Train reward: -309.861, Eval reward: -173.997, TD loss:   4.537, Episode:  478, Epsilon: 0.01
Iteration:   73400, Train reward: -309.861, Eval reward: -173.997, TD loss:   5.044, Episode:  478, Epsilon: 0.01
Iteration:   73500, Train reward: -309.861, Eval reward: -173.997, TD loss:   5.029, Episode:  478, Epsilon: 0.01
Iteration:   73600, Train reward: -309.861, Eval reward: -173.997, TD loss:   4.765, Episode:  478, Epsilon: 0.01
Iteration:   73700, Train reward: -298.254, Eval reward: -173.997, TD loss:   4.531, Episode:  479, Epsilon: 0.01
Iteration:   73800, Train reward: -283.114, Eval reward: -173.997, TD loss:   5.301, Episode:  480, Epsilon: 0.01
Iteration:   73900, Train reward: -283.114, Eval reward: -173.997, TD loss:   4.529, Episode:  480, Epsilon: 0.01
Iteration:   74000, Train reward: -278.377, Eval reward: -66.649, TD loss:   5.143, Episode:  481, Epsilon: 0.01
Iteration:   74100, Train reward: -277.016, Eval reward: -66.649, TD loss:   4.962, Episode:  482, Epsilon: 0.01
Iteration:   74200, Train reward: -277.016, Eval reward: -66.649, TD loss:   4.824, Episode:  482, Epsilon: 0.01
Iteration:   74300, Train reward: -277.016, Eval reward: -66.649, TD loss:   4.523, Episode:  482, Epsilon: 0.01
Iteration:   74400, Train reward: -277.016, Eval reward: -66.649, TD loss:   5.452, Episode:  482, Epsilon: 0.01
Iteration:   74500, Train reward: -277.016, Eval reward: -66.649, TD loss:   4.872, Episode:  482, Epsilon: 0.01
Iteration:   74600, Train reward: -277.016, Eval reward: -66.649, TD loss:   4.516, Episode:  482, Epsilon: 0.01
Iteration:   74700, Train reward: -277.016, Eval reward: -66.649, TD loss:   5.013, Episode:  482, Epsilon: 0.01
Iteration:   74800, Train reward: -277.016, Eval reward: -66.649, TD loss:   4.407, Episode:  482, Epsilon: 0.01
Iteration:   74900, Train reward: -277.016, Eval reward: -66.649, TD loss:   4.987, Episode:  482, Epsilon: 0.01
Iteration:   75000, Train reward: -277.016, Eval reward: -103.104, TD loss:   4.676, Episode:  482, Epsilon: 0.01
Iteration:   75100, Train reward: -267.608, Eval reward: -103.104, TD loss:   5.151, Episode:  483, Epsilon: 0.01
Iteration:   75200, Train reward: -267.608, Eval reward: -103.104, TD loss:   4.823, Episode:  483, Epsilon: 0.01
Iteration:   75300, Train reward: -267.608, Eval reward: -103.104, TD loss:   5.473, Episode:  483, Epsilon: 0.01
Iteration:   75400, Train reward: -267.608, Eval reward: -103.104, TD loss:   4.716, Episode:  483, Epsilon: 0.01
Iteration:   75500, Train reward: -267.608, Eval reward: -103.104, TD loss:   4.489, Episode:  483, Epsilon: 0.01
Iteration:   75600, Train reward: -267.608, Eval reward: -103.104, TD loss:   4.514, Episode:  483, Epsilon: 0.01
Iteration:   75700, Train reward: -267.608, Eval reward: -103.104, TD loss:   4.838, Episode:  483, Epsilon: 0.01
Iteration:   75800, Train reward: -267.608, Eval reward: -103.104, TD loss:   5.065, Episode:  483, Epsilon: 0.01
Iteration:   75900, Train reward: -267.608, Eval reward: -103.104, TD loss:   4.653, Episode:  483, Epsilon: 0.01
Iteration:   76000, Train reward: -267.608, Eval reward: -93.615, TD loss:   4.869, Episode:  483, Epsilon: 0.01
Iteration:   76100, Train reward: -257.480, Eval reward: -93.615, TD loss:   4.819, Episode:  484, Epsilon: 0.01
Iteration:   76200, Train reward: -257.480, Eval reward: -93.615, TD loss:   4.322, Episode:  484, Epsilon: 0.01
Iteration:   76300, Train reward: -257.480, Eval reward: -93.615, TD loss:   4.562, Episode:  484, Epsilon: 0.01
Iteration:   76400, Train reward: -257.480, Eval reward: -93.615, TD loss:   5.053, Episode:  484, Epsilon: 0.01
Iteration:   76500, Train reward: -257.480, Eval reward: -93.615, TD loss:   4.874, Episode:  484, Epsilon: 0.01
Iteration:   76600, Train reward: -257.480, Eval reward: -93.615, TD loss:   4.346, Episode:  484, Epsilon: 0.01
Iteration:   76700, Train reward: -257.480, Eval reward: -93.615, TD loss:   4.273, Episode:  484, Epsilon: 0.01
Iteration:   76800, Train reward: -257.480, Eval reward: -93.615, TD loss:   4.418, Episode:  484, Epsilon: 0.01
Iteration:   76900, Train reward: -257.480, Eval reward: -93.615, TD loss:   4.694, Episode:  484, Epsilon: 0.01
Iteration:   77000, Train reward: -257.480, Eval reward: -88.141, TD loss:   4.108, Episode:  484, Epsilon: 0.01
Iteration:   77100, Train reward: -241.718, Eval reward: -88.141, TD loss:   4.940, Episode:  485, Epsilon: 0.01
Iteration:   77200, Train reward: -241.718, Eval reward: -88.141, TD loss:   4.437, Episode:  485, Epsilon: 0.01
Iteration:   77300, Train reward: -241.718, Eval reward: -88.141, TD loss:   4.504, Episode:  485, Epsilon: 0.01
Iteration:   77400, Train reward: -241.718, Eval reward: -88.141, TD loss:   4.726, Episode:  485, Epsilon: 0.01
Iteration:   77500, Train reward: -241.718, Eval reward: -88.141, TD loss:   4.276, Episode:  485, Epsilon: 0.01
Iteration:   77600, Train reward: -241.718, Eval reward: -88.141, TD loss:   4.666, Episode:  485, Epsilon: 0.01
Iteration:   77700, Train reward: -241.718, Eval reward: -88.141, TD loss:   4.546, Episode:  485, Epsilon: 0.01
Iteration:   77800, Train reward: -241.718, Eval reward: -88.141, TD loss:   4.626, Episode:  485, Epsilon: 0.01
Iteration:   77900, Train reward: -241.718, Eval reward: -88.141, TD loss:   4.517, Episode:  485, Epsilon: 0.01
Iteration:   78000, Train reward: -241.718, Eval reward: -126.599, TD loss:   4.194, Episode:  485, Epsilon: 0.01
Iteration:   78100, Train reward: -230.765, Eval reward: -126.599, TD loss:   4.786, Episode:  486, Epsilon: 0.01
Iteration:   78200, Train reward: -230.765, Eval reward: -126.599, TD loss:   4.775, Episode:  486, Epsilon: 0.01
Iteration:   78300, Train reward: -230.765, Eval reward: -126.599, TD loss:   4.888, Episode:  486, Epsilon: 0.01
Iteration:   78400, Train reward: -230.765, Eval reward: -126.599, TD loss:   4.889, Episode:  486, Epsilon: 0.01
Iteration:   78500, Train reward: -230.765, Eval reward: -126.599, TD loss:   4.823, Episode:  486, Epsilon: 0.01
Iteration:   78600, Train reward: -230.765, Eval reward: -126.599, TD loss:   4.574, Episode:  486, Epsilon: 0.01
Iteration:   78700, Train reward: -230.765, Eval reward: -126.599, TD loss:   4.402, Episode:  486, Epsilon: 0.01
Iteration:   78800, Train reward: -230.765, Eval reward: -126.599, TD loss:   4.618, Episode:  486, Epsilon: 0.01
Iteration:   78900, Train reward: -230.765, Eval reward: -126.599, TD loss:   4.199, Episode:  486, Epsilon: 0.01
Iteration:   79000, Train reward: -230.765, Eval reward: -87.905, TD loss:   4.987, Episode:  486, Epsilon: 0.01
Iteration:   79100, Train reward: -222.033, Eval reward: -87.905, TD loss:   4.251, Episode:  487, Epsilon: 0.01
Iteration:   79200, Train reward: -222.033, Eval reward: -87.905, TD loss:   4.564, Episode:  487, Epsilon: 0.01
Iteration:   79300, Train reward: -222.033, Eval reward: -87.905, TD loss:   4.741, Episode:  487, Epsilon: 0.01
Iteration:   79400, Train reward: -222.033, Eval reward: -87.905, TD loss:   4.248, Episode:  487, Epsilon: 0.01
Iteration:   79500, Train reward: -222.033, Eval reward: -87.905, TD loss:   4.512, Episode:  487, Epsilon: 0.01
Iteration:   79600, Train reward: -222.033, Eval reward: -87.905, TD loss:   4.583, Episode:  487, Epsilon: 0.01
Iteration:   79700, Train reward: -222.033, Eval reward: -87.905, TD loss:   3.828, Episode:  487, Epsilon: 0.01
Iteration:   79800, Train reward: -222.033, Eval reward: -87.905, TD loss:   4.384, Episode:  487, Epsilon: 0.01
Iteration:   79900, Train reward: -222.033, Eval reward: -87.905, TD loss:   4.162, Episode:  487, Epsilon: 0.01
Iteration:   80000, Train reward: -222.033, Eval reward: -137.664, TD loss:   4.463, Episode:  487, Epsilon: 0.01
Iteration:   80100, Train reward: -218.333, Eval reward: -137.664, TD loss:   4.352, Episode:  488, Epsilon: 0.01
Iteration:   80200, Train reward: -218.333, Eval reward: -137.664, TD loss:   4.410, Episode:  488, Epsilon: 0.01
Iteration:   80300, Train reward: -208.252, Eval reward: -137.664, TD loss:   4.545, Episode:  489, Epsilon: 0.01
Iteration:   80400, Train reward: -208.252, Eval reward: -137.664, TD loss:   4.435, Episode:  489, Epsilon: 0.01
Iteration:   80500, Train reward: -208.252, Eval reward: -137.664, TD loss:   4.174, Episode:  489, Epsilon: 0.01
Iteration:   80600, Train reward: -208.252, Eval reward: -137.664, TD loss:   4.412, Episode:  489, Epsilon: 0.01
Iteration:   80700, Train reward: -208.252, Eval reward: -137.664, TD loss:   4.547, Episode:  489, Epsilon: 0.01
Iteration:   80800, Train reward: -208.252, Eval reward: -137.664, TD loss:   4.203, Episode:  489, Epsilon: 0.01
Iteration:   80900, Train reward: -208.252, Eval reward: -137.664, TD loss:   4.223, Episode:  489, Epsilon: 0.01
Iteration:   81000, Train reward: -208.252, Eval reward: -95.359, TD loss:   4.230, Episode:  489, Epsilon: 0.01
Iteration:   81100, Train reward: -208.252, Eval reward: -95.359, TD loss:   4.284, Episode:  489, Epsilon: 0.01
Iteration:   81200, Train reward: -208.252, Eval reward: -95.359, TD loss:   4.768, Episode:  489, Epsilon: 0.01
Iteration:   81300, Train reward: -193.791, Eval reward: -95.359, TD loss:   4.692, Episode:  490, Epsilon: 0.01
Iteration:   81400, Train reward: -172.999, Eval reward: -95.359, TD loss:   4.447, Episode:  491, Epsilon: 0.01
Iteration:   81500, Train reward: -162.979, Eval reward: -95.359, TD loss:   4.827, Episode:  492, Epsilon: 0.01
Iteration:   81600, Train reward: -162.979, Eval reward: -95.359, TD loss:   4.614, Episode:  492, Epsilon: 0.01
Iteration:   81700, Train reward: -153.044, Eval reward: -95.359, TD loss:   4.144, Episode:  493, Epsilon: 0.01
Iteration:   81800, Train reward: -153.044, Eval reward: -95.359, TD loss:   4.629, Episode:  493, Epsilon: 0.01
Iteration:   81900, Train reward: -133.804, Eval reward: -95.359, TD loss:   4.303, Episode:  494, Epsilon: 0.01
Iteration:   82000, Train reward: -126.546, Eval reward: -115.643, TD loss:   4.586, Episode:  495, Epsilon: 0.01
Iteration:   82100, Train reward: -126.546, Eval reward: -115.643, TD loss:   4.159, Episode:  495, Epsilon: 0.01
Iteration:   82200, Train reward: -123.135, Eval reward: -115.643, TD loss:   4.382, Episode:  496, Epsilon: 0.01
Iteration:   82300, Train reward: -123.135, Eval reward: -115.643, TD loss:   4.494, Episode:  496, Epsilon: 0.01
Iteration:   82400, Train reward: -121.182, Eval reward: -115.643, TD loss:   4.317, Episode:  497, Epsilon: 0.01
Iteration:   82500, Train reward: -119.033, Eval reward: -115.643, TD loss:   4.973, Episode:  498, Epsilon: 0.01
Iteration:   82600, Train reward: -119.033, Eval reward: -115.643, TD loss:   4.482, Episode:  498, Epsilon: 0.01
Iteration:   82700, Train reward: -122.104, Eval reward: -115.643, TD loss:   4.042, Episode:  499, Epsilon: 0.01
Iteration:   82800, Train reward: -125.730, Eval reward: -115.643, TD loss:   4.412, Episode:  500, Epsilon: 0.01
Iteration:   82900, Train reward: -125.730, Eval reward: -115.643, TD loss:   4.196, Episode:  500, Epsilon: 0.01
Iteration:   83000, Train reward: -125.730, Eval reward: -138.354, TD loss:   4.586, Episode:  500, Epsilon: 0.01
Iteration:   83100, Train reward: -125.730, Eval reward: -138.354, TD loss:   4.668, Episode:  500, Epsilon: 0.01
Iteration:   83200, Train reward: -125.730, Eval reward: -138.354, TD loss:   4.245, Episode:  500, Epsilon: 0.01
Iteration:   83300, Train reward: -125.730, Eval reward: -138.354, TD loss:   4.411, Episode:  500, Epsilon: 0.01
Iteration:   83400, Train reward: -125.730, Eval reward: -138.354, TD loss:   4.750, Episode:  500, Epsilon: 0.01
Iteration:   83500, Train reward: -125.730, Eval reward: -138.354, TD loss:   4.415, Episode:  500, Epsilon: 0.01
Iteration:   83600, Train reward: -125.730, Eval reward: -138.354, TD loss:   4.729, Episode:  500, Epsilon: 0.01
Iteration:   83700, Train reward: -125.730, Eval reward: -138.354, TD loss:   4.283, Episode:  500, Epsilon: 0.01
Iteration:   83800, Train reward: -115.562, Eval reward: -138.354, TD loss:   4.214, Episode:  501, Epsilon: 0.01
Iteration:   83900, Train reward: -115.562, Eval reward: -138.354, TD loss:   4.234, Episode:  501, Epsilon: 0.01
Iteration:   84000, Train reward: -115.562, Eval reward: -138.744, TD loss:   4.175, Episode:  501, Epsilon: 0.01
Iteration:   84100, Train reward: -115.562, Eval reward: -138.744, TD loss:   4.284, Episode:  501, Epsilon: 0.01
Iteration:   84200, Train reward: -115.562, Eval reward: -138.744, TD loss:   4.164, Episode:  501, Epsilon: 0.01
Iteration:   84300, Train reward: -115.562, Eval reward: -138.744, TD loss:   4.607, Episode:  501, Epsilon: 0.01
Iteration:   84400, Train reward: -115.562, Eval reward: -138.744, TD loss:   3.804, Episode:  501, Epsilon: 0.01
Iteration:   84500, Train reward: -115.562, Eval reward: -138.744, TD loss:   4.589, Episode:  501, Epsilon: 0.01
Iteration:   84600, Train reward: -115.562, Eval reward: -138.744, TD loss:   4.270, Episode:  501, Epsilon: 0.01
Iteration:   84700, Train reward: -115.562, Eval reward: -138.744, TD loss:   4.150, Episode:  501, Epsilon: 0.01
Iteration:   84800, Train reward: -115.004, Eval reward: -138.744, TD loss:   4.396, Episode:  502, Epsilon: 0.01
Iteration:   84900, Train reward: -115.004, Eval reward: -138.744, TD loss:   4.258, Episode:  502, Epsilon: 0.01
Iteration:   85000, Train reward: -116.151, Eval reward: -87.078, TD loss:   4.416, Episode:  503, Epsilon: 0.01
Iteration:   85100, Train reward: -116.792, Eval reward: -87.078, TD loss:   4.202, Episode:  504, Epsilon: 0.01
Iteration:   85200, Train reward: -117.410, Eval reward: -87.078, TD loss:   4.678, Episode:  505, Epsilon: 0.01
Iteration:   85300, Train reward: -117.410, Eval reward: -87.078, TD loss:   4.089, Episode:  505, Epsilon: 0.01
Iteration:   85400, Train reward: -116.376, Eval reward: -87.078, TD loss:   4.145, Episode:  506, Epsilon: 0.01
Iteration:   85500, Train reward: -116.376, Eval reward: -87.078, TD loss:   4.048, Episode:  506, Epsilon: 0.01
Iteration:   85600, Train reward: -117.832, Eval reward: -87.078, TD loss:   4.227, Episode:  507, Epsilon: 0.01
Iteration:   85700, Train reward: -118.354, Eval reward: -87.078, TD loss:   3.829, Episode:  508, Epsilon: 0.01
Iteration:   85800, Train reward: -118.354, Eval reward: -87.078, TD loss:   4.240, Episode:  508, Epsilon: 0.01
Iteration:   85900, Train reward: -118.354, Eval reward: -87.078, TD loss:   4.297, Episode:  508, Epsilon: 0.01
Iteration:   86000, Train reward: -118.354, Eval reward: -84.234, TD loss:   4.499, Episode:  508, Epsilon: 0.01
Iteration:   86100, Train reward: -118.354, Eval reward: -84.234, TD loss:   4.198, Episode:  508, Epsilon: 0.01
Iteration:   86200, Train reward: -118.354, Eval reward: -84.234, TD loss:   3.780, Episode:  508, Epsilon: 0.01
Iteration:   86300, Train reward: -118.354, Eval reward: -84.234, TD loss:   3.875, Episode:  508, Epsilon: 0.01
Iteration:   86400, Train reward: -118.354, Eval reward: -84.234, TD loss:   4.110, Episode:  508, Epsilon: 0.01
Iteration:   86500, Train reward: -118.354, Eval reward: -84.234, TD loss:   3.898, Episode:  508, Epsilon: 0.01
Iteration:   86600, Train reward: -118.354, Eval reward: -84.234, TD loss:   3.832, Episode:  508, Epsilon: 0.01
Iteration:   86700, Train reward: -115.179, Eval reward: -84.234, TD loss:   3.642, Episode:  509, Epsilon: 0.01
Iteration:   86800, Train reward: -115.179, Eval reward: -84.234, TD loss:   3.515, Episode:  509, Epsilon: 0.01
Iteration:   86900, Train reward: -117.106, Eval reward: -84.234, TD loss:   3.433, Episode:  510, Epsilon: 0.01
Iteration:   87000, Train reward: -117.415, Eval reward: -127.216, TD loss:   3.989, Episode:  511, Epsilon: 0.01
Iteration:   87100, Train reward: -117.415, Eval reward: -127.216, TD loss:   4.073, Episode:  511, Epsilon: 0.01
Iteration:   87200, Train reward: -117.415, Eval reward: -127.216, TD loss:   3.909, Episode:  511, Epsilon: 0.01
Iteration:   87300, Train reward: -117.415, Eval reward: -127.216, TD loss:   4.223, Episode:  511, Epsilon: 0.01
Iteration:   87400, Train reward: -117.415, Eval reward: -127.216, TD loss:   3.867, Episode:  511, Epsilon: 0.01
Iteration:   87500, Train reward: -117.415, Eval reward: -127.216, TD loss:   3.624, Episode:  511, Epsilon: 0.01
Iteration:   87600, Train reward: -117.415, Eval reward: -127.216, TD loss:   3.832, Episode:  511, Epsilon: 0.01
Iteration:   87700, Train reward: -117.415, Eval reward: -127.216, TD loss:   3.770, Episode:  511, Epsilon: 0.01
Iteration:   87800, Train reward: -117.415, Eval reward: -127.216, TD loss:   4.123, Episode:  511, Epsilon: 0.01
Iteration:   87900, Train reward: -117.415, Eval reward: -127.216, TD loss:   4.197, Episode:  511, Epsilon: 0.01
Iteration:   88000, Train reward: -116.343, Eval reward: -70.959, TD loss:   3.879, Episode:  512, Epsilon: 0.01
Iteration:   88100, Train reward: -116.343, Eval reward: -70.959, TD loss:   3.538, Episode:  512, Epsilon: 0.01
Iteration:   88200, Train reward: -117.117, Eval reward: -70.959, TD loss:   3.919, Episode:  513, Epsilon: 0.01
Iteration:   88300, Train reward: -117.117, Eval reward: -70.959, TD loss:   3.839, Episode:  513, Epsilon: 0.01
Iteration:   88400, Train reward: -117.117, Eval reward: -70.959, TD loss:   3.972, Episode:  513, Epsilon: 0.01
Iteration:   88500, Train reward: -117.117, Eval reward: -70.959, TD loss:   3.863, Episode:  513, Epsilon: 0.01
Iteration:   88600, Train reward: -116.592, Eval reward: -70.959, TD loss:   3.342, Episode:  514, Epsilon: 0.01
Iteration:   88700, Train reward: -116.592, Eval reward: -70.959, TD loss:   3.514, Episode:  514, Epsilon: 0.01
Iteration:   88800, Train reward: -115.280, Eval reward: -70.959, TD loss:   3.674, Episode:  515, Epsilon: 0.01
Iteration:   88900, Train reward: -115.280, Eval reward: -70.959, TD loss:   3.564, Episode:  515, Epsilon: 0.01
Iteration:   89000, Train reward: -115.280, Eval reward: -101.151, TD loss:   3.554, Episode:  515, Epsilon: 0.01
Iteration:   89100, Train reward: -115.280, Eval reward: -101.151, TD loss:   3.519, Episode:  515, Epsilon: 0.01
Iteration:   89200, Train reward: -115.280, Eval reward: -101.151, TD loss:   3.342, Episode:  515, Epsilon: 0.01
Iteration:   89300, Train reward: -115.280, Eval reward: -101.151, TD loss:   3.768, Episode:  515, Epsilon: 0.01
Iteration:   89400, Train reward: -115.280, Eval reward: -101.151, TD loss:   3.808, Episode:  515, Epsilon: 0.01
Iteration:   89500, Train reward: -115.280, Eval reward: -101.151, TD loss:   3.720, Episode:  515, Epsilon: 0.01
Iteration:   89600, Train reward: -115.280, Eval reward: -101.151, TD loss:   3.294, Episode:  515, Epsilon: 0.01
Iteration:   89700, Train reward: -115.280, Eval reward: -101.151, TD loss:   3.261, Episode:  515, Epsilon: 0.01
Iteration:   89800, Train reward: -112.735, Eval reward: -101.151, TD loss:   3.361, Episode:  516, Epsilon: 0.01
Iteration:   89900, Train reward: -111.955, Eval reward: -101.151, TD loss:   3.725, Episode:  517, Epsilon: 0.01
Iteration:   90000, Train reward: -111.955, Eval reward: -101.557, TD loss:   3.600, Episode:  517, Epsilon: 0.01
Iteration:   90100, Train reward: -111.955, Eval reward: -101.557, TD loss:   3.752, Episode:  517, Epsilon: 0.01
Iteration:   90200, Train reward: -111.955, Eval reward: -101.557, TD loss:   3.359, Episode:  517, Epsilon: 0.01
Iteration:   90300, Train reward: -111.955, Eval reward: -101.557, TD loss:   3.444, Episode:  517, Epsilon: 0.01
Iteration:   90400, Train reward: -111.955, Eval reward: -101.557, TD loss:   3.118, Episode:  517, Epsilon: 0.01
Iteration:   90500, Train reward: -111.955, Eval reward: -101.557, TD loss:   3.384, Episode:  517, Epsilon: 0.01
Iteration:   90600, Train reward: -111.955, Eval reward: -101.557, TD loss:   3.384, Episode:  517, Epsilon: 0.01
Iteration:   90700, Train reward: -111.955, Eval reward: -101.557, TD loss:   3.302, Episode:  517, Epsilon: 0.01
Iteration:   90800, Train reward: -111.955, Eval reward: -101.557, TD loss:   3.632, Episode:  517, Epsilon: 0.01
Iteration:   90900, Train reward: -107.013, Eval reward: -101.557, TD loss:   3.480, Episode:  518, Epsilon: 0.01
Iteration:   91000, Train reward: -107.013, Eval reward: -112.312, TD loss:   3.044, Episode:  518, Epsilon: 0.01
Iteration:   91100, Train reward: -107.013, Eval reward: -112.312, TD loss:   3.578, Episode:  518, Epsilon: 0.01
Iteration:   91200, Train reward: -107.013, Eval reward: -112.312, TD loss:   3.420, Episode:  518, Epsilon: 0.01
Iteration:   91300, Train reward: -107.013, Eval reward: -112.312, TD loss:   3.377, Episode:  518, Epsilon: 0.01
Iteration:   91400, Train reward: -107.013, Eval reward: -112.312, TD loss:   3.208, Episode:  518, Epsilon: 0.01
Iteration:   91500, Train reward: -107.013, Eval reward: -112.312, TD loss:   2.979, Episode:  518, Epsilon: 0.01
Iteration:   91600, Train reward: -107.013, Eval reward: -112.312, TD loss:   2.985, Episode:  518, Epsilon: 0.01
Iteration:   91700, Train reward: -107.013, Eval reward: -112.312, TD loss:   3.517, Episode:  518, Epsilon: 0.01
Iteration:   91800, Train reward: -107.013, Eval reward: -112.312, TD loss:   3.324, Episode:  518, Epsilon: 0.01
Iteration:   91900, Train reward: -106.051, Eval reward: -112.312, TD loss:   3.552, Episode:  519, Epsilon: 0.01
Iteration:   92000, Train reward: -106.051, Eval reward: -106.807, TD loss:   3.275, Episode:  519, Epsilon: 0.01
Iteration:   92100, Train reward: -106.051, Eval reward: -106.807, TD loss:   3.253, Episode:  519, Epsilon: 0.01
Iteration:   92200, Train reward: -106.051, Eval reward: -106.807, TD loss:   3.037, Episode:  519, Epsilon: 0.01
Iteration:   92300, Train reward: -106.051, Eval reward: -106.807, TD loss:   3.207, Episode:  519, Epsilon: 0.01
Iteration:   92400, Train reward: -106.051, Eval reward: -106.807, TD loss:   3.316, Episode:  519, Epsilon: 0.01
Iteration:   92500, Train reward: -106.051, Eval reward: -106.807, TD loss:   3.332, Episode:  519, Epsilon: 0.01
Iteration:   92600, Train reward: -106.051, Eval reward: -106.807, TD loss:   3.381, Episode:  519, Epsilon: 0.01
Iteration:   92700, Train reward: -106.051, Eval reward: -106.807, TD loss:   3.441, Episode:  519, Epsilon: 0.01
Iteration:   92800, Train reward: -106.051, Eval reward: -106.807, TD loss:   2.887, Episode:  519, Epsilon: 0.01
Iteration:   92900, Train reward: -107.254, Eval reward: -106.807, TD loss:   3.269, Episode:  520, Epsilon: 0.01
Iteration:   93000, Train reward: -107.254, Eval reward: -89.428, TD loss:   3.017, Episode:  520, Epsilon: 0.01
Iteration:   93100, Train reward: -107.254, Eval reward: -89.428, TD loss:   3.322, Episode:  520, Epsilon: 0.01
Iteration:   93200, Train reward: -107.254, Eval reward: -89.428, TD loss:   2.919, Episode:  520, Epsilon: 0.01
Iteration:   93300, Train reward: -107.254, Eval reward: -89.428, TD loss:   2.959, Episode:  520, Epsilon: 0.01
Iteration:   93400, Train reward: -107.254, Eval reward: -89.428, TD loss:   3.469, Episode:  520, Epsilon: 0.01
Iteration:   93500, Train reward: -107.254, Eval reward: -89.428, TD loss:   3.099, Episode:  520, Epsilon: 0.01
Iteration:   93600, Train reward: -107.254, Eval reward: -89.428, TD loss:   2.910, Episode:  520, Epsilon: 0.01
Iteration:   93700, Train reward: -107.254, Eval reward: -89.428, TD loss:   2.861, Episode:  520, Epsilon: 0.01
Iteration:   93800, Train reward: -107.254, Eval reward: -89.428, TD loss:   3.162, Episode:  520, Epsilon: 0.01
Iteration:   93900, Train reward: -106.847, Eval reward: -89.428, TD loss:   2.889, Episode:  521, Epsilon: 0.01
Iteration:   94000, Train reward: -106.847, Eval reward: -85.924, TD loss:   3.065, Episode:  521, Epsilon: 0.01
Iteration:   94100, Train reward: -106.847, Eval reward: -85.924, TD loss:   3.037, Episode:  521, Epsilon: 0.01
Iteration:   94200, Train reward: -106.847, Eval reward: -85.924, TD loss:   3.216, Episode:  521, Epsilon: 0.01
Iteration:   94300, Train reward: -106.847, Eval reward: -85.924, TD loss:   3.138, Episode:  521, Epsilon: 0.01
Iteration:   94400, Train reward: -106.847, Eval reward: -85.924, TD loss:   3.030, Episode:  521, Epsilon: 0.01
Iteration:   94500, Train reward: -106.847, Eval reward: -85.924, TD loss:   2.916, Episode:  521, Epsilon: 0.01
Iteration:   94600, Train reward: -106.847, Eval reward: -85.924, TD loss:   3.036, Episode:  521, Epsilon: 0.01
Iteration:   94700, Train reward: -106.847, Eval reward: -85.924, TD loss:   2.723, Episode:  521, Epsilon: 0.01
Iteration:   94800, Train reward: -106.847, Eval reward: -85.924, TD loss:   3.012, Episode:  521, Epsilon: 0.01
Iteration:   94900, Train reward: -109.841, Eval reward: -85.924, TD loss:   2.980, Episode:  522, Epsilon: 0.01
Iteration:   95000, Train reward: -109.841, Eval reward: -103.174, TD loss:   2.982, Episode:  522, Epsilon: 0.01
Iteration:   95100, Train reward: -109.841, Eval reward: -103.174, TD loss:   3.146, Episode:  522, Epsilon: 0.01
Iteration:   95200, Train reward: -109.841, Eval reward: -103.174, TD loss:   3.098, Episode:  522, Epsilon: 0.01
Iteration:   95300, Train reward: -109.841, Eval reward: -103.174, TD loss:   2.940, Episode:  522, Epsilon: 0.01
Iteration:   95400, Train reward: -109.841, Eval reward: -103.174, TD loss:   2.997, Episode:  522, Epsilon: 0.01
Iteration:   95500, Train reward: -109.841, Eval reward: -103.174, TD loss:   3.042, Episode:  522, Epsilon: 0.01
Iteration:   95600, Train reward: -109.841, Eval reward: -103.174, TD loss:   3.089, Episode:  522, Epsilon: 0.01
Iteration:   95700, Train reward: -109.841, Eval reward: -103.174, TD loss:   2.985, Episode:  522, Epsilon: 0.01
Iteration:   95800, Train reward: -109.841, Eval reward: -103.174, TD loss:   3.127, Episode:  522, Epsilon: 0.01
Iteration:   95900, Train reward: -110.574, Eval reward: -103.174, TD loss:   3.162, Episode:  523, Epsilon: 0.01
Iteration:   96000, Train reward: -110.574, Eval reward: -83.374, TD loss:   3.059, Episode:  523, Epsilon: 0.01
Iteration:   96100, Train reward: -110.574, Eval reward: -83.374, TD loss:   2.971, Episode:  523, Epsilon: 0.01
Iteration:   96200, Train reward: -110.574, Eval reward: -83.374, TD loss:   2.773, Episode:  523, Epsilon: 0.01
Iteration:   96300, Train reward: -110.574, Eval reward: -83.374, TD loss:   2.766, Episode:  523, Epsilon: 0.01
Iteration:   96400, Train reward: -110.574, Eval reward: -83.374, TD loss:   2.804, Episode:  523, Epsilon: 0.01
Iteration:   96500, Train reward: -110.574, Eval reward: -83.374, TD loss:   2.849, Episode:  523, Epsilon: 0.01
Iteration:   96600, Train reward: -110.574, Eval reward: -83.374, TD loss:   2.867, Episode:  523, Epsilon: 0.01
Iteration:   96700, Train reward: -110.574, Eval reward: -83.374, TD loss:   2.919, Episode:  523, Epsilon: 0.01
Iteration:   96800, Train reward: -110.574, Eval reward: -83.374, TD loss:   3.096, Episode:  523, Epsilon: 0.01
Iteration:   96900, Train reward: -107.697, Eval reward: -83.374, TD loss:   2.642, Episode:  524, Epsilon: 0.01
Iteration:   97000, Train reward: -110.271, Eval reward: -120.098, TD loss:   2.964, Episode:  525, Epsilon: 0.01
Iteration:   97100, Train reward: -110.271, Eval reward: -120.098, TD loss:   2.658, Episode:  525, Epsilon: 0.01
Iteration:   97200, Train reward: -110.271, Eval reward: -120.098, TD loss:   2.918, Episode:  525, Epsilon: 0.01
Iteration:   97300, Train reward: -110.271, Eval reward: -120.098, TD loss:   2.802, Episode:  525, Epsilon: 0.01
Iteration:   97400, Train reward: -110.271, Eval reward: -120.098, TD loss:   2.780, Episode:  525, Epsilon: 0.01
Iteration:   97500, Train reward: -110.271, Eval reward: -120.098, TD loss:   2.985, Episode:  525, Epsilon: 0.01
Iteration:   97600, Train reward: -110.271, Eval reward: -120.098, TD loss:   2.704, Episode:  525, Epsilon: 0.01
Iteration:   97700, Train reward: -110.271, Eval reward: -120.098, TD loss:   2.901, Episode:  525, Epsilon: 0.01
Iteration:   97800, Train reward: -110.271, Eval reward: -120.098, TD loss:   2.983, Episode:  525, Epsilon: 0.01
Iteration:   97900, Train reward: -110.271, Eval reward: -120.098, TD loss:   2.811, Episode:  525, Epsilon: 0.01
Iteration:   98000, Train reward: -108.788, Eval reward: -118.524, TD loss:   2.956, Episode:  526, Epsilon: 0.01
Iteration:   98100, Train reward: -108.788, Eval reward: -118.524, TD loss:   3.070, Episode:  526, Epsilon: 0.01
Iteration:   98200, Train reward: -108.788, Eval reward: -118.524, TD loss:   2.808, Episode:  526, Epsilon: 0.01
Iteration:   98300, Train reward: -108.788, Eval reward: -118.524, TD loss:   2.687, Episode:  526, Epsilon: 0.01
Iteration:   98400, Train reward: -108.788, Eval reward: -118.524, TD loss:   2.865, Episode:  526, Epsilon: 0.01
Iteration:   98500, Train reward: -108.788, Eval reward: -118.524, TD loss:   2.714, Episode:  526, Epsilon: 0.01
Iteration:   98600, Train reward: -108.788, Eval reward: -118.524, TD loss:   3.373, Episode:  526, Epsilon: 0.01
Iteration:   98700, Train reward: -108.788, Eval reward: -118.524, TD loss:   2.903, Episode:  526, Epsilon: 0.01
Iteration:   98800, Train reward: -108.788, Eval reward: -118.524, TD loss:   2.903, Episode:  526, Epsilon: 0.01
Iteration:   98900, Train reward: -108.788, Eval reward: -118.524, TD loss:   2.932, Episode:  526, Epsilon: 0.01
Iteration:   99000, Train reward: -107.455, Eval reward: -117.945, TD loss:   2.824, Episode:  527, Epsilon: 0.01
Iteration:   99100, Train reward: -107.455, Eval reward: -117.945, TD loss:   2.735, Episode:  527, Epsilon: 0.01
Iteration:   99200, Train reward: -107.455, Eval reward: -117.945, TD loss:   2.964, Episode:  527, Epsilon: 0.01
Iteration:   99300, Train reward: -107.455, Eval reward: -117.945, TD loss:   2.891, Episode:  527, Epsilon: 0.01
Iteration:   99400, Train reward: -107.455, Eval reward: -117.945, TD loss:   2.923, Episode:  527, Epsilon: 0.01
Iteration:   99500, Train reward: -107.455, Eval reward: -117.945, TD loss:   3.127, Episode:  527, Epsilon: 0.01
Iteration:   99600, Train reward: -107.455, Eval reward: -117.945, TD loss:   2.730, Episode:  527, Epsilon: 0.01
Iteration:   99700, Train reward: -107.455, Eval reward: -117.945, TD loss:   2.536, Episode:  527, Epsilon: 0.01
Iteration:   99800, Train reward: -107.455, Eval reward: -117.945, TD loss:   2.697, Episode:  527, Epsilon: 0.01
Iteration:   99900, Train reward: -107.455, Eval reward: -117.945, TD loss:   2.860, Episode:  527, Epsilon: 0.01
Iteration:  100000, Train reward: -108.124, Eval reward: -171.540, TD loss:   2.986, Episode:  528, Epsilon: 0.01
Iteration:  100100, Train reward: -108.124, Eval reward: -171.540, TD loss:   2.856, Episode:  528, Epsilon: 0.01
Iteration:  100200, Train reward: -108.124, Eval reward: -171.540, TD loss:   2.696, Episode:  528, Epsilon: 0.01
Iteration:  100300, Train reward: -106.116, Eval reward: -171.540, TD loss:   2.834, Episode:  529, Epsilon: 0.01
Iteration:  100400, Train reward: -106.116, Eval reward: -171.540, TD loss:   3.116, Episode:  529, Epsilon: 0.01
Iteration:  100500, Train reward: -106.116, Eval reward: -171.540, TD loss:   2.562, Episode:  529, Epsilon: 0.01
Iteration:  100600, Train reward: -106.116, Eval reward: -171.540, TD loss:   2.904, Episode:  529, Epsilon: 0.01
Iteration:  100700, Train reward: -106.116, Eval reward: -171.540, TD loss:   2.607, Episode:  529, Epsilon: 0.01
Iteration:  100800, Train reward: -106.116, Eval reward: -171.540, TD loss:   2.440, Episode:  529, Epsilon: 0.01
Iteration:  100900, Train reward: -106.116, Eval reward: -171.540, TD loss:   2.608, Episode:  529, Epsilon: 0.01
Iteration:  101000, Train reward: -106.116, Eval reward: -165.789, TD loss:   2.748, Episode:  529, Epsilon: 0.01
Iteration:  101100, Train reward: -106.116, Eval reward: -165.789, TD loss:   2.585, Episode:  529, Epsilon: 0.01
Iteration:  101200, Train reward: -106.116, Eval reward: -165.789, TD loss:   2.732, Episode:  529, Epsilon: 0.01
Iteration:  101300, Train reward: -104.397, Eval reward: -165.789, TD loss:   2.656, Episode:  530, Epsilon: 0.01
Iteration:  101400, Train reward: -104.397, Eval reward: -165.789, TD loss:   2.605, Episode:  530, Epsilon: 0.01
Iteration:  101500, Train reward: -104.397, Eval reward: -165.789, TD loss:   2.535, Episode:  530, Epsilon: 0.01
Iteration:  101600, Train reward: -104.397, Eval reward: -165.789, TD loss:   2.638, Episode:  530, Epsilon: 0.01
Iteration:  101700, Train reward: -104.397, Eval reward: -165.789, TD loss:   2.667, Episode:  530, Epsilon: 0.01
Iteration:  101800, Train reward: -104.397, Eval reward: -165.789, TD loss:   2.705, Episode:  530, Epsilon: 0.01
Iteration:  101900, Train reward: -104.397, Eval reward: -165.789, TD loss:   2.581, Episode:  530, Epsilon: 0.01
Iteration:  102000, Train reward: -104.397, Eval reward: -312.439, TD loss:   2.713, Episode:  530, Epsilon: 0.01
Iteration:  102100, Train reward: -104.397, Eval reward: -312.439, TD loss:   2.898, Episode:  530, Epsilon: 0.01
Iteration:  102200, Train reward: -104.397, Eval reward: -312.439, TD loss:   2.745, Episode:  530, Epsilon: 0.01
Iteration:  102300, Train reward: -101.570, Eval reward: -312.439, TD loss:   2.561, Episode:  531, Epsilon: 0.01
Iteration:  102400, Train reward: -101.570, Eval reward: -312.439, TD loss:   2.634, Episode:  531, Epsilon: 0.01
Iteration:  102500, Train reward: -101.570, Eval reward: -312.439, TD loss:   2.894, Episode:  531, Epsilon: 0.01
Iteration:  102600, Train reward: -101.570, Eval reward: -312.439, TD loss:   2.465, Episode:  531, Epsilon: 0.01
Iteration:  102700, Train reward: -101.570, Eval reward: -312.439, TD loss:   2.566, Episode:  531, Epsilon: 0.01
Iteration:  102800, Train reward: -101.570, Eval reward: -312.439, TD loss:   2.721, Episode:  531, Epsilon: 0.01
Iteration:  102900, Train reward: -101.570, Eval reward: -312.439, TD loss:   2.786, Episode:  531, Epsilon: 0.01
Iteration:  103000, Train reward: -101.570, Eval reward: -84.694, TD loss:   2.650, Episode:  531, Epsilon: 0.01
Iteration:  103100, Train reward: -101.570, Eval reward: -84.694, TD loss:   2.382, Episode:  531, Epsilon: 0.01
Iteration:  103200, Train reward: -101.570, Eval reward: -84.694, TD loss:   2.479, Episode:  531, Epsilon: 0.01
Iteration:  103300, Train reward: -101.782, Eval reward: -84.694, TD loss:   2.785, Episode:  532, Epsilon: 0.01
Iteration:  103400, Train reward: -101.782, Eval reward: -84.694, TD loss:   2.577, Episode:  532, Epsilon: 0.01
Iteration:  103500, Train reward: -101.782, Eval reward: -84.694, TD loss:   2.682, Episode:  532, Epsilon: 0.01
Iteration:  103600, Train reward: -101.782, Eval reward: -84.694, TD loss:   2.321, Episode:  532, Epsilon: 0.01
Iteration:  103700, Train reward: -101.782, Eval reward: -84.694, TD loss:   2.484, Episode:  532, Epsilon: 0.01
Iteration:  103800, Train reward: -101.782, Eval reward: -84.694, TD loss:   2.376, Episode:  532, Epsilon: 0.01
Iteration:  103900, Train reward: -101.782, Eval reward: -84.694, TD loss:   2.570, Episode:  532, Epsilon: 0.01
Iteration:  104000, Train reward: -101.782, Eval reward: -128.182, TD loss:   2.718, Episode:  532, Epsilon: 0.01
Iteration:  104100, Train reward: -101.782, Eval reward: -128.182, TD loss:   2.769, Episode:  532, Epsilon: 0.01
Iteration:  104200, Train reward: -101.782, Eval reward: -128.182, TD loss:   2.458, Episode:  532, Epsilon: 0.01
Iteration:  104300, Train reward: -98.367, Eval reward: -128.182, TD loss:   2.398, Episode:  533, Epsilon: 0.01
Iteration:  104400, Train reward: -98.367, Eval reward: -128.182, TD loss:   2.447, Episode:  533, Epsilon: 0.01
Iteration:  104500, Train reward: -98.367, Eval reward: -128.182, TD loss:   2.579, Episode:  533, Epsilon: 0.01
Iteration:  104600, Train reward: -98.367, Eval reward: -128.182, TD loss:   2.650, Episode:  533, Epsilon: 0.01
Iteration:  104700, Train reward: -98.367, Eval reward: -128.182, TD loss:   2.587, Episode:  533, Epsilon: 0.01
Iteration:  104800, Train reward: -98.367, Eval reward: -128.182, TD loss:   2.746, Episode:  533, Epsilon: 0.01
Iteration:  104900, Train reward: -98.367, Eval reward: -128.182, TD loss:   2.516, Episode:  533, Epsilon: 0.01
Iteration:  105000, Train reward: -98.367, Eval reward: -130.177, TD loss:   2.372, Episode:  533, Epsilon: 0.01
Iteration:  105100, Train reward: -98.367, Eval reward: -130.177, TD loss:   2.682, Episode:  533, Epsilon: 0.01
Iteration:  105200, Train reward: -98.367, Eval reward: -130.177, TD loss:   2.526, Episode:  533, Epsilon: 0.01
Iteration:  105300, Train reward: -97.357, Eval reward: -130.177, TD loss:   2.683, Episode:  534, Epsilon: 0.01
Iteration:  105400, Train reward: -97.357, Eval reward: -130.177, TD loss:   2.553, Episode:  534, Epsilon: 0.01
Iteration:  105500, Train reward: -97.357, Eval reward: -130.177, TD loss:   2.571, Episode:  534, Epsilon: 0.01
Iteration:  105600, Train reward: -97.357, Eval reward: -130.177, TD loss:   2.416, Episode:  534, Epsilon: 0.01
Iteration:  105700, Train reward: -97.357, Eval reward: -130.177, TD loss:   2.537, Episode:  534, Epsilon: 0.01
Iteration:  105800, Train reward: -97.357, Eval reward: -130.177, TD loss:   2.415, Episode:  534, Epsilon: 0.01
Iteration:  105900, Train reward: -97.357, Eval reward: -130.177, TD loss:   2.386, Episode:  534, Epsilon: 0.01
Iteration:  106000, Train reward: -97.357, Eval reward: -126.847, TD loss:   2.432, Episode:  534, Epsilon: 0.01
Iteration:  106100, Train reward: -97.357, Eval reward: -126.847, TD loss:   2.496, Episode:  534, Epsilon: 0.01
Iteration:  106200, Train reward: -97.357, Eval reward: -126.847, TD loss:   2.543, Episode:  534, Epsilon: 0.01
Iteration:  106300, Train reward: -96.060, Eval reward: -126.847, TD loss:   2.462, Episode:  535, Epsilon: 0.01
Iteration:  106400, Train reward: -96.060, Eval reward: -126.847, TD loss:   2.370, Episode:  535, Epsilon: 0.01
Iteration:  106500, Train reward: -96.060, Eval reward: -126.847, TD loss:   2.546, Episode:  535, Epsilon: 0.01
Iteration:  106600, Train reward: -96.060, Eval reward: -126.847, TD loss:   2.606, Episode:  535, Epsilon: 0.01
Iteration:  106700, Train reward: -96.060, Eval reward: -126.847, TD loss:   2.425, Episode:  535, Epsilon: 0.01
Iteration:  106800, Train reward: -96.060, Eval reward: -126.847, TD loss:   2.526, Episode:  535, Epsilon: 0.01
Iteration:  106900, Train reward: -96.060, Eval reward: -126.847, TD loss:   2.429, Episode:  535, Epsilon: 0.01
Iteration:  107000, Train reward: -96.060, Eval reward: -135.824, TD loss:   2.442, Episode:  535, Epsilon: 0.01
Iteration:  107100, Train reward: -96.060, Eval reward: -135.824, TD loss:   2.525, Episode:  535, Epsilon: 0.01
Iteration:  107200, Train reward: -96.060, Eval reward: -135.824, TD loss:   2.503, Episode:  535, Epsilon: 0.01
Iteration:  107300, Train reward: -99.241, Eval reward: -135.824, TD loss:   2.589, Episode:  536, Epsilon: 0.01
Iteration:  107400, Train reward: -99.241, Eval reward: -135.824, TD loss:   2.450, Episode:  536, Epsilon: 0.01
Iteration:  107500, Train reward: -103.363, Eval reward: -135.824, TD loss:   2.573, Episode:  537, Epsilon: 0.01
Iteration:  107600, Train reward: -103.363, Eval reward: -135.824, TD loss:   2.794, Episode:  537, Epsilon: 0.01
Iteration:  107700, Train reward: -103.363, Eval reward: -135.824, TD loss:   2.263, Episode:  537, Epsilon: 0.01
Iteration:  107800, Train reward: -103.363, Eval reward: -135.824, TD loss:   2.758, Episode:  537, Epsilon: 0.01
Iteration:  107900, Train reward: -103.363, Eval reward: -135.824, TD loss:   2.643, Episode:  537, Epsilon: 0.01
Iteration:  108000, Train reward: -103.363, Eval reward: -141.829, TD loss:   2.613, Episode:  537, Epsilon: 0.01
Iteration:  108100, Train reward: -103.363, Eval reward: -141.829, TD loss:   2.330, Episode:  537, Epsilon: 0.01
Iteration:  108200, Train reward: -103.363, Eval reward: -141.829, TD loss:   2.606, Episode:  537, Epsilon: 0.01
Iteration:  108300, Train reward: -106.791, Eval reward: -141.829, TD loss:   2.452, Episode:  538, Epsilon: 0.01
Iteration:  108400, Train reward: -106.791, Eval reward: -141.829, TD loss:   2.544, Episode:  538, Epsilon: 0.01
Iteration:  108500, Train reward: -106.791, Eval reward: -141.829, TD loss:   2.523, Episode:  538, Epsilon: 0.01
Iteration:  108600, Train reward: -106.791, Eval reward: -141.829, TD loss:   2.491, Episode:  538, Epsilon: 0.01
Iteration:  108700, Train reward: -106.791, Eval reward: -141.829, TD loss:   2.626, Episode:  538, Epsilon: 0.01
Iteration:  108800, Train reward: -106.791, Eval reward: -141.829, TD loss:   2.604, Episode:  538, Epsilon: 0.01
Iteration:  108900, Train reward: -106.791, Eval reward: -141.829, TD loss:   2.313, Episode:  538, Epsilon: 0.01
Iteration:  109000, Train reward: -106.791, Eval reward: -217.402, TD loss:   2.652, Episode:  538, Epsilon: 0.01
Iteration:  109100, Train reward: -106.791, Eval reward: -217.402, TD loss:   2.500, Episode:  538, Epsilon: 0.01
Iteration:  109200, Train reward: -106.791, Eval reward: -217.402, TD loss:   2.445, Episode:  538, Epsilon: 0.01
Iteration:  109300, Train reward: -108.962, Eval reward: -217.402, TD loss:   2.688, Episode:  539, Epsilon: 0.01
Iteration:  109400, Train reward: -108.962, Eval reward: -217.402, TD loss:   2.446, Episode:  539, Epsilon: 0.01
Iteration:  109500, Train reward: -108.962, Eval reward: -217.402, TD loss:   2.625, Episode:  539, Epsilon: 0.01
Iteration:  109600, Train reward: -108.962, Eval reward: -217.402, TD loss:   2.522, Episode:  539, Epsilon: 0.01
Iteration:  109700, Train reward: -108.962, Eval reward: -217.402, TD loss:   2.405, Episode:  539, Epsilon: 0.01
Iteration:  109800, Train reward: -108.962, Eval reward: -217.402, TD loss:   2.283, Episode:  539, Epsilon: 0.01
Iteration:  109900, Train reward: -108.962, Eval reward: -217.402, TD loss:   2.441, Episode:  539, Epsilon: 0.01
Iteration:  110000, Train reward: -108.962, Eval reward: -177.215, TD loss:   2.377, Episode:  539, Epsilon: 0.01
Iteration:  110100, Train reward: -108.962, Eval reward: -177.215, TD loss:   2.362, Episode:  539, Epsilon: 0.01
Iteration:  110200, Train reward: -108.962, Eval reward: -177.215, TD loss:   2.355, Episode:  539, Epsilon: 0.01
Iteration:  110300, Train reward: -108.368, Eval reward: -177.215, TD loss:   2.159, Episode:  540, Epsilon: 0.01
Iteration:  110400, Train reward: -108.368, Eval reward: -177.215, TD loss:   2.460, Episode:  540, Epsilon: 0.01
Iteration:  110500, Train reward: -108.368, Eval reward: -177.215, TD loss:   2.362, Episode:  540, Epsilon: 0.01
Iteration:  110600, Train reward: -108.368, Eval reward: -177.215, TD loss:   2.579, Episode:  540, Epsilon: 0.01
Iteration:  110700, Train reward: -108.368, Eval reward: -177.215, TD loss:   2.645, Episode:  540, Epsilon: 0.01
Iteration:  110800, Train reward: -108.368, Eval reward: -177.215, TD loss:   2.263, Episode:  540, Epsilon: 0.01
Iteration:  110900, Train reward: -108.368, Eval reward: -177.215, TD loss:   2.363, Episode:  540, Epsilon: 0.01
Iteration:  111000, Train reward: -108.368, Eval reward: -148.496, TD loss:   2.315, Episode:  540, Epsilon: 0.01
Iteration:  111100, Train reward: -108.368, Eval reward: -148.496, TD loss:   2.327, Episode:  540, Epsilon: 0.01
Iteration:  111200, Train reward: -108.368, Eval reward: -148.496, TD loss:   2.136, Episode:  540, Epsilon: 0.01
Iteration:  111300, Train reward: -111.989, Eval reward: -148.496, TD loss:   2.541, Episode:  541, Epsilon: 0.01
Iteration:  111400, Train reward: -111.989, Eval reward: -148.496, TD loss:   2.309, Episode:  541, Epsilon: 0.01
Iteration:  111500, Train reward: -111.989, Eval reward: -148.496, TD loss:   2.383, Episode:  541, Epsilon: 0.01
Iteration:  111600, Train reward: -111.989, Eval reward: -148.496, TD loss:   2.148, Episode:  541, Epsilon: 0.01
Iteration:  111700, Train reward: -111.989, Eval reward: -148.496, TD loss:   2.303, Episode:  541, Epsilon: 0.01
Iteration:  111800, Train reward: -111.989, Eval reward: -148.496, TD loss:   2.217, Episode:  541, Epsilon: 0.01
Iteration:  111900, Train reward: -111.989, Eval reward: -148.496, TD loss:   2.264, Episode:  541, Epsilon: 0.01
Iteration:  112000, Train reward: -111.989, Eval reward: -296.343, TD loss:   2.223, Episode:  541, Epsilon: 0.01
Iteration:  112100, Train reward: -111.989, Eval reward: -296.343, TD loss:   1.876, Episode:  541, Epsilon: 0.01
Iteration:  112200, Train reward: -111.989, Eval reward: -296.343, TD loss:   2.364, Episode:  541, Epsilon: 0.01
Iteration:  112300, Train reward: -111.008, Eval reward: -296.343, TD loss:   2.187, Episode:  542, Epsilon: 0.01
Iteration:  112400, Train reward: -111.008, Eval reward: -296.343, TD loss:   2.231, Episode:  542, Epsilon: 0.01
Iteration:  112500, Train reward: -111.008, Eval reward: -296.343, TD loss:   2.133, Episode:  542, Epsilon: 0.01
Iteration:  112600, Train reward: -111.008, Eval reward: -296.343, TD loss:   2.381, Episode:  542, Epsilon: 0.01
Iteration:  112700, Train reward: -111.008, Eval reward: -296.343, TD loss:   2.217, Episode:  542, Epsilon: 0.01
Iteration:  112800, Train reward: -111.008, Eval reward: -296.343, TD loss:   1.908, Episode:  542, Epsilon: 0.01
Iteration:  112900, Train reward: -111.008, Eval reward: -296.343, TD loss:   2.190, Episode:  542, Epsilon: 0.01
Iteration:  113000, Train reward: -111.008, Eval reward: -757.493, TD loss:   2.201, Episode:  542, Epsilon: 0.01
Iteration:  113100, Train reward: -140.493, Eval reward: -757.493, TD loss:   2.121, Episode:  543, Epsilon: 0.01
Iteration:  113200, Train reward: -140.493, Eval reward: -757.493, TD loss:   2.065, Episode:  543, Epsilon: 0.01
Iteration:  113300, Train reward: -140.493, Eval reward: -757.493, TD loss:   2.036, Episode:  543, Epsilon: 0.01
Iteration:  113400, Train reward: -140.493, Eval reward: -757.493, TD loss:   2.226, Episode:  543, Epsilon: 0.01
Iteration:  113500, Train reward: -140.493, Eval reward: -757.493, TD loss:   2.163, Episode:  543, Epsilon: 0.01
Iteration:  113600, Train reward: -140.493, Eval reward: -757.493, TD loss:   2.387, Episode:  543, Epsilon: 0.01
Iteration:  113700, Train reward: -140.493, Eval reward: -757.493, TD loss:   2.346, Episode:  543, Epsilon: 0.01
Iteration:  113800, Train reward: -140.493, Eval reward: -757.493, TD loss:   2.259, Episode:  543, Epsilon: 0.01
Iteration:  113900, Train reward: -140.493, Eval reward: -757.493, TD loss:   2.421, Episode:  543, Epsilon: 0.01
Iteration:  114000, Train reward: -178.085, Eval reward: -555.897, TD loss:   2.136, Episode:  544, Epsilon: 0.01
Iteration:  114100, Train reward: -178.085, Eval reward: -555.897, TD loss:   2.546, Episode:  544, Epsilon: 0.01
Iteration:  114200, Train reward: -178.085, Eval reward: -555.897, TD loss:   2.128, Episode:  544, Epsilon: 0.01
Iteration:  114300, Train reward: -178.085, Eval reward: -555.897, TD loss:   2.350, Episode:  544, Epsilon: 0.01
Iteration:  114400, Train reward: -178.085, Eval reward: -555.897, TD loss:   2.309, Episode:  544, Epsilon: 0.01
Iteration:  114500, Train reward: -178.085, Eval reward: -555.897, TD loss:   2.297, Episode:  544, Epsilon: 0.01
Iteration:  114600, Train reward: -178.085, Eval reward: -555.897, TD loss:   2.444, Episode:  544, Epsilon: 0.01
Iteration:  114700, Train reward: -178.085, Eval reward: -555.897, TD loss:   2.376, Episode:  544, Epsilon: 0.01
Iteration:  114800, Train reward: -178.085, Eval reward: -555.897, TD loss:   1.993, Episode:  544, Epsilon: 0.01
Iteration:  114900, Train reward: -178.085, Eval reward: -555.897, TD loss:   1.993, Episode:  544, Epsilon: 0.01
Iteration:  115000, Train reward: -177.820, Eval reward: -176.977, TD loss:   2.011, Episode:  545, Epsilon: 0.01
Iteration:  115100, Train reward: -177.820, Eval reward: -176.977, TD loss:   2.328, Episode:  545, Epsilon: 0.01
Iteration:  115200, Train reward: -177.820, Eval reward: -176.977, TD loss:   2.291, Episode:  545, Epsilon: 0.01
Iteration:  115300, Train reward: -177.820, Eval reward: -176.977, TD loss:   2.312, Episode:  545, Epsilon: 0.01
Iteration:  115400, Train reward: -177.820, Eval reward: -176.977, TD loss:   2.473, Episode:  545, Epsilon: 0.01
Iteration:  115500, Train reward: -177.820, Eval reward: -176.977, TD loss:   2.423, Episode:  545, Epsilon: 0.01
Iteration:  115600, Train reward: -177.820, Eval reward: -176.977, TD loss:   2.204, Episode:  545, Epsilon: 0.01
Iteration:  115700, Train reward: -177.820, Eval reward: -176.977, TD loss:   2.368, Episode:  545, Epsilon: 0.01
Iteration:  115800, Train reward: -177.820, Eval reward: -176.977, TD loss:   2.636, Episode:  545, Epsilon: 0.01
Iteration:  115900, Train reward: -177.820, Eval reward: -176.977, TD loss:   2.166, Episode:  545, Epsilon: 0.01
Iteration:  116000, Train reward: -178.707, Eval reward: -157.449, TD loss:   2.071, Episode:  546, Epsilon: 0.01
Iteration:  116100, Train reward: -178.707, Eval reward: -157.449, TD loss:   2.121, Episode:  546, Epsilon: 0.01
Iteration:  116200, Train reward: -178.707, Eval reward: -157.449, TD loss:   2.125, Episode:  546, Epsilon: 0.01
Iteration:  116300, Train reward: -178.707, Eval reward: -157.449, TD loss:   2.136, Episode:  546, Epsilon: 0.01
Iteration:  116400, Train reward: -178.707, Eval reward: -157.449, TD loss:   2.413, Episode:  546, Epsilon: 0.01
Iteration:  116500, Train reward: -178.707, Eval reward: -157.449, TD loss:   2.453, Episode:  546, Epsilon: 0.01
Iteration:  116600, Train reward: -178.707, Eval reward: -157.449, TD loss:   2.317, Episode:  546, Epsilon: 0.01
Iteration:  116700, Train reward: -178.707, Eval reward: -157.449, TD loss:   2.423, Episode:  546, Epsilon: 0.01
Iteration:  116800, Train reward: -178.707, Eval reward: -157.449, TD loss:   2.296, Episode:  546, Epsilon: 0.01
Iteration:  116900, Train reward: -178.707, Eval reward: -157.449, TD loss:   2.186, Episode:  546, Epsilon: 0.01
Iteration:  117000, Train reward: -178.845, Eval reward: -256.274, TD loss:   2.345, Episode:  547, Epsilon: 0.01
Iteration:  117100, Train reward: -178.845, Eval reward: -256.274, TD loss:   2.377, Episode:  547, Epsilon: 0.01
Iteration:  117200, Train reward: -178.845, Eval reward: -256.274, TD loss:   2.120, Episode:  547, Epsilon: 0.01
Iteration:  117300, Train reward: -178.845, Eval reward: -256.274, TD loss:   2.378, Episode:  547, Epsilon: 0.01
Iteration:  117400, Train reward: -178.845, Eval reward: -256.274, TD loss:   2.441, Episode:  547, Epsilon: 0.01
Iteration:  117500, Train reward: -178.845, Eval reward: -256.274, TD loss:   2.207, Episode:  547, Epsilon: 0.01
Iteration:  117600, Train reward: -178.845, Eval reward: -256.274, TD loss:   2.362, Episode:  547, Epsilon: 0.01
Iteration:  117700, Train reward: -178.845, Eval reward: -256.274, TD loss:   2.275, Episode:  547, Epsilon: 0.01
Iteration:  117800, Train reward: -178.845, Eval reward: -256.274, TD loss:   2.192, Episode:  547, Epsilon: 0.01
Iteration:  117900, Train reward: -178.845, Eval reward: -256.274, TD loss:   2.260, Episode:  547, Epsilon: 0.01
Iteration:  118000, Train reward: -179.093, Eval reward: -219.589, TD loss:   2.142, Episode:  548, Epsilon: 0.01
Iteration:  118100, Train reward: -179.093, Eval reward: -219.589, TD loss:   2.060, Episode:  548, Epsilon: 0.01
Iteration:  118200, Train reward: -179.093, Eval reward: -219.589, TD loss:   2.245, Episode:  548, Epsilon: 0.01
Iteration:  118300, Train reward: -179.093, Eval reward: -219.589, TD loss:   2.094, Episode:  548, Epsilon: 0.01
Iteration:  118400, Train reward: -179.093, Eval reward: -219.589, TD loss:   2.170, Episode:  548, Epsilon: 0.01
Iteration:  118500, Train reward: -179.093, Eval reward: -219.589, TD loss:   2.291, Episode:  548, Epsilon: 0.01
Iteration:  118600, Train reward: -179.093, Eval reward: -219.589, TD loss:   2.051, Episode:  548, Epsilon: 0.01
Iteration:  118700, Train reward: -179.093, Eval reward: -219.589, TD loss:   2.302, Episode:  548, Epsilon: 0.01
Iteration:  118800, Train reward: -179.093, Eval reward: -219.589, TD loss:   2.230, Episode:  548, Epsilon: 0.01
Iteration:  118900, Train reward: -179.093, Eval reward: -219.589, TD loss:   2.096, Episode:  548, Epsilon: 0.01
Iteration:  119000, Train reward: -181.664, Eval reward: -97.491, TD loss:   2.083, Episode:  549, Epsilon: 0.01
Iteration:  119100, Train reward: -181.664, Eval reward: -97.491, TD loss:   2.338, Episode:  549, Epsilon: 0.01
Iteration:  119200, Train reward: -181.664, Eval reward: -97.491, TD loss:   2.343, Episode:  549, Epsilon: 0.01
Iteration:  119300, Train reward: -181.664, Eval reward: -97.491, TD loss:   2.433, Episode:  549, Epsilon: 0.01
Iteration:  119400, Train reward: -181.664, Eval reward: -97.491, TD loss:   2.125, Episode:  549, Epsilon: 0.01
Iteration:  119500, Train reward: -181.664, Eval reward: -97.491, TD loss:   2.129, Episode:  549, Epsilon: 0.01
Iteration:  119600, Train reward: -181.664, Eval reward: -97.491, TD loss:   2.172, Episode:  549, Epsilon: 0.01
Iteration:  119700, Train reward: -181.664, Eval reward: -97.491, TD loss:   2.089, Episode:  549, Epsilon: 0.01
Iteration:  119800, Train reward: -181.664, Eval reward: -97.491, TD loss:   2.039, Episode:  549, Epsilon: 0.01
Iteration:  119900, Train reward: -181.664, Eval reward: -97.491, TD loss:   2.200, Episode:  549, Epsilon: 0.01
Iteration:  120000, Train reward: -183.435, Eval reward: -114.250, TD loss:   2.347, Episode:  550, Epsilon: 0.01
Iteration:  120100, Train reward: -183.435, Eval reward: -114.250, TD loss:   2.210, Episode:  550, Epsilon: 0.01
Iteration:  120200, Train reward: -183.435, Eval reward: -114.250, TD loss:   2.273, Episode:  550, Epsilon: 0.01
Iteration:  120300, Train reward: -183.435, Eval reward: -114.250, TD loss:   2.110, Episode:  550, Epsilon: 0.01
Iteration:  120400, Train reward: -183.435, Eval reward: -114.250, TD loss:   1.884, Episode:  550, Epsilon: 0.01
Iteration:  120500, Train reward: -183.435, Eval reward: -114.250, TD loss:   2.242, Episode:  550, Epsilon: 0.01
Iteration:  120600, Train reward: -183.435, Eval reward: -114.250, TD loss:   1.964, Episode:  550, Epsilon: 0.01
Iteration:  120700, Train reward: -183.435, Eval reward: -114.250, TD loss:   1.955, Episode:  550, Epsilon: 0.01
Iteration:  120800, Train reward: -183.435, Eval reward: -114.250, TD loss:   1.768, Episode:  550, Epsilon: 0.01
Iteration:  120900, Train reward: -183.435, Eval reward: -114.250, TD loss:   1.921, Episode:  550, Epsilon: 0.01
Iteration:  121000, Train reward: -185.856, Eval reward: -496.116, TD loss:   2.066, Episode:  551, Epsilon: 0.01
Iteration:  121100, Train reward: -185.856, Eval reward: -496.116, TD loss:   1.670, Episode:  551, Epsilon: 0.01
Iteration:  121200, Train reward: -185.856, Eval reward: -496.116, TD loss:   1.803, Episode:  551, Epsilon: 0.01
Iteration:  121300, Train reward: -185.856, Eval reward: -496.116, TD loss:   2.084, Episode:  551, Epsilon: 0.01
Iteration:  121400, Train reward: -185.856, Eval reward: -496.116, TD loss:   2.076, Episode:  551, Epsilon: 0.01
Iteration:  121500, Train reward: -185.856, Eval reward: -496.116, TD loss:   2.336, Episode:  551, Epsilon: 0.01
Iteration:  121600, Train reward: -185.856, Eval reward: -496.116, TD loss:   1.937, Episode:  551, Epsilon: 0.01
Iteration:  121700, Train reward: -185.856, Eval reward: -496.116, TD loss:   2.084, Episode:  551, Epsilon: 0.01
Iteration:  121800, Train reward: -185.856, Eval reward: -496.116, TD loss:   2.084, Episode:  551, Epsilon: 0.01
Iteration:  121900, Train reward: -185.856, Eval reward: -496.116, TD loss:   1.923, Episode:  551, Epsilon: 0.01
Iteration:  122000, Train reward: -186.409, Eval reward: -238.970, TD loss:   1.872, Episode:  552, Epsilon: 0.01
Iteration:  122100, Train reward: -201.528, Eval reward: -238.970, TD loss:   1.878, Episode:  553, Epsilon: 0.01
Iteration:  122200, Train reward: -201.528, Eval reward: -238.970, TD loss:   2.045, Episode:  553, Epsilon: 0.01
Iteration:  122300, Train reward: -201.528, Eval reward: -238.970, TD loss:   2.123, Episode:  553, Epsilon: 0.01
Iteration:  122400, Train reward: -212.210, Eval reward: -238.970, TD loss:   2.099, Episode:  554, Epsilon: 0.01
Iteration:  122500, Train reward: -212.210, Eval reward: -238.970, TD loss:   1.972, Episode:  554, Epsilon: 0.01
Iteration:  122600, Train reward: -212.210, Eval reward: -238.970, TD loss:   1.917, Episode:  554, Epsilon: 0.01
Iteration:  122700, Train reward: -212.210, Eval reward: -238.970, TD loss:   2.105, Episode:  554, Epsilon: 0.01
Iteration:  122800, Train reward: -212.210, Eval reward: -238.970, TD loss:   2.166, Episode:  554, Epsilon: 0.01
Iteration:  122900, Train reward: -212.210, Eval reward: -238.970, TD loss:   1.999, Episode:  554, Epsilon: 0.01
Iteration:  123000, Train reward: -212.210, Eval reward: -106.478, TD loss:   1.881, Episode:  554, Epsilon: 0.01
Iteration:  123100, Train reward: -212.210, Eval reward: -106.478, TD loss:   1.937, Episode:  554, Epsilon: 0.01
Iteration:  123200, Train reward: -212.210, Eval reward: -106.478, TD loss:   1.914, Episode:  554, Epsilon: 0.01
Iteration:  123300, Train reward: -212.210, Eval reward: -106.478, TD loss:   2.037, Episode:  554, Epsilon: 0.01
Iteration:  123400, Train reward: -211.438, Eval reward: -106.478, TD loss:   1.988, Episode:  555, Epsilon: 0.01
Iteration:  123500, Train reward: -211.438, Eval reward: -106.478, TD loss:   1.985, Episode:  555, Epsilon: 0.01
Iteration:  123600, Train reward: -211.438, Eval reward: -106.478, TD loss:   2.118, Episode:  555, Epsilon: 0.01
Iteration:  123700, Train reward: -211.438, Eval reward: -106.478, TD loss:   1.948, Episode:  555, Epsilon: 0.01
Iteration:  123800, Train reward: -211.438, Eval reward: -106.478, TD loss:   2.069, Episode:  555, Epsilon: 0.01
Iteration:  123900, Train reward: -211.438, Eval reward: -106.478, TD loss:   1.992, Episode:  555, Epsilon: 0.01
Iteration:  124000, Train reward: -211.438, Eval reward: -462.343, TD loss:   1.977, Episode:  555, Epsilon: 0.01
Iteration:  124100, Train reward: -211.438, Eval reward: -462.343, TD loss:   1.869, Episode:  555, Epsilon: 0.01
Iteration:  124200, Train reward: -211.438, Eval reward: -462.343, TD loss:   1.810, Episode:  555, Epsilon: 0.01
Iteration:  124300, Train reward: -211.438, Eval reward: -462.343, TD loss:   1.703, Episode:  555, Epsilon: 0.01
Iteration:  124400, Train reward: -209.957, Eval reward: -462.343, TD loss:   1.805, Episode:  556, Epsilon: 0.01
Iteration:  124500, Train reward: -209.957, Eval reward: -462.343, TD loss:   2.056, Episode:  556, Epsilon: 0.01
Iteration:  124600, Train reward: -209.957, Eval reward: -462.343, TD loss:   1.896, Episode:  556, Epsilon: 0.01
Iteration:  124700, Train reward: -209.957, Eval reward: -462.343, TD loss:   2.054, Episode:  556, Epsilon: 0.01
Iteration:  124800, Train reward: -209.957, Eval reward: -462.343, TD loss:   1.609, Episode:  556, Epsilon: 0.01
Iteration:  124900, Train reward: -209.957, Eval reward: -462.343, TD loss:   1.790, Episode:  556, Epsilon: 0.01
Iteration:  125000, Train reward: -209.957, Eval reward: -296.053, TD loss:   1.781, Episode:  556, Epsilon: 0.01
Iteration:  125100, Train reward: -209.957, Eval reward: -296.053, TD loss:   1.782, Episode:  556, Epsilon: 0.01
Iteration:  125200, Train reward: -209.957, Eval reward: -296.053, TD loss:   1.980, Episode:  556, Epsilon: 0.01
Iteration:  125300, Train reward: -209.957, Eval reward: -296.053, TD loss:   1.598, Episode:  556, Epsilon: 0.01
Iteration:  125400, Train reward: -204.168, Eval reward: -296.053, TD loss:   1.968, Episode:  557, Epsilon: 0.01
Iteration:  125500, Train reward: -204.168, Eval reward: -296.053, TD loss:   1.984, Episode:  557, Epsilon: 0.01
Iteration:  125600, Train reward: -204.168, Eval reward: -296.053, TD loss:   1.895, Episode:  557, Epsilon: 0.01
Iteration:  125700, Train reward: -204.168, Eval reward: -296.053, TD loss:   1.662, Episode:  557, Epsilon: 0.01
Iteration:  125800, Train reward: -204.168, Eval reward: -296.053, TD loss:   1.873, Episode:  557, Epsilon: 0.01
Iteration:  125900, Train reward: -204.168, Eval reward: -296.053, TD loss:   2.147, Episode:  557, Epsilon: 0.01
Iteration:  126000, Train reward: -204.168, Eval reward: -477.481, TD loss:   1.689, Episode:  557, Epsilon: 0.01
Iteration:  126100, Train reward: -204.168, Eval reward: -477.481, TD loss:   1.755, Episode:  557, Epsilon: 0.01
Iteration:  126200, Train reward: -204.168, Eval reward: -477.481, TD loss:   1.720, Episode:  557, Epsilon: 0.01
Iteration:  126300, Train reward: -204.168, Eval reward: -477.481, TD loss:   1.744, Episode:  557, Epsilon: 0.01
Iteration:  126400, Train reward: -199.551, Eval reward: -477.481, TD loss:   1.601, Episode:  558, Epsilon: 0.01
Iteration:  126500, Train reward: -199.551, Eval reward: -477.481, TD loss:   1.895, Episode:  558, Epsilon: 0.01
Iteration:  126600, Train reward: -199.551, Eval reward: -477.481, TD loss:   1.763, Episode:  558, Epsilon: 0.01
Iteration:  126700, Train reward: -199.551, Eval reward: -477.481, TD loss:   1.815, Episode:  558, Epsilon: 0.01
Iteration:  126800, Train reward: -199.551, Eval reward: -477.481, TD loss:   1.990, Episode:  558, Epsilon: 0.01
Iteration:  126900, Train reward: -205.271, Eval reward: -477.481, TD loss:   1.873, Episode:  559, Epsilon: 0.01
Iteration:  127000, Train reward: -232.300, Eval reward: -100.172, TD loss:   2.031, Episode:  560, Epsilon: 0.01
Iteration:  127100, Train reward: -232.300, Eval reward: -100.172, TD loss:   1.959, Episode:  560, Epsilon: 0.01
Iteration:  127200, Train reward: -232.300, Eval reward: -100.172, TD loss:   1.912, Episode:  560, Epsilon: 0.01
Iteration:  127300, Train reward: -232.300, Eval reward: -100.172, TD loss:   1.940, Episode:  560, Epsilon: 0.01
Iteration:  127400, Train reward: -232.300, Eval reward: -100.172, TD loss:   2.074, Episode:  560, Epsilon: 0.01
Iteration:  127500, Train reward: -236.909, Eval reward: -100.172, TD loss:   2.157, Episode:  561, Epsilon: 0.01
Iteration:  127600, Train reward: -236.909, Eval reward: -100.172, TD loss:   1.876, Episode:  561, Epsilon: 0.01
Iteration:  127700, Train reward: -236.909, Eval reward: -100.172, TD loss:   1.981, Episode:  561, Epsilon: 0.01
Iteration:  127800, Train reward: -236.909, Eval reward: -100.172, TD loss:   1.994, Episode:  561, Epsilon: 0.01
Iteration:  127900, Train reward: -236.909, Eval reward: -100.172, TD loss:   2.046, Episode:  561, Epsilon: 0.01
Iteration:  128000, Train reward: -236.909, Eval reward: -96.001, TD loss:   1.941, Episode:  561, Epsilon: 0.01
Iteration:  128100, Train reward: -236.909, Eval reward: -96.001, TD loss:   1.864, Episode:  561, Epsilon: 0.01
Iteration:  128200, Train reward: -236.909, Eval reward: -96.001, TD loss:   1.918, Episode:  561, Epsilon: 0.01
Iteration:  128300, Train reward: -236.909, Eval reward: -96.001, TD loss:   1.949, Episode:  561, Epsilon: 0.01
Iteration:  128400, Train reward: -236.909, Eval reward: -96.001, TD loss:   1.972, Episode:  561, Epsilon: 0.01
Iteration:  128500, Train reward: -237.045, Eval reward: -96.001, TD loss:   1.887, Episode:  562, Epsilon: 0.01
Iteration:  128600, Train reward: -237.045, Eval reward: -96.001, TD loss:   2.039, Episode:  562, Epsilon: 0.01
Iteration:  128700, Train reward: -237.045, Eval reward: -96.001, TD loss:   1.614, Episode:  562, Epsilon: 0.01
Iteration:  128800, Train reward: -237.045, Eval reward: -96.001, TD loss:   1.945, Episode:  562, Epsilon: 0.01
Iteration:  128900, Train reward: -237.045, Eval reward: -96.001, TD loss:   1.892, Episode:  562, Epsilon: 0.01
Iteration:  129000, Train reward: -237.045, Eval reward: -215.597, TD loss:   2.057, Episode:  562, Epsilon: 0.01
Iteration:  129100, Train reward: -237.045, Eval reward: -215.597, TD loss:   1.817, Episode:  562, Epsilon: 0.01
Iteration:  129200, Train reward: -237.045, Eval reward: -215.597, TD loss:   1.726, Episode:  562, Epsilon: 0.01
Iteration:  129300, Train reward: -217.373, Eval reward: -215.597, TD loss:   1.766, Episode:  563, Epsilon: 0.01
Iteration:  129400, Train reward: -217.373, Eval reward: -215.597, TD loss:   2.015, Episode:  563, Epsilon: 0.01
Iteration:  129500, Train reward: -217.373, Eval reward: -215.597, TD loss:   2.086, Episode:  563, Epsilon: 0.01
Iteration:  129600, Train reward: -203.636, Eval reward: -215.597, TD loss:   2.007, Episode:  564, Epsilon: 0.01
Iteration:  129700, Train reward: -203.636, Eval reward: -215.597, TD loss:   1.792, Episode:  564, Epsilon: 0.01
Iteration:  129800, Train reward: -203.636, Eval reward: -215.597, TD loss:   1.855, Episode:  564, Epsilon: 0.01
Iteration:  129900, Train reward: -203.636, Eval reward: -215.597, TD loss:   1.906, Episode:  564, Epsilon: 0.01
Iteration:  130000, Train reward: -203.636, Eval reward: -530.970, TD loss:   2.043, Episode:  564, Epsilon: 0.01
Iteration:  130100, Train reward: -203.636, Eval reward: -530.970, TD loss:   2.102, Episode:  564, Epsilon: 0.01
Iteration:  130200, Train reward: -203.636, Eval reward: -530.970, TD loss:   1.985, Episode:  564, Epsilon: 0.01
Iteration:  130300, Train reward: -203.636, Eval reward: -530.970, TD loss:   1.879, Episode:  564, Epsilon: 0.01
Iteration:  130400, Train reward: -203.636, Eval reward: -530.970, TD loss:   1.953, Episode:  564, Epsilon: 0.01
Iteration:  130500, Train reward: -203.636, Eval reward: -530.970, TD loss:   1.965, Episode:  564, Epsilon: 0.01
Iteration:  130600, Train reward: -204.905, Eval reward: -530.970, TD loss:   2.067, Episode:  565, Epsilon: 0.01
Iteration:  130700, Train reward: -204.905, Eval reward: -530.970, TD loss:   1.843, Episode:  565, Epsilon: 0.01
Iteration:  130800, Train reward: -204.905, Eval reward: -530.970, TD loss:   2.034, Episode:  565, Epsilon: 0.01
Iteration:  130900, Train reward: -204.905, Eval reward: -530.970, TD loss:   1.971, Episode:  565, Epsilon: 0.01
Iteration:  131000, Train reward: -204.905, Eval reward: -489.361, TD loss:   1.736, Episode:  565, Epsilon: 0.01
Iteration:  131100, Train reward: -213.621, Eval reward: -489.361, TD loss:   1.942, Episode:  566, Epsilon: 0.01
Iteration:  131200, Train reward: -213.621, Eval reward: -489.361, TD loss:   2.181, Episode:  566, Epsilon: 0.01
Iteration:  131300, Train reward: -213.621, Eval reward: -489.361, TD loss:   2.125, Episode:  566, Epsilon: 0.01
Iteration:  131400, Train reward: -213.621, Eval reward: -489.361, TD loss:   2.177, Episode:  566, Epsilon: 0.01
Iteration:  131500, Train reward: -213.621, Eval reward: -489.361, TD loss:   1.921, Episode:  566, Epsilon: 0.01
Iteration:  131600, Train reward: -213.621, Eval reward: -489.361, TD loss:   1.931, Episode:  566, Epsilon: 0.01
Iteration:  131700, Train reward: -213.621, Eval reward: -489.361, TD loss:   2.023, Episode:  566, Epsilon: 0.01
Iteration:  131800, Train reward: -213.621, Eval reward: -489.361, TD loss:   2.072, Episode:  566, Epsilon: 0.01
Iteration:  131900, Train reward: -213.621, Eval reward: -489.361, TD loss:   1.914, Episode:  566, Epsilon: 0.01
Iteration:  132000, Train reward: -213.621, Eval reward: -230.311, TD loss:   1.734, Episode:  566, Epsilon: 0.01
Iteration:  132100, Train reward: -211.304, Eval reward: -230.311, TD loss:   1.766, Episode:  567, Epsilon: 0.01
Iteration:  132200, Train reward: -211.304, Eval reward: -230.311, TD loss:   1.925, Episode:  567, Epsilon: 0.01
Iteration:  132300, Train reward: -211.304, Eval reward: -230.311, TD loss:   1.824, Episode:  567, Epsilon: 0.01
Iteration:  132400, Train reward: -211.304, Eval reward: -230.311, TD loss:   1.908, Episode:  567, Epsilon: 0.01
Iteration:  132500, Train reward: -211.559, Eval reward: -230.311, TD loss:   1.976, Episode:  568, Epsilon: 0.01
Iteration:  132600, Train reward: -211.559, Eval reward: -230.311, TD loss:   2.140, Episode:  568, Epsilon: 0.01
Iteration:  132700, Train reward: -211.559, Eval reward: -230.311, TD loss:   1.816, Episode:  568, Epsilon: 0.01
Iteration:  132800, Train reward: -211.559, Eval reward: -230.311, TD loss:   1.792, Episode:  568, Epsilon: 0.01
Iteration:  132900, Train reward: -211.559, Eval reward: -230.311, TD loss:   1.800, Episode:  568, Epsilon: 0.01
Iteration:  133000, Train reward: -211.559, Eval reward: -181.112, TD loss:   1.724, Episode:  568, Epsilon: 0.01
Iteration:  133100, Train reward: -211.559, Eval reward: -181.112, TD loss:   1.877, Episode:  568, Epsilon: 0.01
Iteration:  133200, Train reward: -211.559, Eval reward: -181.112, TD loss:   1.719, Episode:  568, Epsilon: 0.01
Iteration:  133300, Train reward: -211.559, Eval reward: -181.112, TD loss:   1.728, Episode:  568, Epsilon: 0.01
Iteration:  133400, Train reward: -211.559, Eval reward: -181.112, TD loss:   1.872, Episode:  568, Epsilon: 0.01
Iteration:  133500, Train reward: -214.737, Eval reward: -181.112, TD loss:   1.850, Episode:  569, Epsilon: 0.01
Iteration:  133600, Train reward: -214.737, Eval reward: -181.112, TD loss:   1.801, Episode:  569, Epsilon: 0.01
Iteration:  133700, Train reward: -231.525, Eval reward: -181.112, TD loss:   1.956, Episode:  570, Epsilon: 0.01
Iteration:  133800, Train reward: -264.846, Eval reward: -181.112, TD loss:   2.135, Episode:  571, Epsilon: 0.01
Iteration:  133900, Train reward: -264.846, Eval reward: -181.112, TD loss:   1.947, Episode:  571, Epsilon: 0.01
Iteration:  134000, Train reward: -264.846, Eval reward:  -0.217, TD loss:   1.889, Episode:  571, Epsilon: 0.01
Iteration:  134100, Train reward: -264.846, Eval reward:  -0.217, TD loss:   1.881, Episode:  571, Epsilon: 0.01
Iteration:  134200, Train reward: -264.846, Eval reward:  -0.217, TD loss:   2.063, Episode:  571, Epsilon: 0.01
Iteration:  134300, Train reward: -264.846, Eval reward:  -0.217, TD loss:   1.909, Episode:  571, Epsilon: 0.01
Iteration:  134400, Train reward: -264.846, Eval reward:  -0.217, TD loss:   1.967, Episode:  571, Epsilon: 0.01
Iteration:  134500, Train reward: -264.846, Eval reward:  -0.217, TD loss:   1.956, Episode:  571, Epsilon: 0.01
Iteration:  134600, Train reward: -264.846, Eval reward:  -0.217, TD loss:   1.778, Episode:  571, Epsilon: 0.01
Iteration:  134700, Train reward: -264.846, Eval reward:  -0.217, TD loss:   2.013, Episode:  571, Epsilon: 0.01
Iteration:  134800, Train reward: -260.383, Eval reward:  -0.217, TD loss:   1.824, Episode:  572, Epsilon: 0.01
Iteration:  134900, Train reward: -260.383, Eval reward:  -0.217, TD loss:   1.867, Episode:  572, Epsilon: 0.01
Iteration:  135000, Train reward: -260.383, Eval reward: -49.303, TD loss:   1.684, Episode:  572, Epsilon: 0.01
Iteration:  135100, Train reward: -260.383, Eval reward: -49.303, TD loss:   1.840, Episode:  572, Epsilon: 0.01
Iteration:  135200, Train reward: -260.383, Eval reward: -49.303, TD loss:   1.907, Episode:  572, Epsilon: 0.01
Iteration:  135300, Train reward: -260.383, Eval reward: -49.303, TD loss:   1.791, Episode:  572, Epsilon: 0.01
Iteration:  135400, Train reward: -260.383, Eval reward: -49.303, TD loss:   1.712, Episode:  572, Epsilon: 0.01
Iteration:  135500, Train reward: -260.383, Eval reward: -49.303, TD loss:   1.757, Episode:  572, Epsilon: 0.01
Iteration:  135600, Train reward: -260.383, Eval reward: -49.303, TD loss:   1.687, Episode:  572, Epsilon: 0.01
Iteration:  135700, Train reward: -260.383, Eval reward: -49.303, TD loss:   1.748, Episode:  572, Epsilon: 0.01
Iteration:  135800, Train reward: -245.288, Eval reward: -49.303, TD loss:   1.845, Episode:  573, Epsilon: 0.01
Iteration:  135900, Train reward: -250.021, Eval reward: -49.303, TD loss:   1.596, Episode:  574, Epsilon: 0.01
Iteration:  136000, Train reward: -250.021, Eval reward: -314.246, TD loss:   1.945, Episode:  574, Epsilon: 0.01
Iteration:  136100, Train reward: -250.021, Eval reward: -314.246, TD loss:   1.919, Episode:  574, Epsilon: 0.01
Iteration:  136200, Train reward: -250.021, Eval reward: -314.246, TD loss:   1.770, Episode:  574, Epsilon: 0.01
Iteration:  136300, Train reward: -250.021, Eval reward: -314.246, TD loss:   1.776, Episode:  574, Epsilon: 0.01
Iteration:  136400, Train reward: -250.021, Eval reward: -314.246, TD loss:   1.945, Episode:  574, Epsilon: 0.01
Iteration:  136500, Train reward: -250.021, Eval reward: -314.246, TD loss:   1.784, Episode:  574, Epsilon: 0.01
Iteration:  136600, Train reward: -250.021, Eval reward: -314.246, TD loss:   1.853, Episode:  574, Epsilon: 0.01
Iteration:  136700, Train reward: -250.021, Eval reward: -314.246, TD loss:   1.899, Episode:  574, Epsilon: 0.01
Iteration:  136800, Train reward: -250.021, Eval reward: -314.246, TD loss:   1.750, Episode:  574, Epsilon: 0.01
Iteration:  136900, Train reward: -248.831, Eval reward: -314.246, TD loss:   1.808, Episode:  575, Epsilon: 0.01
Iteration:  137000, Train reward: -248.831, Eval reward: -92.569, TD loss:   1.958, Episode:  575, Epsilon: 0.01
Iteration:  137100, Train reward: -249.726, Eval reward: -92.569, TD loss:   1.751, Episode:  576, Epsilon: 0.01
Iteration:  137200, Train reward: -249.726, Eval reward: -92.569, TD loss:   1.771, Episode:  576, Epsilon: 0.01
Iteration:  137300, Train reward: -249.726, Eval reward: -92.569, TD loss:   1.821, Episode:  576, Epsilon: 0.01
Iteration:  137400, Train reward: -249.726, Eval reward: -92.569, TD loss:   1.746, Episode:  576, Epsilon: 0.01
Iteration:  137500, Train reward: -249.726, Eval reward: -92.569, TD loss:   1.601, Episode:  576, Epsilon: 0.01
Iteration:  137600, Train reward: -249.726, Eval reward: -92.569, TD loss:   1.987, Episode:  576, Epsilon: 0.01
Iteration:  137700, Train reward: -249.726, Eval reward: -92.569, TD loss:   1.661, Episode:  576, Epsilon: 0.01
Iteration:  137800, Train reward: -249.726, Eval reward: -92.569, TD loss:   1.687, Episode:  576, Epsilon: 0.01
Iteration:  137900, Train reward: -249.726, Eval reward: -92.569, TD loss:   1.694, Episode:  576, Epsilon: 0.01
Iteration:  138000, Train reward: -249.726, Eval reward: -143.301, TD loss:   1.694, Episode:  576, Epsilon: 0.01
Iteration:  138100, Train reward: -249.435, Eval reward: -143.301, TD loss:   1.779, Episode:  577, Epsilon: 0.01
Iteration:  138200, Train reward: -249.435, Eval reward: -143.301, TD loss:   1.537, Episode:  577, Epsilon: 0.01
Iteration:  138300, Train reward: -249.435, Eval reward: -143.301, TD loss:   1.532, Episode:  577, Epsilon: 0.01
Iteration:  138400, Train reward: -249.435, Eval reward: -143.301, TD loss:   1.450, Episode:  577, Epsilon: 0.01
Iteration:  138500, Train reward: -249.435, Eval reward: -143.301, TD loss:   1.708, Episode:  577, Epsilon: 0.01
Iteration:  138600, Train reward: -249.435, Eval reward: -143.301, TD loss:   1.806, Episode:  577, Epsilon: 0.01
Iteration:  138700, Train reward: -249.435, Eval reward: -143.301, TD loss:   1.631, Episode:  577, Epsilon: 0.01
Iteration:  138800, Train reward: -249.435, Eval reward: -143.301, TD loss:   1.578, Episode:  577, Epsilon: 0.01
Iteration:  138900, Train reward: -249.435, Eval reward: -143.301, TD loss:   1.591, Episode:  577, Epsilon: 0.01
Iteration:  139000, Train reward: -249.435, Eval reward: -68.590, TD loss:   1.574, Episode:  577, Epsilon: 0.01
Iteration:  139100, Train reward: -250.607, Eval reward: -68.590, TD loss:   1.458, Episode:  578, Epsilon: 0.01
Iteration:  139200, Train reward: -250.607, Eval reward: -68.590, TD loss:   1.654, Episode:  578, Epsilon: 0.01
Iteration:  139300, Train reward: -250.607, Eval reward: -68.590, TD loss:   1.362, Episode:  578, Epsilon: 0.01
Iteration:  139400, Train reward: -250.607, Eval reward: -68.590, TD loss:   1.537, Episode:  578, Epsilon: 0.01
Iteration:  139500, Train reward: -250.607, Eval reward: -68.590, TD loss:   1.577, Episode:  578, Epsilon: 0.01
Iteration:  139600, Train reward: -250.607, Eval reward: -68.590, TD loss:   1.655, Episode:  578, Epsilon: 0.01
Iteration:  139700, Train reward: -250.607, Eval reward: -68.590, TD loss:   1.575, Episode:  578, Epsilon: 0.01
Iteration:  139800, Train reward: -250.607, Eval reward: -68.590, TD loss:   1.534, Episode:  578, Epsilon: 0.01
Iteration:  139900, Train reward: -250.607, Eval reward: -68.590, TD loss:   1.415, Episode:  578, Epsilon: 0.01
Iteration:  140000, Train reward: -250.607, Eval reward: -415.404, TD loss:   1.443, Episode:  578, Epsilon: 0.01
Iteration:  140100, Train reward: -240.473, Eval reward: -415.404, TD loss:   1.598, Episode:  579, Epsilon: 0.01
Iteration:  140200, Train reward: -240.473, Eval reward: -415.404, TD loss:   1.716, Episode:  579, Epsilon: 0.01
Iteration:  140300, Train reward: -240.473, Eval reward: -415.404, TD loss:   1.507, Episode:  579, Epsilon: 0.01
Iteration:  140400, Train reward: -240.473, Eval reward: -415.404, TD loss:   1.618, Episode:  579, Epsilon: 0.01
Iteration:  140500, Train reward: -218.426, Eval reward: -415.404, TD loss:   1.986, Episode:  580, Epsilon: 0.01
Iteration:  140600, Train reward: -218.426, Eval reward: -415.404, TD loss:   1.806, Episode:  580, Epsilon: 0.01
Iteration:  140700, Train reward: -218.426, Eval reward: -415.404, TD loss:   1.807, Episode:  580, Epsilon: 0.01
Iteration:  140800, Train reward: -218.426, Eval reward: -415.404, TD loss:   1.771, Episode:  580, Epsilon: 0.01
Iteration:  140900, Train reward: -218.426, Eval reward: -415.404, TD loss:   2.050, Episode:  580, Epsilon: 0.01
Iteration:  141000, Train reward: -218.426, Eval reward: -267.444, TD loss:   1.822, Episode:  580, Epsilon: 0.01
Iteration:  141100, Train reward: -218.426, Eval reward: -267.444, TD loss:   1.847, Episode:  580, Epsilon: 0.01
Iteration:  141200, Train reward: -218.426, Eval reward: -267.444, TD loss:   1.716, Episode:  580, Epsilon: 0.01
Iteration:  141300, Train reward: -218.426, Eval reward: -267.444, TD loss:   1.755, Episode:  580, Epsilon: 0.01
Iteration:  141400, Train reward: -214.388, Eval reward: -267.444, TD loss:   1.736, Episode:  581, Epsilon: 0.01
Iteration:  141500, Train reward: -214.388, Eval reward: -267.444, TD loss:   1.797, Episode:  581, Epsilon: 0.01
Iteration:  141600, Train reward: -214.388, Eval reward: -267.444, TD loss:   1.743, Episode:  581, Epsilon: 0.01
Iteration:  141700, Train reward: -214.388, Eval reward: -267.444, TD loss:   1.875, Episode:  581, Epsilon: 0.01
Iteration:  141800, Train reward: -214.388, Eval reward: -267.444, TD loss:   1.775, Episode:  581, Epsilon: 0.01
Iteration:  141900, Train reward: -214.388, Eval reward: -267.444, TD loss:   1.903, Episode:  581, Epsilon: 0.01
Iteration:  142000, Train reward: -214.388, Eval reward: -160.474, TD loss:   1.908, Episode:  581, Epsilon: 0.01
Iteration:  142100, Train reward: -214.388, Eval reward: -160.474, TD loss:   1.862, Episode:  581, Epsilon: 0.01
Iteration:  142200, Train reward: -214.388, Eval reward: -160.474, TD loss:   1.616, Episode:  581, Epsilon: 0.01
Iteration:  142300, Train reward: -214.388, Eval reward: -160.474, TD loss:   1.784, Episode:  581, Epsilon: 0.01
Iteration:  142400, Train reward: -210.401, Eval reward: -160.474, TD loss:   1.744, Episode:  582, Epsilon: 0.01
Iteration:  142500, Train reward: -210.401, Eval reward: -160.474, TD loss:   1.716, Episode:  582, Epsilon: 0.01
Iteration:  142600, Train reward: -210.401, Eval reward: -160.474, TD loss:   1.863, Episode:  582, Epsilon: 0.01
Iteration:  142700, Train reward: -210.401, Eval reward: -160.474, TD loss:   1.990, Episode:  582, Epsilon: 0.01
Iteration:  142800, Train reward: -210.401, Eval reward: -160.474, TD loss:   1.901, Episode:  582, Epsilon: 0.01
Iteration:  142900, Train reward: -210.401, Eval reward: -160.474, TD loss:   1.811, Episode:  582, Epsilon: 0.01
Iteration:  143000, Train reward: -210.401, Eval reward: -123.060, TD loss:   1.842, Episode:  582, Epsilon: 0.01
Iteration:  143100, Train reward: -210.401, Eval reward: -123.060, TD loss:   1.696, Episode:  582, Epsilon: 0.01
Iteration:  143200, Train reward: -210.401, Eval reward: -123.060, TD loss:   1.683, Episode:  582, Epsilon: 0.01
Iteration:  143300, Train reward: -210.401, Eval reward: -123.060, TD loss:   1.541, Episode:  582, Epsilon: 0.01
Iteration:  143400, Train reward: -199.512, Eval reward: -123.060, TD loss:   1.900, Episode:  583, Epsilon: 0.01
Iteration:  143500, Train reward: -199.512, Eval reward: -123.060, TD loss:   1.844, Episode:  583, Epsilon: 0.01
Iteration:  143600, Train reward: -199.512, Eval reward: -123.060, TD loss:   1.696, Episode:  583, Epsilon: 0.01
Iteration:  143700, Train reward: -199.512, Eval reward: -123.060, TD loss:   1.751, Episode:  583, Epsilon: 0.01
Iteration:  143800, Train reward: -199.512, Eval reward: -123.060, TD loss:   1.839, Episode:  583, Epsilon: 0.01
Iteration:  143900, Train reward: -199.512, Eval reward: -123.060, TD loss:   1.724, Episode:  583, Epsilon: 0.01
Iteration:  144000, Train reward: -200.392, Eval reward: -412.009, TD loss:   1.750, Episode:  584, Epsilon: 0.01
Iteration:  144100, Train reward: -200.392, Eval reward: -412.009, TD loss:   1.867, Episode:  584, Epsilon: 0.01
Iteration:  144200, Train reward: -200.392, Eval reward: -412.009, TD loss:   1.775, Episode:  584, Epsilon: 0.01
Iteration:  144300, Train reward: -200.392, Eval reward: -412.009, TD loss:   1.616, Episode:  584, Epsilon: 0.01
Iteration:  144400, Train reward: -200.392, Eval reward: -412.009, TD loss:   1.740, Episode:  584, Epsilon: 0.01
Iteration:  144500, Train reward: -200.392, Eval reward: -412.009, TD loss:   1.845, Episode:  584, Epsilon: 0.01
Iteration:  144600, Train reward: -216.119, Eval reward: -412.009, TD loss:   1.769, Episode:  585, Epsilon: 0.01
Iteration:  144700, Train reward: -216.119, Eval reward: -412.009, TD loss:   1.829, Episode:  585, Epsilon: 0.01
Iteration:  144800, Train reward: -216.119, Eval reward: -412.009, TD loss:   1.577, Episode:  585, Epsilon: 0.01
Iteration:  144900, Train reward: -216.119, Eval reward: -412.009, TD loss:   1.766, Episode:  585, Epsilon: 0.01
Iteration:  145000, Train reward: -216.119, Eval reward: -67.866, TD loss:   1.584, Episode:  585, Epsilon: 0.01
Iteration:  145100, Train reward: -216.119, Eval reward: -67.866, TD loss:   1.743, Episode:  585, Epsilon: 0.01
Iteration:  145200, Train reward: -216.119, Eval reward: -67.866, TD loss:   1.652, Episode:  585, Epsilon: 0.01
Iteration:  145300, Train reward: -216.119, Eval reward: -67.866, TD loss:   1.725, Episode:  585, Epsilon: 0.01
Iteration:  145400, Train reward: -216.119, Eval reward: -67.866, TD loss:   1.451, Episode:  585, Epsilon: 0.01
Iteration:  145500, Train reward: -216.119, Eval reward: -67.866, TD loss:   1.658, Episode:  585, Epsilon: 0.01
Iteration:  145600, Train reward: -205.378, Eval reward: -67.866, TD loss:   1.617, Episode:  586, Epsilon: 0.01
Iteration:  145700, Train reward: -205.378, Eval reward: -67.866, TD loss:   1.656, Episode:  586, Epsilon: 0.01
Iteration:  145800, Train reward: -220.403, Eval reward: -67.866, TD loss:   1.533, Episode:  587, Epsilon: 0.01
Iteration:  145900, Train reward: -220.403, Eval reward: -67.866, TD loss:   1.780, Episode:  587, Epsilon: 0.01
Iteration:  146000, Train reward: -220.403, Eval reward: -419.250, TD loss:   1.760, Episode:  587, Epsilon: 0.01
Iteration:  146100, Train reward: -220.403, Eval reward: -419.250, TD loss:   1.631, Episode:  587, Epsilon: 0.01
Iteration:  146200, Train reward: -220.403, Eval reward: -419.250, TD loss:   1.610, Episode:  587, Epsilon: 0.01
Iteration:  146300, Train reward: -220.403, Eval reward: -419.250, TD loss:   1.524, Episode:  587, Epsilon: 0.01
Iteration:  146400, Train reward: -220.403, Eval reward: -419.250, TD loss:   1.608, Episode:  587, Epsilon: 0.01
Iteration:  146500, Train reward: -220.403, Eval reward: -419.250, TD loss:   1.506, Episode:  587, Epsilon: 0.01
Iteration:  146600, Train reward: -220.403, Eval reward: -419.250, TD loss:   1.463, Episode:  587, Epsilon: 0.01
Iteration:  146700, Train reward: -220.403, Eval reward: -419.250, TD loss:   1.512, Episode:  587, Epsilon: 0.01
Iteration:  146800, Train reward: -220.425, Eval reward: -419.250, TD loss:   1.561, Episode:  588, Epsilon: 0.01
Iteration:  146900, Train reward: -220.425, Eval reward: -419.250, TD loss:   1.387, Episode:  588, Epsilon: 0.01
Iteration:  147000, Train reward: -220.425, Eval reward: -176.623, TD loss:   1.575, Episode:  588, Epsilon: 0.01
Iteration:  147100, Train reward: -223.125, Eval reward: -176.623, TD loss:   1.297, Episode:  589, Epsilon: 0.01
Iteration:  147200, Train reward: -223.125, Eval reward: -176.623, TD loss:   1.435, Episode:  589, Epsilon: 0.01
Iteration:  147300, Train reward: -208.303, Eval reward: -176.623, TD loss:   1.443, Episode:  590, Epsilon: 0.01
Iteration:  147400, Train reward: -208.303, Eval reward: -176.623, TD loss:   1.490, Episode:  590, Epsilon: 0.01
Iteration:  147500, Train reward: -167.591, Eval reward: -176.623, TD loss:   1.606, Episode:  591, Epsilon: 0.01
Iteration:  147600, Train reward: -167.591, Eval reward: -176.623, TD loss:   1.534, Episode:  591, Epsilon: 0.01
Iteration:  147700, Train reward: -167.591, Eval reward: -176.623, TD loss:   1.748, Episode:  591, Epsilon: 0.01
Iteration:  147800, Train reward: -167.591, Eval reward: -176.623, TD loss:   1.432, Episode:  591, Epsilon: 0.01
Iteration:  147900, Train reward: -167.591, Eval reward: -176.623, TD loss:   1.633, Episode:  591, Epsilon: 0.01
Iteration:  148000, Train reward: -167.591, Eval reward: -174.081, TD loss:   1.663, Episode:  591, Epsilon: 0.01
Iteration:  148100, Train reward: -167.591, Eval reward: -174.081, TD loss:   1.499, Episode:  591, Epsilon: 0.01
Iteration:  148200, Train reward: -167.591, Eval reward: -174.081, TD loss:   1.399, Episode:  591, Epsilon: 0.01
Iteration:  148300, Train reward: -167.591, Eval reward: -174.081, TD loss:   1.324, Episode:  591, Epsilon: 0.01
Iteration:  148400, Train reward: -167.591, Eval reward: -174.081, TD loss:   1.617, Episode:  591, Epsilon: 0.01
Iteration:  148500, Train reward: -169.338, Eval reward: -174.081, TD loss:   1.342, Episode:  592, Epsilon: 0.01
Iteration:  148600, Train reward: -169.338, Eval reward: -174.081, TD loss:   1.676, Episode:  592, Epsilon: 0.01
Iteration:  148700, Train reward: -172.539, Eval reward: -174.081, TD loss:   1.437, Episode:  593, Epsilon: 0.01
Iteration:  148800, Train reward: -172.539, Eval reward: -174.081, TD loss:   1.509, Episode:  593, Epsilon: 0.01
Iteration:  148900, Train reward: -172.539, Eval reward: -174.081, TD loss:   1.467, Episode:  593, Epsilon: 0.01
Iteration:  149000, Train reward: -172.539, Eval reward: -63.690, TD loss:   1.370, Episode:  593, Epsilon: 0.01
Iteration:  149100, Train reward: -172.539, Eval reward: -63.690, TD loss:   1.457, Episode:  593, Epsilon: 0.01
Iteration:  149200, Train reward: -172.539, Eval reward: -63.690, TD loss:   1.584, Episode:  593, Epsilon: 0.01
Iteration:  149300, Train reward: -172.539, Eval reward: -63.690, TD loss:   1.394, Episode:  593, Epsilon: 0.01
Iteration:  149400, Train reward: -172.539, Eval reward: -63.690, TD loss:   1.688, Episode:  593, Epsilon: 0.01
Iteration:  149500, Train reward: -172.539, Eval reward: -63.690, TD loss:   1.379, Episode:  593, Epsilon: 0.01
Iteration:  149600, Train reward: -172.539, Eval reward: -63.690, TD loss:   1.358, Episode:  593, Epsilon: 0.01
Iteration:  149700, Train reward: -152.231, Eval reward: -63.690, TD loss:   1.345, Episode:  594, Epsilon: 0.01
Iteration:  149800, Train reward: -152.231, Eval reward: -63.690, TD loss:   1.534, Episode:  594, Epsilon: 0.01
Iteration:  149900, Train reward: -152.231, Eval reward: -63.690, TD loss:   1.500, Episode:  594, Epsilon: 0.01
Iteration:  150000, Train reward: -152.231, Eval reward: -49.401, TD loss:   1.480, Episode:  594, Epsilon: 0.01
